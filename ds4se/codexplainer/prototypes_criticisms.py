# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/8.6_codexplainer.prototypes_criticisms.ipynb (unless otherwise specified).

__all__ = ['logger', 'reshape_vectors', 'Clusterizer', 'KMedoidsClusterizer', 'CriticismFinder',
           'plot_data_distributions', 'plot_gmms', 'plot_overlap_gmm_compute_kl_div', 'plot_boundaries',
           'perform_analysis', 'plot_3d_data', 'perform_bootstrapping_4_metrics', 'classify_svm',
           'test_proto_crits_results']

# Cell

import numpy as np
import pandas as pd

from typing import Tuple, List, Optional, Any, Iterable, Dict
from abc import ABC, abstractmethod

from pathlib import Path
import pickle

# ds4se
import ds4se
from ..utils.clusterization import *
from ..utils.visualization import *
from ..mgmnt.prep.files_mgmnt import *
from ..utils.distances import *

from tqdm import tqdm

# Cell

import logging

logger = logging.getLogger(__name__)
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
logger.setLevel(logging.INFO)

# Cell

def reshape_vectors(vectors):
    result = []
    for v in vectors:
        result.append(v.reshape(500,1).T)
    return np.array(result)

# Cell


# General implementation aiming to allow the use of different clustering algorithms

class Clusterizer(ABC):
    def __init__(self):
        pass

    @abstractmethod
    def perform_clusterization(self, data_vectors: np.ndarray, dims: Optional[int]=2,
                               dist_metric: Optional[str]='euclidean'):
        """
        Perform clusterization on a given dataset

        """
        pass

# Cell

class KMedoidsClusterizer(Clusterizer):
    def __init__(self):
        # TODO
        super().__init__()

    def perform_clusterization(self, data_vectors: np, dims: Optional[int]=2,
                               dist_metric: Optional[str]='euclidean') -> Tuple:
        """
        Perform clusterization using k-medoids
        - First perform dimensionality reduction by means of PCA + t-SNE
        - Finds best k

        :param data_vectors:
        :param dims: Int. indicating the number of dimensions for
                     dim. reduction

        :return: Tuple (reduced data, clusters, medoid ids, k_medoids_instance (pyclustering obj.))
        """
        return perform_clusterize_kmedoids(data_vectors, dims=dims, reduct_dist=dist_metric)


# Cell

class CriticismFinder:

    def get_critisicms(data, prototypes: List, n: Optional[int]=None,
                       distance: Optional[Any]=None) ->Tuple:
        """
        :param data: Dataset
        :param prototypes: List of found prototypes
        :param n: Numbers of criticisms to find
        :param distance: Distance object instantiating appropriate distance calculation

        :return: Tuple (criticisms points, criticisms ids)
        """
        crit_points, crit_ids = gen_criticisms(data, prototypes, n, distance)
        return crit_points, crit_ids

# Cell

def plot_data_distributions(cluster_data: Dict, model_key: str, model_name: str,
                            human_dist: str, human_key: str,
                            out_path: str,
                            show: bool, export: bool):
    """
    Plot the couple of data distribution (individually) for a given model and a human distribution
    :param cluster_data: Dictionary containing cluster data for both distributions
    :param model_key: Str indicating the key for the model in the dict.
    :param model_name: Str indicating the model name (plotting purposes)
    :param human_dist: Str indicating the human distr. name (plotting purposes)
    :param human_key: Str indicating the human distr. key in the dict.
    :param out_path: Str indicating the destination path for generated figures
    :param show: bool indicating whether or not to show the plots
    :param export: bool indicating whether or not to export the plots
    """
    # Gen. model
    plot_data_distribution_2d(
        cluster_data[model_key][0],
        model_name, out_path,
        export=export, show=show
    )

    # Human distribution
    plot_data_distribution_2d(
        cluster_data[human_key][0],
        human_dist, out_path,
        export=export, show=show
    )

# Cell

def plot_gmms(cluster_data: Dict, model_key: str, model_name: str,
              human_dist: str, human_key: str,
              out_path: str,
              show: bool, export: bool
             ):
    """
    Plot the distributions with the computed GMMs (individually) for both distributions
    :param cluster_data: Dictionary containing cluster data for both distributions
    :param model_key: Str indicating the key for the model in the dict.
    :param model_name: Str indicating the model name (plotting purposes)
    :param human_dist: Str indicating the human distr. name (plotting purposes)
    :param human_key: Str indicating the human distr. key in the dict.
    :param out_path: Str indicating the destination path for generated figures
    :param show: bool indicating whether or not to show the plots
    :param export: bool indicating whether or not to export the plots
    """
    # Plot for model distr.
    plot_gmm_2d_single_distribution(
        cluster_data[model_key], model_name,
        out_path, export=export, show=show
    )

    # Plot for human distr.
    plot_gmm_2d_single_distribution(
        cluster_data[human_key], human_dist,
        out_path, export=export, show=show
    )

# Cell

def plot_overlap_gmm_compute_kl_div(cluster_data: Dict,
                                    out_path: str,
                                    sample_set1_name: str,
                                    sample_set2_name: str,
                                    export: bool, show: bool):
    """
    Plot the overlapping distributions with GMM models and compute the KL-divergence for the
    couple of given distributions
    :param cluster_data: Dict containing the data for both distributions
    :param out_path: Str indicating the destination directory for the generated figures
    :param export: Bool indicating whether or not export the generated figures
    :param show: Bool indicating whether or not show the generated figures
    """

    gen_hum_js_div_s, gen_hum_js_dist_s, gen_hum_js_div_p, gen_hum_js_dist_p = plot_overlapping_gmms(
        cluster_data,
        out_path=out_path,
        sample_set1_name=sample_set1_name, sample_set2_name=sample_set2_name,
        export=export, show=show
    )
    return gen_hum_js_div_s, gen_hum_js_dist_s, gen_hum_js_div_p, gen_hum_js_dist_p

# Cell

# TODO: Implement for non-kmedoids clustering algorithms

def plot_boundaries(cluster_data: Dict, model_key: str, model_name: str,
                             human_dist: str, human_key: str, out_path: str,
                             show: bool, export: bool):
    """
    :param cluster_data: Dictionary containing cluster data for both distributions
    :param model_key: Str indicating the key for the model in the dict.
    :param model_name: Str indicating the model name (plotting purposes)
    :param human_dist: Str indicating the human distr. name (plotting purposes)
    :param human_key: Str indicating the human distr. key in the dict.
    :param out_path: Str indicating the destination path for generated figures
    :param show: bool indicating whether or not to show the plots
    :param export: bool indicating whether or not to export the plots
    """

    # Plot for generative model
    plot_kmedoids_decision_boundaries(
        cluster_data[model_key], model_name, out_path,
        show=show, export=export
    )

    # Plot for human distribution
    plot_kmedoids_decision_boundaries(
        cluster_data[human_key], human_dist, out_path,
        show=show, export=export
    )

# Cell

def perform_analysis(model_config: str, model_name: str, model_key: str,
                     human_config: str, human_key: str,
                     vectors_storage_path: str,
                     figures_export_path: str,
                     clusterizer: Clusterizer,
                     n_experiments: Optional[int]=None,
                     enable_visualization: Optional[bool]=False,
                     export_figures: Optional[bool]=False,
                     distance_metric: Optional[str]='cosine',
                     plot_3d: Optional[bool]=False
                    ) -> Tuple[np.ndarray, np.ndarray]:
    """
    Perform analysis for a couple of distributions

    :return: Tuple containing js-div & js-dist measurements for the entire sample sets (distribution1 vs distribution2)
    """
    gen_sample_files = get_vector_paths_4_sample_set(set_name=model_config, base_path=vectors_storage_path)
    human_sample_files = get_vector_paths_4_sample_set(set_name=human_config, base_path=vectors_storage_path)

    # For sampling via GMM
    js_div_gen_hmn_smpl = []
    js_dist_gen_hmn_smpl = []

    # For calculation via actual points
    js_div_gen_hmn_pnt = []
    js_dist_gen_hmn_pnt = []

    fig_info = []

    # Configure directory (in case it doesn't exist)
    model_figures_path = configure_child_directory(base_path=figures_export_path, sub_dir=model_config)

    if n_experiments is not None:
        if len(gen_sample_files) < n_experiments or len(human_sample_files) < n_experiments:
            # TODO: Handle error
            logging.error("Amount of samples don't match for performing comparisons (model vs human)")
            return

        gen_sample_files = gen_sample_files[:n_experiments]
        human_sample_files = human_sample_files[:n_experiments]

    for i in tqdm(range(n_experiments)):
        # Configure directory for each sample set
        gen_sample_set = str(gen_sample_files[i].parent).split("/")[-1]
        out_path = configure_child_directory(base_path=str(model_figures_path), sub_dir=gen_sample_set)
        sub_dir = f"{model_key}-{human_config}"
        out_path = configure_child_directory(base_path=out_path, sub_dir=sub_dir)

        gen_vectors = load_np_vectors(gen_sample_files[i])
        human_vectors = load_np_vectors(human_sample_files[i])

        gen_cluster = clusterizer.perform_clusterization(
            gen_vectors, dims=2, dist_metric=distance_metric
        )
        human_cluster = clusterizer.perform_clusterization(
            human_vectors, dims=2, dist_metric=distance_metric
        )

        cluster_data = {
            model_key: gen_cluster,
            human_key: human_cluster
        }

        gen_sample_set_name = f"{model_name}-sample{i}"
        hmn_sample_set_name = f"{human_config}-sample{i}"
        # -------------------------------------------------------------------------------
        # Save reduced data
        # -------------------------------------------------------------------------------
        red_vectors_gen = gen_cluster[0]
        red_vectors_hmn = human_cluster[0]
        np.save(str(Path(out_path) / f"{gen_sample_set_name}-reduced-feats"), red_vectors_gen)
        np.save(str(Path(out_path) / f"{hmn_sample_set_name}-reduced-feats"), red_vectors_hmn)
        # -------------------------------------------------------------------------------
        # Save cluster data (clusters and indices)
        # -------------------------------------------------------------------------------
        np.save(str(Path(out_path) / f"{gen_sample_set_name}-clusters"), gen_cluster[1])
        np.save(str(Path(out_path) / f"{gen_sample_set_name}-idx"), gen_cluster[2])

        np.save(str(Path(out_path) / f"{hmn_sample_set_name}-clusters"), human_cluster[1])
        np.save(str(Path(out_path) / f"{hmn_sample_set_name}-idx"), human_cluster[2])
        # TODO: check crits
        # -------------------------------------------------------------------------------
        # Save clustering instance
        # save_pyclustering_model(gen_cluster[3], str(Path(out_path) / f"{gen_sample_set_name}-cluster_instance.txt"))
        # save_pyclustering_model(human_cluster[3], str(Path(out_path) / f"{hmn_sample_set_name}-cluster_instance.txt"))
        # -------------------------------------------------------------------------------


        # Plot individual distributions
        plot_data_distributions(
            cluster_data, model_key, gen_sample_set_name,
            hmn_sample_set_name, human_key, out_path,
            enable_visualization, export_figures
        )

        # Plot GMMs
        plot_gmms(
            cluster_data, model_key, gen_sample_set_name,
            hmn_sample_set_name, human_key, out_path,
            enable_visualization, export_figures
        )

        # Plot overlapping GMMs & compute js-divergence & distance
        gen_hum_div_smpl, gen_hmn_dist_smpl, gen_hum_div_pnt, gen_hmn_dist_pnt = plot_overlap_gmm_compute_kl_div(
            cluster_data, out_path,
            gen_sample_set_name, hmn_sample_set_name,
            export_figures, enable_visualization
        )

        # Accumulate JS-div data
        js_div_gen_hmn_smpl.append(gen_hum_div_smpl)
        js_dist_gen_hmn_smpl.append(gen_hmn_dist_smpl)

        js_div_gen_hmn_pnt.append(gen_hum_div_pnt)
        js_dist_gen_hmn_pnt.append(gen_hmn_dist_pnt)

        # Plot decision boundaries
        plot_boundaries(cluster_data, model_key, gen_sample_set_name,
                        hmn_sample_set_name, human_key, out_path,
                        enable_visualization, export_figures
        )

        # Human-distribution (GMM-based) vs generated points (points + protos. & crits.)
        add_labels = i == 0 or i == 15
        sample_traces = plot_gmms_vs_points(
            points_data=cluster_data[model_key],
            distribution_data=cluster_data[human_key],
            distribution_name=hmn_sample_set_name,
            points_name=gen_sample_set_name,
            out_path=out_path,
            show=enable_visualization,
            export=export_figures,
            use_gmm_model=True,
            add_labels=add_labels,
            gmm_color='rgb(86, 100, 175)'
        )
        fig_info.append(sample_traces)

        logging.info('Finished individual plots...')


    sheet_titles = tuple([f'Set {i+1}' for i in range(n_experiments)])

    #
    plot_gmms_vs_points_sheet(
        sheet_titles, 30, fig_info, model_figures_path,
        f'{model_name}-vs-{human_config}',
        export=export_figures, show=enable_visualization
    )

    return (np.array(js_div_gen_hmn_smpl), np.array(js_dist_gen_hmn_smpl),
            np.array(js_div_gen_hmn_pnt), np.array(js_dist_gen_hmn_pnt))

# Cell

def plot_3d_data(model_config: str, model_name: str, model_key: str,
                 human_config: str, human_key: str,
                 vectors_storage_path: str, figures_export_path: str,
                 n_experiments: Optional[int]=None,
                 enable_visualization: Optional[bool]=False,
                 export_figures: Optional[bool]=False,
                 distance_metric: Optional[str]='cosine',
                 sample_sets: Optional[bool]=False
                ):
    """
    Plot 3d data for points distribution
    """

    # Load vectors (complete)
    gen_sample_files = get_vector_paths_4_sample_set(set_name=model_config, base_path=vectors_storage_path)
    hmn_sample_files = get_vector_paths_4_sample_set(set_name=human_config, base_path=vectors_storage_path)

    js_div_gen_vs_hmn = []
    js_dist_gen_vs_hmn = []

    # TODO:
    fig_info = []

    # Configure directory (in case it doesn't exist)
    # model_figures_path = configure_child_directory(base_path=figures_export_path, sub_dir=model_config)

    n = len(gen_sample_files) if n_experiments is None else n_experiments

    if sample_sets:
        random_idx = np.random.choice(np.array(range(len(gen_sample_files))),
                                      size=n, replace=False)
        gen_samples = np.take(gen_sample_files, random_idx)

        random_idx = np.random.choice(np.array(range(len(gen_sample_files))),
                                      size=n, replace=False)
        hmn_samples = np.random.take(hmn_sample_files, random_idx)
    else:
        gen_samples = gen_sample_files[:n]
        hmn_samples = gen_sample_files[:n]

    for i in range(n):
        # TODO: Save vectors
        gen_vectors = load_np_vectors(gen_sample_files[i])
        hmn_vectors = load_np_vectors(hmn_sample_files[i])

        gen_vectors_3d = reduce_dims_umap(gen_vectors, metric=distance_metric, dims=3)
        hmn_vectors_3d = reduce_dims_umap(hmn_vectors, metric=distance_metric, dims=3)

        fig = go.Figure()

        x = gen_vectors_3d[:, 0]
        y = gen_vectors_3d[:, 1]
        z = gen_vectors_3d[:, 2]

        fig.add_trace(go.Scatter3d(
            x=x, y=y, z=z, mode='markers',
            name=f'{model_name}-sample{i}',
            marker=dict(
                size=5,
                line_width=0.4
            ))
        )

        x = hmn_vectors_3d[:, 0]
        y = hmn_vectors_3d[:, 1]
        z = hmn_vectors_3d[:, 2]

        fig.add_trace(go.Scatter3d(
            x=x, y=y, z=z, mode='markers',
            name=f'{human_config}-sample{i}',
            marker=dict(
                size=5,
                line_width=0.4
            ))
        )

        fig.update_layout(
            scene = dict(
                xaxis_title='UMAP Dim. 1',
                yaxis_title='UMAP Dim. 2',
                zaxis_title='UMAP Dim. 3'),
        )
        fig.show()

        print("Plotting decision boundaries")
        x, y, z = classify_svm(gen_vectors_3d, hmn_vectors_3d)


        fig.add_trace(go.Surface(
            x=x, y=y, z=z(x,y),
            colorscale='Bluered',
            showscale=False
        ))

        fig.show()
        if()

# Cell

def perform_bootstrapping_4_metrics(metrics_df: pd.DataFrame) -> pd.DataFrame:
    """
    Bootstrap dataframe for each dimension in the given df

    Parameters
    ----------
    metrics_df : DataFrame
        Dataframe containing metrics data
    Returns

    ----------
    """
    metrics_dims = list(metrics_df.columns)

    data_dict = {}

    for dim in metrics_dims:
        dim_data = mtcs_js_dist_trn[dim].values
        zeros_data = verify_if_zeros(dim_data)

        bs_dim_data = bootstrapping(dim_data, np.mean, sample_size=500, full_zeros=zeros_data)
        bs_data = bs_dim_data['bootstrap_repl'].values
        data_dict[dim] = bs_data

    return pd.DataFrame(data_dict)

# Cell

def classify_svm(dataset_gen: np.ndarray, dataset_hmn: np.ndarray,
                 kernel: Optional[str]='linear'):
    """
    Separate the points via SVM classification

    Parameters
    ----
    dataset_gen: np.ndarray
        Dataset containing datapoints from synthetic samples
    dataset_hmn: np.ndarray
        Dataset containing datapoints from human samples
    kernel: Optional[str]
        kernel function to be used with the SVM classifier
        default: linear

    """
    # Build dataset
    X = np.concatenate((dataset_gen, dataset_hmn), axis=0)
    Y = np.concatenate(
        (np.ones(len(dataset_gen)), np.zeros(len(dataset_hmn))),
        axis=0
    )

    # Build classifier
    model = svm.SVC(kernel=kernel)
    clf = model.fit(X, Y)

    # The equation of the separating plane is given by all x so
    # that np.dot(svc.coef_[0], x) + b = 0.
    # Solve for w3 (z)

    z = lambda x,y: (-clf.intercept_[0]-clf.coef_[0][0]*x -clf.coef_[0][1]*y) / clf.coef_[0][2]

    min_int = np.min(X)
    max_int = np.max(X)

    tmp = np.linspace(min_int,max_int,40)
    x,y = np.meshgrid(tmp,tmp)

    return x, y, z

#     fig = plt.figure()
#     ax = fig.add_subplot(111, projection='3d')

#     ax.plot3D(X[Y==0,0], X[Y==0,1], X[Y==0,2],'ob')
#     ax.plot3D(X[Y==1,0], X[Y==1,1], X[Y==1,2],'sr')
#     ax.plot_surface(x, y, z(x,y))
#     ax.view_init(30, 60)
#     plt.show()

# Cell

def test_proto_crits_results(model_config, human_config, model_key, vectors_storage_path,
                             model_name, n_experiments, data_path,
                             out_path,
                             enable_visualization=False,
                             export_figures=False,
                             gmm_color='rgb(86, 100, 175)'
                            ):
    gen_sample_files = get_vector_paths_4_sample_set(set_name=model_config, base_path=vectors_storage_path)
    human_sample_files = get_vector_paths_4_sample_set(set_name=human_config, base_path=vectors_storage_path)

    fig_info = []
    for i in tqdm(range(n_experiments)):
        gen_sample_set = str(gen_sample_files[i].parent).split("/")[-1]
        print(gen_sample_set)
        full_path = Path(data_path) / gen_sample_set / f"{model_key}-{human_config}"
        print(full_path)
        print(full_path.exists())
        # Load data for datapoints
        gen_feats_path = str(full_path / f"{model_name}-sample{i}-reduced-feats.npy")
        gen_feats = np.load(gen_feats_path)
        gen_prots_ids_path = str(full_path / f"{model_name}-sample{i}-idx.npy")
        gen_prots_ids = np.load(gen_prots_ids_path)

        gen_tuple = gen_feats, [], gen_prots_ids, []

        # Load data for distribution
        hmn_feats_path = str(full_path / f"{human_config}-sample{i}-reduced-feats.npy")
        hmn_feats = np.load(hmn_feats_path)
        hmn_prots_ids_path = str(full_path / f"{human_config}-sample{i}-idx.npy")
        hmn_prots_ids = np.load(hmn_prots_ids_path)

        human_tuple = hmn_feats, [], hmn_prots_ids, []

        gen_sample_set_name = f"{model_name}-sample{i}"
        hmn_sample_set_name = f"{human_config}-sample{i}"

        gmm_model_path = str(full_path / f"gmm-{human_config}-sample{i}-{model_name}-sample{i}")

#         print(hmn_feats_path)
#         print(Path(hmn_feats_path).exists())


#         print(hmn_feats)


#         print(hmn_prots_path)
#         print(Path(hmn_feats_path).exists())


        human_tuple = hmn_feats, [], hmn_prots_ids, []

#         print(hmn_prots)

        print(len(hmn_feats))
        print(len(hmn_prots_ids))

        add_labels = i == 0 or i == 15

        logging.info(f'Gathering comparison data for sample {i}...')
        traces_shapes = plot_gmms_vs_points(
            points_data=gen_tuple,
            distribution_data=human_tuple,
            distribution_name=hmn_sample_set_name,
            points_name=gen_sample_set_name,
            out_path=out_path,
            show=False,
            export=export_figures,
            use_gmm_model=False,
            gmm_color=gmm_color,
            add_labels=add_labels,
            compute_crits=False
        )

        fig_info.append(traces_shapes)

    sheet_titles = tuple([f'Set {i+1}' for i in range(30)])
    plot_gmms_vs_points_sheet(sheet_titles, 30, fig_info, out_path,
                              'GPT2-vs-train', export=export_figures, show=enable_visualization)