{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tf/main/ds4se/notebooks/code2vec/code2vec')\n",
    "\n",
    "from typing import *\n",
    "import tensorflow as tf\n",
    "tf.executing_eagerly()\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'code2vec_model_path': '/tf/main/ds4se/dvc-ds4se/models/cv/java-large-release/saved_model_iter3.release',\n",
    "    'code2vec_predicter': {\n",
    "        'SHOW_TOP_CONTEXTS': 10,\n",
    "        'MAX_PATH_LENGTH': 8,\n",
    "        'MAX_PATH_WIDTH': 2,\n",
    "        'JAR_PATH': 'JavaExtractor/JPredict/target/JavaExtractor-0.0.1-SNAPSHOT.jar',\n",
    "    },\n",
    "    'codesearchnet_java_csv_path': '/tf/main/ds4se/dvc-ds4se/code/searchnet/[codesearchnet-java-1597073966.81902].csv',\n",
    "    'spm_model_path': '/tf/main/my_model/spm',\n",
    "    'spm_vocab_size': 16384,\n",
    "    'spm_sentence_length': 256,\n",
    "    'ae_checkpoint_path': '/tf/main/my_model/ae_checkpoint',\n",
    "    'ae_embedding_dim': 256,\n",
    "    'ae_batch_size': 16,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CodeSearchNet-Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_searchnet = pd.read_csv(config['codesearchnet_java_csv_path'], header=0, index_col=0, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496688"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_searchnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "      <th>bpe32k</th>\n",
       "      <th>code_len</th>\n",
       "      <th>bpe32_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/internal/observers/...</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>protected final void fastPathOrderedEmit(U val...</td>\n",
       "      <td>['protected', 'final', 'void', 'fastPathOrdere...</td>\n",
       "      <td>Makes sure the fast-path emits in order.\\n@par...</td>\n",
       "      <td>['Makes', 'sure', 'the', 'fast', '-', 'path', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁protected', '▁final', '▁void', '▁fast', 'Pa...</td>\n",
       "      <td>134</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@CheckReturnValue\\n    @NonNull\\n    @Schedule...</td>\n",
       "      <td>['@', 'CheckReturnValue', '@', 'NonNull', '@',...</td>\n",
       "      <td>Mirrors the one ObservableSource in an Iterabl...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...</td>\n",
       "      <td>63</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings(\"unchecked\")\\n    @CheckRetu...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '\"unchecked\"', ...</td>\n",
       "      <td>Mirrors the one ObservableSource in an array o...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings({ \"unchecked\", \"rawtypes\" })...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '{', '\"unchecke...</td>\n",
       "      <td>Concatenates elements of each ObservableSource...</td>\n",
       "      <td>['Concatenates', 'elements', 'of', 'each', 'Ob...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               repo                                               path  \\\n",
       "0  ReactiveX/RxJava  src/main/java/io/reactivex/internal/observers/...   \n",
       "1  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "2  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "3  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "1  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "2  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "3  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "\n",
       "                                                code  \\\n",
       "0  protected final void fastPathOrderedEmit(U val...   \n",
       "1  @CheckReturnValue\\n    @NonNull\\n    @Schedule...   \n",
       "2  @SuppressWarnings(\"unchecked\")\\n    @CheckRetu...   \n",
       "3  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })...   \n",
       "\n",
       "                                         code_tokens  \\\n",
       "0  ['protected', 'final', 'void', 'fastPathOrdere...   \n",
       "1  ['@', 'CheckReturnValue', '@', 'NonNull', '@',...   \n",
       "2  ['@', 'SuppressWarnings', '(', '\"unchecked\"', ...   \n",
       "3  ['@', 'SuppressWarnings', '(', '{', '\"unchecke...   \n",
       "\n",
       "                                           docstring  \\\n",
       "0  Makes sure the fast-path emits in order.\\n@par...   \n",
       "1  Mirrors the one ObservableSource in an Iterabl...   \n",
       "2  Mirrors the one ObservableSource in an array o...   \n",
       "3  Concatenates elements of each ObservableSource...   \n",
       "\n",
       "                                    docstring_tokens language partition  \\\n",
       "0  ['Makes', 'sure', 'the', 'fast', '-', 'path', ...     java      test   \n",
       "1  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "2  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "3  ['Concatenates', 'elements', 'of', 'each', 'Ob...     java      test   \n",
       "\n",
       "                                              bpe32k  code_len  bpe32_len  \n",
       "0  ['▁protected', '▁final', '▁void', '▁fast', 'Pa...       134        138  \n",
       "1  ['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...        63         71  \n",
       "2  ['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...       107        109  \n",
       "3  ['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...        79         83  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_searchnet.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running code2vec over CodeSearchNet-Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import code2vec\n",
    "import common as code2vec_common\n",
    "import config as code2vec_config\n",
    "import extractor as code2vec_extrator\n",
    "\n",
    "code2vec_cfg = code2vec_config.Config(set_defaults=True)\n",
    "code2vec_cfg.PREDICT = True\n",
    "code2vec_cfg.MODEL_LOAD_PATH = config['code2vec_model_path']\n",
    "code2vec_cfg.DL_FRAMEWORK = 'tensorflow'\n",
    "code2vec_cfg.EXPORT_CODE_VECTORS = True\n",
    "code2vec_cfg.verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2vec_model = code2vec.load_model_dynamically(code2vec_cfg)\n",
    "code2vec_path_extractor = code2vec_extrator.Extractor(\n",
    "    code2vec_cfg,\n",
    "    jar_path=config['code2vec_predicter']['JAR_PATH'],\n",
    "    max_path_length=config['code2vec_predicter']['MAX_PATH_LENGTH'],\n",
    "    max_path_width=config['code2vec_predicter']['MAX_PATH_WIDTH']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "def code2vec_predict(code: str) -> List[np.ndarray]:\n",
    "    os.chdir('/tf/main/ds4se/notebooks/code2vec/code2vec')\n",
    "    with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', suffix='.java') as input_file:\n",
    "        input_file.write(code)\n",
    "        input_file.flush()\n",
    "        input_filename = input_file.name\n",
    "        try:\n",
    "            predict_lines, hash_to_string_dict = code2vec_path_extractor.extract_paths(input_filename)\n",
    "        except ValueError as e:\n",
    "            raise\n",
    "    assert len(predict_lines) == 1\n",
    "    raw_prediction_results = code2vec_model.predict(predict_lines)\n",
    "    assert len(raw_prediction_results) == 1\n",
    "    raw_prediction = raw_prediction_results[0]\n",
    "    return raw_prediction.code_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, row in df_searchnet.iterrows():\n",
    "    if i == 4:\n",
    "        break\n",
    "    print('\\n'.join(repr(code2vec_predict(row['code'])).split('\\n')[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use google/sentencepiece for input tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --user -U sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... (Use docker logs -f NAME to see the logs)\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "print(\"Training... (Use docker logs -f NAME to see the logs)\", flush=True)\n",
    "spm.SentencePieceTrainer.train(\n",
    "    sentence_iterator=(i for i in df_searchnet['code']),\n",
    "    max_sentence_length=config['spm_sentence_length'],\n",
    "    model_prefix=config['spm_model_path'],\n",
    "    model_type='bpe',\n",
    "    vocab_size=config['spm_vocab_size']\n",
    ")\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm_model = spm.SentencePieceProcessor(model_file=config['spm_model_path'] + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁protected', '▁final', '▁void', '▁fast', 'Path', 'Ordered', 'Emit', '(', 'U', '▁value', ',', '▁boolean', '▁delay', 'Error', ',', '▁Disposable', '▁dis', 'posable', ')', '▁{', '▁final', '▁O', 'bserver', '<?', '▁super', '▁V', '>', '▁observer', '▁=', '▁downstream', ';', '▁final', '▁Simple', 'Plain', 'Queue', '<', 'U', '>', '▁q', '▁=', '▁queue', ';', '▁if', '▁(', 'w', 'ip', '.', 'get', '()', '▁==', '▁0', '▁&&', '▁w', 'ip', '.', 'compareAndSet', '(0,', '▁1))', '▁{', '▁if', '▁(', 'q', '.', 'isEmpty', '())', '▁{', '▁accept', '(', 'observer', ',', '▁value', ');', '▁if', '▁(', 'le', 'ave', '(', '-1)', '▁==', '▁0)', '▁{', '▁return', ';', '▁}', '▁}', '▁else', '▁{', '▁q', '.', 'offer', '(', 'value', ');', '▁}', '▁}', '▁else', '▁{', '▁q', '.', 'offer', '(', 'value', ');', '▁if', '▁(!', 'enter', '())', '▁{', '▁return', ';', '▁}', '▁}', '▁Queue', 'Dr', 'ain', 'Helper', '.', 'dr', 'ain', 'Loop', '(', 'q', ',', '▁observer', ',', '▁delay', 'Error', ',', '▁dis', 'posable', ',', '▁this', ');', '▁}', '</s>']\n",
      "[1, 412, 143, 91, 11096, 343, 9899, 7760, 16312, 16351, 195, 16321, 221, 3558, 837, 16321, 13113, 1494, 10013, 16313, 12, 143, 587, 2824, 294, 523, 340, 16342, 6165, 36, 14125, 16319, 143, 2027, 6257, 1323, 16343, 16351, 16342, 2005, 36, 2751, 16319, 95, 55, 16334, 450, 16318, 33, 46, 161, 228, 484, 208, 450, 16318, 6648, 1832, 12366, 12, 95, 55, 16350, 16318, 1163, 338, 12, 3287, 16312, 8231, 16321, 195, 9, 95, 55, 48, 1297, 16312, 15725, 161, 870, 12, 28, 16319, 11, 11, 553, 12, 2005, 16318, 7297, 16312, 353, 9, 11, 11, 553, 12, 2005, 16318, 7297, 16312, 353, 9, 95, 912, 1986, 338, 12, 28, 16319, 11, 11, 5043, 10777, 310, 1399, 16318, 3940, 310, 5204, 16312, 16350, 16321, 6165, 16321, 3558, 837, 16321, 1494, 10013, 16321, 133, 9, 11, 2]\n"
     ]
    }
   ],
   "source": [
    "print(spm_model.encode(df_searchnet['code'].iloc[0], out_type='str', add_bos=True, add_eos=True))\n",
    "print(spm_model.encode(df_searchnet['code'].iloc[0], add_bos=True, add_eos=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_model.vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def encode_and_pad(s: str) -> tf.Tensor:\n",
    "    return tf.convert_to_tensor(\n",
    "        tf.keras.preprocessing.sequence.pad_sequences([\n",
    "            spm_model.encode(s, add_bos=True, add_eos=True)\n",
    "        ], maxlen=config['spm_sentence_length'], padding='post')[0],\n",
    "        dtype=tf.int32\n",
    "    )\n",
    "\n",
    "df_searchnet_tf_slices = []\n",
    "for i, row in enumerate(df_searchnet['code']):\n",
    "    df_searchnet_tf_slices.append(encode_and_pad(row))\n",
    "    if (i % 10000) == 0:\n",
    "        print(i)\n",
    "        \n",
    "df_searchnet_tf = tf.data.Dataset.from_tensor_slices(df_searchnet_tf_slices).shuffle(len(df_searchnet_tf_slices))\n",
    "df_searchnet_tf = df_searchnet_tf.batch(config['ae_batch_size'], drop_remainder=True)\n",
    "del df_searchnet_tf_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (16, 256), types: tf.int32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_searchnet_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([1] * config['ae_batch_size'], 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    spm_model.vocab_size(),\n",
    "    config['ae_embedding_dim'],\n",
    "    config['spm_sentence_length'],\n",
    "    config['ae_batch_size'])\n",
    "decoder = Decoder(\n",
    "    spm_model.vocab_size(),\n",
    "    config['ae_embedding_dim'],\n",
    "    config['spm_sentence_length'],\n",
    "    config['ae_batch_size'])\n",
    "checkpoint_prefix = config['ae_checkpoint_path']\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    optimizer=optimizer,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (16, 256, 256)\n",
      "Encoder Hidden state shape: (batch size, units) (16, 256)\n",
      "Decoder output shape: (batch_size, vocab size) (16, 16384)\n"
     ]
    }
   ],
   "source": [
    "# sample input\n",
    "example_input_batch = next(iter(df_searchnet_tf))\n",
    "example_input_batch.shape\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
    "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((config['ae_batch_size'], 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.3997\n",
      "Epoch 1 Loss 3.7845\n",
      "Time taken for 1 epoch 436.3125982284546 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.6036\n",
      "Epoch 2 Loss 3.1126\n",
      "Time taken for 1 epoch 134.10465955734253 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.4923\n",
      "Epoch 3 Loss 3.1136\n",
      "Time taken for 1 epoch 134.5851469039917 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.7383\n",
      "Epoch 4 Loss 3.1887\n",
      "Time taken for 1 epoch 133.68952465057373 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.6992\n",
      "Epoch 5 Loss 3.1851\n",
      "Time taken for 1 epoch 135.46811485290527 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.5103\n",
      "Epoch 6 Loss 2.9542\n",
      "Time taken for 1 epoch 137.94829106330872 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.3405\n",
      "Epoch 7 Loss 3.1072\n",
      "Time taken for 1 epoch 135.55201148986816 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.3652\n",
      "Epoch 8 Loss 2.9516\n",
      "Time taken for 1 epoch 135.92289400100708 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 2.9978\n",
      "Epoch 9 Loss 2.7130\n",
      "Time taken for 1 epoch 136.479975938797 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.6442\n",
      "Epoch 10 Loss 2.8110\n",
      "Time taken for 1 epoch 134.91528129577637 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 10\n",
    "steps_per_epoch = config['spm_sentence_length']//config['ae_batch_size']\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, inp) in enumerate(df_searchnet_tf.take(config['ae_batch_size'])):\n",
    "        batch_loss = train_step(inp, inp, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
