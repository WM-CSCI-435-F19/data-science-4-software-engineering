{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp interpretability.d2v_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from tokenizers import Tokenizer\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec usage for source code\n",
    "\n",
    "> Use doc2vec models to get distributed representation (embedding vectors) for source code\n",
    "\n",
    "> @Alvaro 15 April 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def check_file_existence(path):\n",
    "    if not os.path.exists(path):\n",
    "        logging.error('Provided file cannot be found.')\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer class is defined abstract in order to provide alternatives for tokenization (SentencePiece and HuggingFace's Tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizer(ABC):\n",
    "    def __init__(self, tkzr_path:str, d2v_path: str):\n",
    "        \"\"\"\n",
    "        Default constructor for Vectorizer class\n",
    "        \"\"\"\n",
    "        self.tkzr_path = tkzr_path\n",
    "        self.d2v_path = d2v_path\n",
    "        \n",
    "        self._load_tokenizer_model(self.tkzr_path)\n",
    "        self._load_doc2vec_model(d2v_path)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def tokenize_df(self, df: pd.DataFrame, code_column: str):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _load_tokenizer_model(self, model_path: str):\n",
    "        pass\n",
    "    \n",
    "    def _load_doc2vec_model(self, model_path: str):\n",
    "        \"\"\"\n",
    "        :param model_path: Path to the model file\n",
    "        :return: Gensim Doc2Vec model (corresponding to the loaded model)\n",
    "        \"\"\"\n",
    "        if not check_file_existence(model_path):\n",
    "            msg = 'Doc2vec model could no be loaded'\n",
    "            logging.error('Doc2vec model could no be loaded')\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        model = gensim.models.Doc2Vec.load(model_path)\n",
    "        self.d2v_model = model    \n",
    "        \n",
    "    def infer_d2v(self, df: pd.DataFrame, tokenized_column: str, out_path: str, steps: int=200) -> tuple:\n",
    "        \"\"\"\n",
    "        Performs vectorization via Doc2Vec model \n",
    "        \"param df\": Pandas DataFrame containing source code\n",
    "        :param code_column: Column name of the column corresponding to source code\n",
    "        :param steps: Steps for the doc2vec infere\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        df_inferred = df.copy()\n",
    "        \n",
    "        inferred_vecs = np.array([self.d2v_model.infer_vector(tok_snippet, steps=200) \\\n",
    "                                  for tok_snippet in df[tokenized_column].values])\n",
    "        \n",
    "        indices = np.array(df.index)\n",
    "        \n",
    "        np.save(f\"{out_path}/indices\", indices)\n",
    "        np.save(f\"{out_path}/feat_vectors\", inferred_vecs)\n",
    "        \n",
    "        return indices, inferred_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizerSP(Doc2VecVectorizer):\n",
    "    \"\"\"\n",
    "    Class to perform vectorization via Doc2Vec model\n",
    "    leveraging SentencePiece to tokenizer sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, sp_path: str, d2v_path: str):\n",
    "        \"\"\"\n",
    "        :param sp_path: Path to the SentencePiece saved model\n",
    "        :param d2v_path: Path to the Doc2Vec saved model\n",
    "        \"\"\"\n",
    "        super().__init__(sp_path, d2v_path)\n",
    "    \n",
    "    def _load_tokenizer_model(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Loads the sentence piece model stored in the specified path \n",
    "        :param model_path: Path to the model file\n",
    "        :return: SentencePieceProcessor object (corresponding to loaded model)\n",
    "        \"\"\"\n",
    "        if not check_file_existence(model_path):\n",
    "            msg = 'Sentence piece model could no be loaded'\n",
    "            logging.error(msg)\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        sp_processor = spm.SentencePieceProcessor()\n",
    "        sp_processor.load(model_path)\n",
    "        self.tokenizer = sp_processor\n",
    "        \n",
    "    def tokenize_df(self, df: pd.DataFrame, code_column: str):\n",
    "        \"\"\"\n",
    "        Performs processing for a DataFrame containing source code\n",
    "        :param df: Pandas DataFrame\n",
    "        :param code_column: Name corresponding to the column containing source code\n",
    "        :return: DataFrame containing the processed code using SentencePiece\n",
    "        \"\"\"\n",
    "        result_df = df[code_column].apply(lambda snippet: self.__sp_encode_as_pieces(snippet))\n",
    "        return result_df\n",
    "    \n",
    "    def __sp_encode_as_pieces(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Performs tokenization of given text using SentencePieceProcesor\n",
    "        :param txt: String to be encoded (tokenized)\n",
    "        :return: List of the subword tokens\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode_as_pieces(txt)\n",
    "    \n",
    "    def __sp_encode_as_ids(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Performs encoding of given text using SentencePieceProcesor\n",
    "        :param txt: String to be encoded\n",
    "        :return: List of the subword tokens (ids)\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode_as_ids(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizerHF(Doc2VecVectorizer):\n",
    "    \"\"\"\n",
    "    Class to perform vectorization via Doc2Vec model\n",
    "    leveraging HF's Tokenizer\n",
    "    \"\"\"\n",
    "    def __init__(self, tkzr_path: str, d2v_path: str):\n",
    "        \"\"\"\n",
    "        :param tkzr_path: Path to the HF Tokenizer saved model\n",
    "        :param d2v_path: Path to the Doc2Vec saved model\n",
    "        \"\"\"\n",
    "        super().__init__(tkzr_path, d2v_path)\n",
    "        \n",
    "    def _load_tokenizer_model(self, path: str) -> Tokenizer:\n",
    "        \"\"\"\n",
    "        Function to load a saved HuggingFace tokenizer\n",
    "\n",
    "        :param path: Path containing the tokenizer file\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not check_file_existence(path):\n",
    "            msg = 'HuggingFace tokenizer could no be loaded.'\n",
    "            logging.error(msg)\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        self.tokenizer = Tokenizer.from_file(path)\n",
    "    \n",
    "    def tokenize_df(self, df: pd.DataFrame, code_column: str):\n",
    "        \"\"\"\n",
    "        Performs processing for a DataFrame containing source code\n",
    "        :param df: Pandas DataFrame\n",
    "        :param code_column: Name corresponding to the column containing source code\n",
    "        :return: DataFrame containing the processed code using SentencePiece\n",
    "        \"\"\"\n",
    "        result_df = df[code_column].apply(lambda snippet: self.__encode_string_as_tokens(snippet))\n",
    "        return result_df\n",
    "    \n",
    "    def __encode_string_as_tokens(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Perform tokenization using HF Tokenizer\n",
    "        \n",
    "        :return: List containing obtained tokens\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode(txt).tokens\n",
    "    \n",
    "    def __encode_string_as_ids(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Perform tokenization using HF Tokenizer\n",
    "        \n",
    "        :return: List containing obtained ids (of tokens)\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode(txt).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def configure_dirs(base_path: str, config_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs configuration of directories for storing vectors\n",
    "    :param base_path:\n",
    "    :param config_name:\n",
    "    \n",
    "    :return: Full configuration path\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    base_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = str(datetime.timestamp(now))\n",
    "\n",
    "    full_path = base_path / timestamp \n",
    "    full_path.mkdir(exist_ok=True)\n",
    "    full_path = full_path/ config_name\n",
    "    full_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    return str(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test gensim's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-15 20:40:58,357 : INFO : loading Doc2Vec object from ../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n",
      "2021-04-15 20:40:58,926 : INFO : loading vocabulary recursively from ../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.vocabulary.* with mmap=None\n",
      "2021-04-15 20:40:58,927 : INFO : loading trainables recursively from ../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.trainables.* with mmap=None\n",
      "2021-04-15 20:40:58,928 : INFO : loading wv recursively from ../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.wv.* with mmap=None\n",
      "2021-04-15 20:40:58,928 : INFO : loading docvecs recursively from ../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.* with mmap=None\n",
      "2021-04-15 20:40:58,929 : INFO : loading vectors_docs from ../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.vectors_docs.npy with mmap=None\n",
      "2021-04-15 20:41:13,740 : INFO : loaded ../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n"
     ]
    }
   ],
   "source": [
    "d2v_model = gensim.models.Doc2Vec.load('../../dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Searchnet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df = pd.read_csv(\"/tf/main/dvc-ds4se/code/searchnet/[codesearchnet-java-1597073966.81902].csv\",  header=0, index_col=0, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "      <th>bpe32k</th>\n",
       "      <th>code_len</th>\n",
       "      <th>bpe32_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/internal/observers/...</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>protected final void fastPathOrderedEmit(U val...</td>\n",
       "      <td>['protected', 'final', 'void', 'fastPathOrdere...</td>\n",
       "      <td>Makes sure the fast-path emits in order.\\n@par...</td>\n",
       "      <td>['Makes', 'sure', 'the', 'fast', '-', 'path', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁protected', '▁final', '▁void', '▁fast', 'Pa...</td>\n",
       "      <td>134</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@CheckReturnValue\\n    @NonNull\\n    @Schedule...</td>\n",
       "      <td>['@', 'CheckReturnValue', '@', 'NonNull', '@',...</td>\n",
       "      <td>Mirrors the one ObservableSource in an Iterabl...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...</td>\n",
       "      <td>63</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings(\"unchecked\")\\n    @CheckRetu...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '\"unchecked\"', ...</td>\n",
       "      <td>Mirrors the one ObservableSource in an array o...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings({ \"unchecked\", \"rawtypes\" })...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '{', '\"unchecke...</td>\n",
       "      <td>Concatenates elements of each ObservableSource...</td>\n",
       "      <td>['Concatenates', 'elements', 'of', 'each', 'Ob...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings({ \"unchecked\", \"rawtypes\" })...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '{', '\"unchecke...</td>\n",
       "      <td>Returns an Observable that emits the items emi...</td>\n",
       "      <td>['Returns', 'an', 'Observable', 'that', 'emits...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               repo                                               path  \\\n",
       "0  ReactiveX/RxJava  src/main/java/io/reactivex/internal/observers/...   \n",
       "1  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "2  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "3  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "4  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "1  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "2  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "3  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "4  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "\n",
       "                                                code  \\\n",
       "0  protected final void fastPathOrderedEmit(U val...   \n",
       "1  @CheckReturnValue\\n    @NonNull\\n    @Schedule...   \n",
       "2  @SuppressWarnings(\"unchecked\")\\n    @CheckRetu...   \n",
       "3  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })...   \n",
       "4  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })...   \n",
       "\n",
       "                                         code_tokens  \\\n",
       "0  ['protected', 'final', 'void', 'fastPathOrdere...   \n",
       "1  ['@', 'CheckReturnValue', '@', 'NonNull', '@',...   \n",
       "2  ['@', 'SuppressWarnings', '(', '\"unchecked\"', ...   \n",
       "3  ['@', 'SuppressWarnings', '(', '{', '\"unchecke...   \n",
       "4  ['@', 'SuppressWarnings', '(', '{', '\"unchecke...   \n",
       "\n",
       "                                           docstring  \\\n",
       "0  Makes sure the fast-path emits in order.\\n@par...   \n",
       "1  Mirrors the one ObservableSource in an Iterabl...   \n",
       "2  Mirrors the one ObservableSource in an array o...   \n",
       "3  Concatenates elements of each ObservableSource...   \n",
       "4  Returns an Observable that emits the items emi...   \n",
       "\n",
       "                                    docstring_tokens language partition  \\\n",
       "0  ['Makes', 'sure', 'the', 'fast', '-', 'path', ...     java      test   \n",
       "1  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "2  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "3  ['Concatenates', 'elements', 'of', 'each', 'Ob...     java      test   \n",
       "4  ['Returns', 'an', 'Observable', 'that', 'emits...     java      test   \n",
       "\n",
       "                                              bpe32k  code_len  bpe32_len  \n",
       "0  ['▁protected', '▁final', '▁void', '▁fast', 'Pa...       134        138  \n",
       "1  ['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...        63         71  \n",
       "2  ['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...       107        109  \n",
       "3  ['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...        79         83  \n",
       "4  ['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...        91        112  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples = java_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "      <th>bpe32k</th>\n",
       "      <th>code_len</th>\n",
       "      <th>bpe32_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16751</th>\n",
       "      <td>OpenLiberty/open-liberty</td>\n",
       "      <td>dev/com.ibm.ws.artifact.zip/src/com/ibm/ws/art...</td>\n",
       "      <td>https://github.com/OpenLiberty/open-liberty/bl...</td>\n",
       "      <td>@Trivial\\n    public static Map&lt;String, ZipEnt...</td>\n",
       "      <td>['@', 'Trivial', 'public', 'static', 'Map', '&lt;...</td>\n",
       "      <td>Create a table of entry data using the relativ...</td>\n",
       "      <td>['Create', 'a', 'table', 'of', 'entry', 'data'...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁', '@', 'Trivial', '▁public', '▁static', '▁...</td>\n",
       "      <td>87</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21794</th>\n",
       "      <td>OpenLiberty/open-liberty</td>\n",
       "      <td>dev/com.ibm.ws.monitor/src/com/ibm/ws/monitor/...</td>\n",
       "      <td>https://github.com/OpenLiberty/open-liberty/bl...</td>\n",
       "      <td>public boolean isMonitorable(Class&lt;?&gt; clazz) {...</td>\n",
       "      <td>['public', 'boolean', 'isMonitorable', '(', 'C...</td>\n",
       "      <td>Determine of the specified class can be monito...</td>\n",
       "      <td>['Determine', 'of', 'the', 'specified', 'class...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁boolean', '▁is', 'Monitor', 'abl...</td>\n",
       "      <td>197</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23928</th>\n",
       "      <td>neo4j-contrib/neo4j-apoc-procedures</td>\n",
       "      <td>src/main/java/apoc/algo/CoreGraphAlgorithms.java</td>\n",
       "      <td>https://github.com/neo4j-contrib/neo4j-apoc-pr...</td>\n",
       "      <td>public int[] loadDegrees(String relName, Direc...</td>\n",
       "      <td>['public', 'int', '[', ']', 'loadDegrees', '('...</td>\n",
       "      <td>/*\\nprivate int[] loadDegrees(ReadOperations o...</td>\n",
       "      <td>['/', '*', 'private', 'int', '[]', 'loadDegree...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁int', '[]', '▁load', 'Deg', 'ree...</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22323</th>\n",
       "      <td>isisaddons-legacy/isis-module-publishing</td>\n",
       "      <td>dom/src/main/java/org/isisaddons/module/publis...</td>\n",
       "      <td>https://github.com/isisaddons-legacy/isis-modu...</td>\n",
       "      <td>@Programmatic\\n    @Override\\n    public Objec...</td>\n",
       "      <td>['@', 'Programmatic', '@', 'Override', 'public...</td>\n",
       "      <td>region &gt; serialize (API)</td>\n",
       "      <td>['region', '&gt;', 'serialize', '(', 'API', ')']</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁', '@', 'Pro', 'g', 'rammat', 'ic', '▁', '@...</td>\n",
       "      <td>58</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>reactor/reactor-core</td>\n",
       "      <td>reactor-core/src/main/java/reactor/core/publis...</td>\n",
       "      <td>https://github.com/reactor/reactor-core/blob/d...</td>\n",
       "      <td>public final Flux&lt;T&gt; publishOn(Scheduler sched...</td>\n",
       "      <td>['public', 'final', 'Flux', '&lt;', 'T', '&gt;', 'pu...</td>\n",
       "      <td>Run onNext, onComplete and onError on a suppli...</td>\n",
       "      <td>['Run', 'onNext', 'onComplete', 'and', 'onErro...</td>\n",
       "      <td>java</td>\n",
       "      <td>valid</td>\n",
       "      <td>['▁public', '▁final', '▁F', 'l', 'ux', '&lt;', 'T...</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           repo  \\\n",
       "16751                  OpenLiberty/open-liberty   \n",
       "21794                  OpenLiberty/open-liberty   \n",
       "23928       neo4j-contrib/neo4j-apoc-procedures   \n",
       "22323  isisaddons-legacy/isis-module-publishing   \n",
       "1666                       reactor/reactor-core   \n",
       "\n",
       "                                                    path  \\\n",
       "16751  dev/com.ibm.ws.artifact.zip/src/com/ibm/ws/art...   \n",
       "21794  dev/com.ibm.ws.monitor/src/com/ibm/ws/monitor/...   \n",
       "23928   src/main/java/apoc/algo/CoreGraphAlgorithms.java   \n",
       "22323  dom/src/main/java/org/isisaddons/module/publis...   \n",
       "1666   reactor-core/src/main/java/reactor/core/publis...   \n",
       "\n",
       "                                                     url  \\\n",
       "16751  https://github.com/OpenLiberty/open-liberty/bl...   \n",
       "21794  https://github.com/OpenLiberty/open-liberty/bl...   \n",
       "23928  https://github.com/neo4j-contrib/neo4j-apoc-pr...   \n",
       "22323  https://github.com/isisaddons-legacy/isis-modu...   \n",
       "1666   https://github.com/reactor/reactor-core/blob/d...   \n",
       "\n",
       "                                                    code  \\\n",
       "16751  @Trivial\\n    public static Map<String, ZipEnt...   \n",
       "21794  public boolean isMonitorable(Class<?> clazz) {...   \n",
       "23928  public int[] loadDegrees(String relName, Direc...   \n",
       "22323  @Programmatic\\n    @Override\\n    public Objec...   \n",
       "1666   public final Flux<T> publishOn(Scheduler sched...   \n",
       "\n",
       "                                             code_tokens  \\\n",
       "16751  ['@', 'Trivial', 'public', 'static', 'Map', '<...   \n",
       "21794  ['public', 'boolean', 'isMonitorable', '(', 'C...   \n",
       "23928  ['public', 'int', '[', ']', 'loadDegrees', '('...   \n",
       "22323  ['@', 'Programmatic', '@', 'Override', 'public...   \n",
       "1666   ['public', 'final', 'Flux', '<', 'T', '>', 'pu...   \n",
       "\n",
       "                                               docstring  \\\n",
       "16751  Create a table of entry data using the relativ...   \n",
       "21794  Determine of the specified class can be monito...   \n",
       "23928  /*\\nprivate int[] loadDegrees(ReadOperations o...   \n",
       "22323                           region > serialize (API)   \n",
       "1666   Run onNext, onComplete and onError on a suppli...   \n",
       "\n",
       "                                        docstring_tokens language partition  \\\n",
       "16751  ['Create', 'a', 'table', 'of', 'entry', 'data'...     java     train   \n",
       "21794  ['Determine', 'of', 'the', 'specified', 'class...     java     train   \n",
       "23928  ['/', '*', 'private', 'int', '[]', 'loadDegree...     java     train   \n",
       "22323      ['region', '>', 'serialize', '(', 'API', ')']     java     train   \n",
       "1666   ['Run', 'onNext', 'onComplete', 'and', 'onErro...     java     valid   \n",
       "\n",
       "                                                  bpe32k  code_len  bpe32_len  \n",
       "16751  ['▁', '@', 'Trivial', '▁public', '▁static', '▁...        87         99  \n",
       "21794  ['▁public', '▁boolean', '▁is', 'Monitor', 'abl...       197        224  \n",
       "23928  ['▁public', '▁int', '[]', '▁load', 'Deg', 'ree...        42         57  \n",
       "22323  ['▁', '@', 'Pro', 'g', 'rammat', 'ic', '▁', '@...        58         88  \n",
       "1666   ['▁public', '▁final', '▁F', 'l', 'ux', '<', 'T...        31         40  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16751, 21794, 23928, 22323,  1666, 19402, 28651, 24093,  6367,\n",
       "        2260])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(java_samples.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"bpe32k_path\": \"/tf/main/dvc-ds4se/models/bpe/sentencepiece/deprecated/java_bpe_32k.model\",\n",
    "    \"doc2vec_java_path\": \"/tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\",\n",
    "    \"hf_tokenizer\": \"/tf/main/nbs/tokenizer.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test vectorization with Doc2Vec (based on SentencePiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = configure_dirs('vectors', 'human_trn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-20 21:45:30,750 : INFO : loading Doc2Vec object from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n",
      "2021-05-20 21:45:31,351 : INFO : loading vocabulary recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.vocabulary.* with mmap=None\n",
      "2021-05-20 21:45:31,352 : INFO : loading trainables recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.trainables.* with mmap=None\n",
      "2021-05-20 21:45:31,353 : INFO : loading wv recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.wv.* with mmap=None\n",
      "2021-05-20 21:45:31,354 : INFO : loading docvecs recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.* with mmap=None\n",
      "2021-05-20 21:45:31,354 : INFO : loading vectors_docs from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.vectors_docs.npy with mmap=None\n",
      "2021-05-20 21:45:32,045 : INFO : loaded /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Doc2VecVectorizerSP(params['bpe32k_path'], params[\"doc2vec_java_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = vectorizer.tokenize_df(java_samples, 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples['bpe32k-tokens'] = tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, vectors = vectorizer.infer_d2v(java_samples, 'bpe32k-tokens', config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test vectorization with Doc2Vec (based on HuggingFace's Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-20 21:47:31,681 : INFO : loading Doc2Vec object from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n",
      "2021-05-20 21:47:32,241 : INFO : loading vocabulary recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.vocabulary.* with mmap=None\n",
      "2021-05-20 21:47:32,242 : INFO : loading trainables recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.trainables.* with mmap=None\n",
      "2021-05-20 21:47:32,243 : INFO : loading wv recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.wv.* with mmap=None\n",
      "2021-05-20 21:47:32,244 : INFO : loading docvecs recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.* with mmap=None\n",
      "2021-05-20 21:47:32,245 : INFO : loading vectors_docs from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.vectors_docs.npy with mmap=None\n",
      "2021-05-20 21:47:34,313 : INFO : loaded /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n"
     ]
    }
   ],
   "source": [
    "hf_vectorizer = Doc2VecVectorizerHF(params['hf_tokenizer'], params[\"doc2vec_java_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = hf_vectorizer.tokenize_df(java_samples, 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples['bpe-hf-tokens'] = tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, vectors = hf_vectorizer.infer_d2v(java_samples, 'bpe-hf-tokens', config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export code as module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
