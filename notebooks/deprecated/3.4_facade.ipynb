{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp facade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import random\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "import sentencepiece as sp\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from ds4se.mining.unsupervised.traceability.eval import *\n",
    "# import ds4se.mining.unsupervised.traceability.approach.cisco as cisco\n",
    "from enum import Enum, unique, auto\n",
    "from ds4se.exp import i\n",
    "import os\n",
    "import pkg_resources\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@unique\n",
    "class LinkType(Enum):\n",
    "    req2tc = auto()\n",
    "    req2src = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for data analysis part of library\n",
    "\n",
    "#export\n",
    "\"\"\"\n",
    "Helper functions to extract all entries in the dataframe, which will be contents of either source or target artifacts. Contents are stored\n",
    "in the column named \"contents\". This helper function retrive strings stored in this columns and stored them in a list.\n",
    ":param df: dataframe of content that need to be processed\n",
    ":param spm: sentence piece processor that will process the dataframe\n",
    ":returns: documents lists of all entries in the dataframe \n",
    "\"\"\"\n",
    "def get_docs(df, spm):\n",
    "    docs = []\n",
    "    for fn in df[\"contents\"]:\n",
    "        docs += spm.EncodeAsPieces(fn)\n",
    "    return docs\n",
    "\n",
    "#export\n",
    "\"\"\"\n",
    "Helper functions to retrive counter object for all tokens in a dataframe. \n",
    ":param docs: doc list of contents that we need to extract information on tokens and their frequency\n",
    ":returns: documents counter of token and corresponding occurrence. \n",
    "\"\"\"\n",
    "def get_counters(docs):\n",
    "    #param doc list of contents that need info on tokens\n",
    "    #return the counters object of tokens   \n",
    "    doc_cnts = []\n",
    "    cnt = Counter()\n",
    "    for tok in docs:\n",
    "        cnt[tok] += 1 \n",
    "        doc_cnts.append(cnt)\n",
    "    return doc_cnts\n",
    "\n",
    "#export\n",
    "\"\"\"\n",
    "Helper functions that get a dataframe and generate a Counter object for all of them tokens it contains, \n",
    "as well as their frequency. It load sentence piece model and call two helper function to calculate token freqnency \n",
    ":param artifacts_df: doc list of contents that we need to extract information on tokens and their frequency\n",
    ":returns: counter object with token and term occurrence. \n",
    "\"\"\"\n",
    "def preprocess(artifacts_df):\n",
    "    spm = sp.SentencePieceProcessor()\n",
    "    bpe_model_path = pkg_resources.resource_filename('ds4se', 'model/test.model')\n",
    "    spm.Load(bpe_model_path)\n",
    "    docs = get_docs(artifacts_df,spm)\n",
    "    cnts = get_counters(docs)\n",
    "    return cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate traceability of two strings of artifacts with given techniques. Method will group two strings as a pair and feed into\n",
    "the traceability model to get result. If users switch the order of source and target, result should be very similar. \n",
    ":param source: a string of the entire source file  \n",
    ":param target: a string of the entire target file \n",
    ":param technique: what tecchnique to use to calculate traceability\n",
    ":param word2vec_metric: optional, what metric to use to calculate traceability. Only for word2vec\n",
    ":returns: a tuple: (distance, similarity), similarity is the traceability value\n",
    "\"\"\"\n",
    "def TraceLinkValue(source, target, technique, word2vec_metric = \"WMD\"):\n",
    "    \n",
    "    dummy_path = pkg_resources.resource_filename('ds4se', 'model/val.csv')\n",
    "\n",
    "    \n",
    "    value1 = random.randint(0,100)/100\n",
    "    value2 = random.randint(0,100)/100\n",
    "    value = (value1, value2)\n",
    "\n",
    "    \n",
    "    if (technique == \"VSM\"):\n",
    "        pass\n",
    "    if (technique == \"LDA\"):\n",
    "        pass\n",
    "    if (technique == \"orthogonal\"):\n",
    "        pass\n",
    "    if (technique == \"LSA\"):\n",
    "        pass\n",
    "    if (technique == \"JS\"):\n",
    "        pass\n",
    "    if (technique == \"word2vec\"):\n",
    "        model_path = pkg_resources.resource_filename('ds4se', 'model/word2vec_libest.model')\n",
    "        parameter = {\n",
    "            \"vectorizationType\": VectorizationType.word2vec,\n",
    "            \"linkType\": LinkType.req2tc,\n",
    "            \"system\": 'libest',\n",
    "            \"path_to_trained_model\": model_path,\n",
    "            \"source_path\": dummy_path,\n",
    "            \"target_path\": dummy_path,\n",
    "            \"system_path\": dummy_path,\n",
    "            \"saving_path\": 'test_data/',\n",
    "            \"names\": ['Source','Target','Linked?']\n",
    "        }\n",
    "        \n",
    "        source_df = pd.DataFrame({ \"ids\": [\"source\"],  \"text\":[source]})\n",
    "        target_df = pd.DataFrame({ \"ids\": [\"target\"],  \"text\":[target]})\n",
    "        word2vec = Word2VecSeqVect(parameter)\n",
    "        word2vec.df_source = source_df\n",
    "        word2vec.df_target = target_df\n",
    "        links = [(source_df[\"ids\"][0],target_df[\"ids\"][0])]\n",
    "        if (word2vec_metric == \"SCM\"):\n",
    "            computeDistanceMetric = word2vec.computeDistanceMetric(links, metric_list = [DistanceMetric.SCM])\n",
    "        else:\n",
    "            computeDistanceMetric = word2vec.computeDistanceMetric(links, metric_list = [DistanceMetric.WMD])\n",
    "        value = (computeDistanceMetric[0][0][2],computeDistanceMetric[0][0][3])    \n",
    "        \n",
    "    if (technique == \"doc2vec\"):\n",
    "        model_path = pkg_resources.resource_filename('ds4se', 'model/doc2vec_libest.model')\n",
    "        parameter = {\n",
    "            \"vectorizationType\": VectorizationType.doc2vec,\n",
    "            \"linkType\": LinkType.req2tc,\n",
    "            \"system\": 'libest',\n",
    "            \"path_to_trained_model\": model_path,\n",
    "            \"source_path\": dummy_path,\n",
    "            \"target_path\": dummy_path,\n",
    "            \"system_path\": dummy_path,\n",
    "            \"saving_path\": 'test_data/',\n",
    "            \"names\": ['Source','Target','Linked?']\n",
    "        }\n",
    "        \n",
    "        source_df = pd.DataFrame({ \"ids\": [\"source\"],  \"text\":[source]})\n",
    "        target_df = pd.DataFrame({ \"ids\": [\"target\"],  \"text\":[target]})\n",
    "        doc2vec = Doc2VecSeqVect(params = parameter)\n",
    "        doc2vec.df_source = source_df\n",
    "        doc2vec.df_target = target_df\n",
    "        links = [(source_df[\"ids\"][0],target_df[\"ids\"][0])]\n",
    "        doc2vec.InferDoc2Vec(steps=200)\n",
    "        table = doc2vec.computeDistanceMetric( links, metric_list = [DistanceMetric.EUC] )\n",
    "        value = (table[0][0][2], table[0][0][3])\n",
    "        #The bottom is here for reference -- may not need it\n",
    "#         doc2vec.SaveLinks()\n",
    "#         #will most likely need to change this part need to change this part to a different path\n",
    "#         path_to_ground_truth = '/tf/main/benchmarking/traceability/testbeds/groundtruth/english/[libest-ground-req-to-tc].txt'\n",
    "#         doc2vec.MatchWithGroundTruth(path_to_ground_truth)\n",
    "#         doc2vec.SaveLinks(grtruth = True)\n",
    "#         #TODO find logic to LoadLink properly and display what is needed\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 14:56:18,823 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-11-08 14:56:18,838 : INFO : built Dictionary(1815 unique tokens: ['@return', 'Converts', 'The', 'a', 'and']...) from 153 documents (total 5769 corpus positions)\n",
      "2020-11-08 14:56:18,840 : INFO : loading Doc2Vec object from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\doc2vec_libest.model\n",
      "2020-11-08 14:56:18,866 : INFO : loading vocabulary recursively from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\doc2vec_libest.model.vocabulary.* with mmap=None\n",
      "2020-11-08 14:56:18,869 : INFO : loading trainables recursively from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\doc2vec_libest.model.trainables.* with mmap=None\n",
      "2020-11-08 14:56:18,870 : INFO : loading wv recursively from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\doc2vec_libest.model.wv.* with mmap=None\n",
      "2020-11-08 14:56:18,871 : INFO : loading docvecs recursively from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\doc2vec_libest.model.docvecs.* with mmap=None\n",
      "2020-11-08 14:56:18,873 : INFO : loaded c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\doc2vec_libest.model\n",
      "2020-11-08 14:56:18,881 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2020-11-08 14:56:18,978 : INFO : Infer Doc2Vec on Source and Target Complete\n",
      "2020-11-08 14:56:18,984 : INFO : Computed distances or similarities ('source', 'target')[[31.28768539428711, 0.03097156045062732]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31.28768539428711, 0.03097156045062732)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = open('test_data/RQ11.txt', 'r').read()\n",
    "str2 = open('test_data/us4020.c', 'r').read()\n",
    "TraceLinkValue(str1,str2,\"doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = (0.5401013460499512, 0.6493079189657213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 14:56:21,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-11-08 14:56:21,224 : INFO : built Dictionary(1815 unique tokens: ['@return', 'Converts', 'The', 'a', 'and']...) from 153 documents (total 5769 corpus positions)\n",
      "2020-11-08 14:56:21,225 : INFO : loading Word2Vec object from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\word2vec_libest.model\n",
      "2020-11-08 14:56:21,493 : INFO : loading wv recursively from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\word2vec_libest.model.wv.* with mmap=None\n",
      "2020-11-08 14:56:21,493 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-11-08 14:56:21,494 : INFO : loading vocabulary recursively from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\word2vec_libest.model.vocabulary.* with mmap=None\n",
      "2020-11-08 14:56:21,495 : INFO : loading trainables recursively from c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\word2vec_libest.model.trainables.* with mmap=None\n",
      "2020-11-08 14:56:21,495 : INFO : setting ignored attribute cum_table to None\n",
      "2020-11-08 14:56:21,496 : INFO : loaded c:\\users\\admin\\desktop\\fall2020\\software engineering\\project\\github desktop\\ds4se\\ds4se\\model\\word2vec_libest.model\n",
      "2020-11-08 14:56:21,507 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-11-08 14:56:21,511 : INFO : constructing a sparse term similarity matrix using <gensim.models.keyedvectors.WordEmbeddingSimilarityIndex object at 0x0000025C57A20D00>\n",
      "2020-11-08 14:56:21,512 : INFO : iterating over columns in dictionary order\n",
      "2020-11-08 14:56:21,519 : INFO : PROGRESS: at 0.06% columns (1 / 1815, 0.055096% density, 0.055096% projected density)\n",
      "2020-11-08 14:56:21,707 : INFO : PROGRESS: at 55.15% columns (1001 / 1815, 0.140033% density, 0.209102% projected density)\n",
      "2020-11-08 14:56:21,808 : INFO : constructed a sparse term similarity matrix with 0.173668% density\n",
      "2020-11-08 14:56:21,824 : INFO : Removed 3 and 3 OOV words from document 1 and 2 (respectively).\n",
      "2020-11-08 14:56:21,827 : INFO : At least one of the documents had no words that were in the vocabulary. Aborting (returning inf).\n",
      "2020-11-08 14:56:21,828 : INFO : Computed distances or similarities ('source', 'target')[[inf, 0.0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FacadeTest\n",
    "#Test case for proto TLV\n",
    "\n",
    "#Prototype should print a value between 0 or 1. Input values aren't used\n",
    "testTLV = TraceLinkValue(\"a a b\", \"a b c\", \"word2vec\")\n",
    "isinstance(testTLV,tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate the number of documents of two artifacts. Since in each dataframe, each document takes exactly one row, just counting the number \n",
    "of rows in each dataframe will gives the result. \n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a list containing the number of documents in both source and target artifacts and the difference between the size of two artifacts\n",
    "\"\"\"\n",
    "def NumDoc(source, target):\n",
    "    source_doc = source.shape[0]\n",
    "    target_doc = target.shape[0]\n",
    "    difference = source_doc - target_doc\n",
    "    return [source_doc, target_doc, difference, -difference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 0, 0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example use\n",
    "d = {'contents': ['this is a content of the source file', 'hello world', 'this is the content of another source file that need to be processed']}\n",
    "df = pd.DataFrame(data=d)\n",
    "target = {'contents': ['this is a content of the target file', 'i like banana', 'this is the content of another target file that need to be processed']}\n",
    "df2 = pd.DataFrame(data=target)\n",
    "NumDoc(df, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FacadeTest\n",
    "#Test Case for Proto NumDoc\n",
    "\n",
    "#Prototype should print an array based on the randomly generated numbers. Input values aren't used.\n",
    "datas1 = [\"Form does not differ from the void, and the void does not differ from the form.\"]\n",
    "datas2 = [\"Form is the void, and the void is form.\"]\n",
    "df1 = pd.DataFrame(data=datas1,columns=['contents'] )\n",
    "df2 = pd.DataFrame(data=datas2,columns=['contents'])\n",
    "testND = NumDoc(df1,df2)\n",
    "assert(isinstance(testND, list))\n",
    "assert(testND[0] == 1)\n",
    "assert(testND[1] == 1)\n",
    "assert(testND[2] == 0)\n",
    "assert(testND[3] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate the number of vocabulary in each of the two artifacts. This method calls the helper function that uses a bpe model.The helper\n",
    "function returns a counter object of all tokens and their occurrence, the length of the list is the vocab size.\n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a list containing the vocabulary size of both source and target artifacts and the difference between the vocabulary sizes two artifacts\n",
    "\"\"\"\n",
    "def VocabSize(source, target):\n",
    "    #param source a string of the entire source file  \n",
    "    #param target a string of the entire target file \n",
    "    #return a list containing the the difference between the two files in terms of vocab\n",
    "    source_list = preprocess(source)\n",
    "    target_list = preprocess(target)\n",
    "    source_size = len(source_list[0])\n",
    "    target_size = len(target_list[0])\n",
    "    difference = source_size - target_size\n",
    "    return [source_size, target_size, difference, -difference]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 18, -1, 1]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example use\n",
    "d = {'contents': ['this is a content of the source file', 'hello world', 'this is the content of another source file that need to be processed']}\n",
    "df = pd.DataFrame(data=d)\n",
    "target = {'contents': ['this is a content of the target file', 'i like banana', 'this is the content of another target file that need to be processed']}\n",
    "df2 = pd.DataFrame(data=target)\n",
    "VocabSize(df, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FacadeTest\n",
    "#Test case for Vocab size\n",
    "datas1 = [\"Form does not differ from the void, and the void does not differ from the form.\"]\n",
    "datas2 = [\"Form is the void, and the void is form.\"]\n",
    "df1 = pd.DataFrame(data=datas1,columns=['contents'] )\n",
    "df2 = pd.DataFrame(data=datas2,columns=['contents'])\n",
    "#Prototype should return an array based on random number values. Inputs aren't used.\n",
    "testVS = VocabSize(df1,df2)\n",
    "assert(isinstance(testVS, list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate the average number of token per document in each of the two artifacts. This method calls the helper function that uses a bpe model.The helper\n",
    "function returns a counter object of all tokens and their occurrence, sum up all the occurrence is the total number of tokens across entire actifact. \n",
    "Divide that number by the number of documents will get the result we need. \n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a list containing the average number of token per document in both source and target artifacts and the difference between these two. \n",
    "\"\"\"\n",
    "def AverageToken(source, target):\n",
    "\n",
    "    #return a list containing the the difference between the two files in terms of tokens\n",
    "    source_doc = source.shape[0]\n",
    "    target_doc = target.shape[0]\n",
    "    \n",
    "    source_list = preprocess(source)\n",
    "    target_list = preprocess(target)\n",
    "    \n",
    "    source_total_token = sum(source_list[0].values())\n",
    "    target_total_token = sum(target_list[0].values())\n",
    "\n",
    "    source_token = source_total_token/source_doc\n",
    "    target_token = target_total_token/target_doc\n",
    "    difference = source_token - target_token\n",
    "    return [source_token, target_token, difference, -difference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.333333333333334, 16.0, -0.6666666666666661, 0.6666666666666661]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example use\n",
    "d = {'contents': ['this is a content of the source file', 'hello world', 'this is the content of another source file that need to be processed']}\n",
    "df = pd.DataFrame(data=d)\n",
    "target = {'contents': ['this is a content of the target file', 'i like banana', 'this is the content of another target file that need to be processed']}\n",
    "df2 = pd.DataFrame(data=target)\n",
    "AverageToken(df,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FacadeTest\n",
    "#Test Case for AverageToken\n",
    "\n",
    "#Prototype should return an array/list. Inputs aren't used\n",
    "testAT = AverageToken(df1,df2)\n",
    "assert(isinstance(testAT, list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate the top 3 most frequent token in one artifacts. This method calls the helper function that uses a bpe model.The helper\n",
    "function returns a counter object of all tokens and their occurrence, get the first three elements will gives us the most frequent\n",
    "token. Divide their occurrence with totle number of tokens to get actual frequency\n",
    "Divide that number by the number of documents will get the result we need. \n",
    ":param artifacts_df: a dataframe of contents that need to be processed\n",
    ":returns: a dictionary of top three most frenquent token with their frenquency\n",
    "\"\"\"\n",
    "def Vocab(artifacts_df):\n",
    "    #Note: we can add a parameter for user to specify the number of most frequent token to return\n",
    "    cnts = preprocess(artifacts_df)\n",
    "    vocab_list = cnts[0].most_common(3)\n",
    "    total = sum(cnts[0].values())\n",
    "    vocab_dict = dict()\n",
    "    vocab_dict[vocab_list[0][0]] = [vocab_list[0][1], vocab_list[0][1]/total]\n",
    "    vocab_dict[vocab_list[1][0]] = [vocab_list[1][1], vocab_list[1][1]/total]\n",
    "    vocab_dict[vocab_list[2][0]] = [vocab_list[2][1], vocab_list[2][1]/total]\n",
    "\n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁': [23, 0.5],\n",
       " 'this': [2, 0.043478260869565216],\n",
       " 'is': [2, 0.043478260869565216]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example use\n",
    "d = {'contents': ['this is a content of the source file', 'hello world', 'this is the content of another source file that need to be processed']}\n",
    "df = pd.DataFrame(data=d)\n",
    "Vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FacadeTest\n",
    "#Test Case for Vocab\n",
    "\n",
    "#Prototype Vocab should return dictionary type. \n",
    "#Will expand to test dictionary values once presets can be generated and tested\n",
    "testVocab = Vocab(df1)\n",
    "\n",
    "assert(isinstance(testVocab,dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #export\n",
    "\"\"\"\n",
    "Calculate the top 3 most frequent token in both source and target artifacts. This method calls the helper function that uses a bpe model \n",
    "with combined dataframe.The helperfunction returns a counter object of all tokens and their occurrence, get the first three elements \n",
    "will gives us the most frequent token. Divide their occurrence with totle number of tokens to get actual frequency. \n",
    "Divide that number by the number of documents will get the result we need. \n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a dictionary of top three most frenquent token with their frenquency\n",
    "\"\"\"\n",
    "def VocabShared(source, target):\n",
    "    df = pd.concat([source, target])\n",
    "    return Vocab(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁': [52, 0.5],\n",
       " 'this': [5, 0.04807692307692308],\n",
       " 'banana': [5, 0.04807692307692308]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example use\n",
    "d = {'contents': ['this is a content of the source file', 'hello world', 'this this is the content of another source file that need to be processed']}\n",
    "df = pd.DataFrame(data=d)\n",
    "target = {'contents': ['this is a content of the target file', 'i like banana banana banana banana banana', 'this is the content of another target file that need to be processed']}\n",
    "df2 = pd.DataFrame(data=target)\n",
    "VocabShared(df, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-295c6e1afca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Prototype should show a dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Test will be expanded to verify frequency verification in two samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtestVocabS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVocabShared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestVocabS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-1610bf2490af>\u001b[0m in \u001b[0;36mVocabShared\u001b[1;34m(source, target)\u001b[0m\n\u001b[0;32m     10\u001b[0m \"\"\"\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mVocabShared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mVocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \"\"\"\n\u001b[1;32m--> 274\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    357\u001b[0m                     \u001b[1;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                 )\n\u001b[1;32m--> 359\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[1;31m# consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "#FacadeTest\n",
    "#Test VocabShared\n",
    "\n",
    "#Prototype should show a dictionary\n",
    "#Test will be expanded to verify frequency verification in two samples\n",
    "testVocabS = VocabShared(\"source\",\"target\")\n",
    "assert(isinstance(testVocabS,dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate the total number of vocabulary size of both soruce and target artifacts. The method first combines two dataframes together\n",
    "and then call help function preprocess to get counter object. The length of resulting object is the total size of vocab. \n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a number indicating the vocabulary size of both soruce and target artifacts\n",
    "\"\"\"\n",
    "def SharedVocabSize(source, target):\n",
    "    df = pd.concat([source, target])\n",
    "    df_counts = preprocess(df)\n",
    "    shared_size = len(df_counts[0])\n",
    "    return shared_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SharedVocabSize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-a8e60179a209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Prototype should return an int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtestSVS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSharedVocabSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSVS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SharedVocabSize' is not defined"
     ]
    }
   ],
   "source": [
    "#FacadeTest\n",
    "#Test Shared vocab size\n",
    "\n",
    "#Prototype should return an int\n",
    "testSVS = SharedVocabSize(\"source\",\"target\")\n",
    "assert(testSVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Dummy Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate mutual information of source and target artifacts, which will be the overlap between two artifacts. \n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a number representing the mutual information of two artifacts.\n",
    "\"\"\"\n",
    "def MutualInformation(source, target):\n",
    "    #param source a string of the entire source file  \n",
    "    #param target a string of the entire target file \n",
    "    #return the mutual information \n",
    "    mutual_information = random.randint(100,200)\n",
    "    return mutual_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FacadeTest\n",
    "#Test Mutual information\n",
    "\n",
    "#Proto mutual information should get an int\n",
    "testMutualInfo = MutualInformation(\"source\",\"target\")\n",
    "assert(testMutualInfo in range(100,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is a content of the source file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is the content of another source file tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is a content of the target file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i like banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is the content of another target file tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            contents\n",
       "0               this is a content of the source file\n",
       "1                                        hello world\n",
       "2  this is the content of another source file tha...\n",
       "0               this is a content of the target file\n",
       "1                                      i like banana\n",
       "2  this is the content of another target file tha..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2 = pd.DataFrame(data=target)\n",
    "i.dit_shannon(preprocess(df)[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "Calculate the cross entropy of soruce and target artifacts. The method first combines two dataframes together\n",
    "and then call the dit_shannon method to calcualte cross entropy with a counter object. \n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a number indicating the vocabulary size of both soruce and target artifacts\n",
    "\"\"\"\n",
    "def CrossEntropy(source, target):\n",
    "    #param source a dataframe of the entire source artifact  \n",
    "    #param target a dataframe of the entire target artifact \n",
    "    #return the entropy\n",
    "    combined = source.append(target)\n",
    "    entropy = i.dit_shannon(preprocess(combined)[0])\n",
    "\n",
    "    return entropy\n",
    "    \n",
    "\n",
    "#     cross_entropy = random.randint(100,200)#looks like it is the msi funciton in the classes for word2vec or doc2vec\n",
    "#     cross_entropy = get_system_entropy_from_df(source, \"col1\",)\n",
    "#     return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-84b80b2051da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Proto cross Entropy should return an int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtestCrossEntropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sauce\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Target\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestCrossEntropy\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-186932b5f56e>\u001b[0m in \u001b[0;36mCrossEntropy\u001b[1;34m(source, target)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#param target a dataframe of the entire target artifact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#return the entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdit_shannon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "#FacadeTest\n",
    "#Test Cross Entropy\n",
    "\n",
    "#Proto cross Entropy should return an int\n",
    "testCrossEntropy = CrossEntropy(\"Sauce\",\"Target\")\n",
    "assert(testCrossEntropy in range(100,200))\n",
    "\n",
    "#Eventually cross entropy will properly implement Entropy calculation and the test will compare a known/predicted entropy\n",
    "# to a calculated value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeArray(text):\n",
    "    print(\"text:\",text)\n",
    "    return np.fromstring(text[1:-1],sep=' ')\n",
    "    \n",
    "#export\n",
    "\"\"\"\n",
    "Calculate KLDivergence of source and target artifacts combined. \n",
    ":param source: a dataframe of the entire source file  \n",
    ":param target: a dataframe of the entire target file \n",
    ":returns: a number representing the divergence of two artifacts.\n",
    "\"\"\"\n",
    "def KLDivergence(source, target):\n",
    "    #param source a string of the entire source file  \n",
    "    #param target a string of the entire target file \n",
    "    #return the divergence  \n",
    "    \n",
    "    #we are going to use the TSNE function since this preforms the divergence\n",
    "    source_df = pd.DataFrame({ \"ids\": [\"source\"],  \"text\":[source]})\n",
    "    target_df = pd.DataFrame({ \"ids\": [\"target\"],  \"text\":[target]})\n",
    "    source_df = source_df[\"text\"].apply(makeArray)\n",
    "    target_ef = target_df[\"text\"].apply(makeArray)\n",
    "    source_df.head()\n",
    "    target_df.head()\n",
    "    divergence = random.randint(100,200)\n",
    "    return divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: source\n",
      "text: target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielquiroga/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#FacadeTest\n",
    "#Test KLDivergence\n",
    "\n",
    "#Proto KLDivegence will return an random int\n",
    "testKLDiver = KLDivergence(\"source\",\"target\")\n",
    "assert(testKLDiver in range(100,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
