{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metrics_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from sklearn import preprocessing\n",
    "import lizard\n",
    "import radon\n",
    "import pprint\n",
    "from radon.raw import analyze\n",
    "from radon.complexity import *\n",
    "from radon.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics_python\n",
    "\n",
    "> This module provides a tool for computing metrics (from static analysis) for python source code using Using <a href=\"https://pypi.org/project/radon/\">radon package <a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <a href=\"https://pypi.org/project/radon/\">radon package <a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def compute_metrics(df_series):\n",
    "    '''\n",
    "    Computes metrics from source code\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    # df: Pandas dataframe containing source code column\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Tuple comprising:\n",
    "    \n",
    "    - Dataframe with computed metrics\n",
    "    - List of records' indices for which metrics could not be computed\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    init_data = {\n",
    "        'sample': [],\n",
    "        'loc':[],\n",
    "        'lloc':[],\n",
    "        'sloc': [],\n",
    "        'comments':[],\n",
    "        'multi': [],\n",
    "        'blank':[],\n",
    "        'single_comments':[],\n",
    "        'h1': [],\n",
    "        'h2': [],\n",
    "        'N1': [],\n",
    "        'N2': [],\n",
    "        'vocabulary': [],\n",
    "        'length': [],\n",
    "        'calculated_length': [],\n",
    "        'volume': [],\n",
    "        'difficulty': [],\n",
    "        'effort': [],\n",
    "        'time': [],\n",
    "        'bugs': [],\n",
    "        'complexity': [],\n",
    "        'maint_idx': [],\n",
    "        'maint_idx_rank': []\n",
    "    }\n",
    "    \n",
    "    # Empty DataFrame\n",
    "    metrics_df = pd.DataFrame(init_data)\n",
    "    \n",
    "    problem_records_indices = []\n",
    "    \n",
    "    for idx, code in df_series.iteritems():\n",
    "        try:\n",
    "            # Computes available metrics if possible\n",
    "            raw = analyze(code)\n",
    "            halstead = h_visit(code)\n",
    "            cc_met = cc_visit(code)\n",
    "            maint_idx = mi_visit(code, False) # False indicates not to consider multi-line strings as comments\n",
    "            maint_idx_rank = mi_rank(maint_idx)\n",
    "\n",
    "            total_complexity = 0\n",
    "\n",
    "            for func in cc_met:\n",
    "                total_complexity += func.complexity\n",
    "\n",
    "            new_row = {\n",
    "                'sample': idx,\n",
    "                'loc': raw.loc,\n",
    "                'lloc': raw.lloc,\n",
    "                'sloc': raw.sloc,\n",
    "                'comments': raw.comments,\n",
    "                'multi': raw.multi,\n",
    "                'blank': raw.blank,\n",
    "                'single_comments': raw.single_comments,\n",
    "                'h1': halstead.total.h1,\n",
    "                'h2': halstead.total.h2,\n",
    "                'N1': halstead.total.N1,\n",
    "                'N2': halstead.total.N2,\n",
    "                'vocabulary': halstead.total.vocabulary,\n",
    "                'length': halstead.total.length,\n",
    "                'calculated_length': halstead.total.calculated_length,\n",
    "                'volume': halstead.total.volume,\n",
    "                'difficulty': halstead.total.difficulty,\n",
    "                'effort': halstead.total.effort,\n",
    "                'time': halstead.total.time,\n",
    "                'bugs': halstead.total.bugs,\n",
    "                'complexity': total_complexity,\n",
    "                'maint_idx': maint_idx,\n",
    "                'maint_idx_rank': maint_idx_rank\n",
    "            }\n",
    "\n",
    "            metrics_df = metrics_df.append(new_row, ignore_index=True)\n",
    "            \n",
    "        except:\n",
    "            problem_records_indices.append(idx)\n",
    "            \n",
    "    if problem_records_indices:\n",
    "        print(f'There was a problem computing metrics for {len(problem_records_indices)} records.')\n",
    "\n",
    "    return metrics_df, problem_records_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class PythonAnalyzer():\n",
    "    \"\"\"\n",
    "    Class aimed to obtain metrics from a dataset of python source code records.\n",
    "    Metrics computation is performed via an open source library.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_metrics_for_df_series(self, df_series):\n",
    "        \"\"\"\n",
    "        Computes metrics (static analysis) for a collection of source code records\n",
    "        \n",
    "        Params:\n",
    "        # df_series: Pandas DF column containing source code records\n",
    "        \n",
    "        Returns:\n",
    "        Tuple comprising\n",
    "        \n",
    "        - Pandas DataFrame with computed metrics\n",
    "        - List of records' indices for which metrics could not be computed\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        return compute_metrics(df_series)\n",
    "        \n",
    "    \n",
    "    def compute_and_save_metrics_for_df(self, df_series, destination_path):\n",
    "        \"\"\"\n",
    "        Computes metrics (static analysis) for a pandas df column (series).\n",
    "        Additionaly, exports metrics results to a csv file located at the specified path\n",
    "        \n",
    "        Params:\n",
    "        # df_series: Pandas DF column containing source code records\n",
    "        # destination_path: string indicating full path (including filename) for the exported file\n",
    "        \n",
    "        Returns:\n",
    "        Tuple comprising\n",
    "        \n",
    "        - Pandas DataFrame with computed metrics\n",
    "        - List of records' indices for which metrics could not be computed\n",
    "        \"\"\"\n",
    "        \n",
    "        metrics_df, error_indices = compute_metrics(df_series)\n",
    "    \n",
    "        metrics_df.to_csv(destination_path)\n",
    "        \n",
    "        return metrics_df, error_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df = pd.read_csv('/tf/data/clean_python.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>code</th>\n",
       "      <th>code_len</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>data_type</th>\n",
       "      <th>method_name</th>\n",
       "      <th>nloc</th>\n",
       "      <th>parameter_count</th>\n",
       "      <th>partition</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>def get_vid_from_url(url):\\n        \"\"\"Extract...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>['def', 'get_vid_from_url', '(', 'url', ')', '...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>src</td>\n",
       "      <td>get_vid_from_url</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>['def', 'sina_xml_to_url_list', '(', 'xml_data...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>src</td>\n",
       "      <td>sina_xml_to_url_list</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37....</td>\n",
       "      <td>30.0</td>\n",
       "      <td>['def', 'makeMimi', '(', 'upid', ')', ':', 'st...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>src</td>\n",
       "      <td>makeMimi</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>def fc2video_download(url, output_dir = '.', m...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>['def', 'fc2video_download', '(', 'url', ',', ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>src</td>\n",
       "      <td>fc2video_download</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>test</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>def dailymotion_download(url, output_dir='.', ...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>['def', 'dailymotion_download', '(', 'url', ',...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>src</td>\n",
       "      <td>dailymotion_download</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>test</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               code  code_len  \\\n",
       "0           0  def get_vid_from_url(url):\\n        \"\"\"Extract...      53.0   \n",
       "1           1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...      52.0   \n",
       "2           2  def makeMimi(upid):\\n    \"\"\"From http://cdn37....      30.0   \n",
       "3           3  def fc2video_download(url, output_dir = '.', m...      66.0   \n",
       "4           4  def dailymotion_download(url, output_dir='.', ...     150.0   \n",
       "\n",
       "                                         code_tokens  cyclomatic_complexity  \\\n",
       "0  ['def', 'get_vid_from_url', '(', 'url', ')', '...                    6.0   \n",
       "1  ['def', 'sina_xml_to_url_list', '(', 'xml_data...                    2.0   \n",
       "2  ['def', 'makeMimi', '(', 'upid', ')', ':', 'st...                    1.0   \n",
       "3  ['def', 'fc2video_download', '(', 'url', ',', ...                    3.0   \n",
       "4  ['def', 'dailymotion_download', '(', 'url', ',...                    6.0   \n",
       "\n",
       "  data_type           method_name  nloc  parameter_count partition  \\\n",
       "0       src      get_vid_from_url   7.0              1.0      test   \n",
       "1       src  sina_xml_to_url_list   7.0              1.0      test   \n",
       "2       src              makeMimi   4.0              1.0      test   \n",
       "3       src     fc2video_download   6.0              5.0      test   \n",
       "4       src  dailymotion_download  17.0              5.0      test   \n",
       "\n",
       "   token_count  \n",
       "0         62.0  \n",
       "1         52.0  \n",
       "2         30.0  \n",
       "3         62.0  \n",
       "4        153.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore DataFrame\n",
    "\n",
    "python_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = python_df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a problem computing metrics for 5 records.\n",
      "Error indices: [67892, 173843, 364457, 364612, 392728]\n",
      "Error records:\n",
      "        Unnamed: 0                                               code  \\\n",
      "67892        15716  def updateRouterStatus(self):\\n        \"\"\"forc...   \n",
      "173843        1667  def connectionLost(self, reason):\\n        \"\"\"...   \n",
      "364457       20103  def _validate_filters_ndb(cls, filters, model_...   \n",
      "364612       20258  def _split_ns_by_scatter(cls,\\n               ...   \n",
      "392728       18374  def orientnii(imfile):\\n    '''Get the orienta...   \n",
      "\n",
      "        code_len                                        code_tokens  \\\n",
      "67892       60.0  ['def', 'updateRouterStatus', '(', 'self', ')'...   \n",
      "173843      76.0  ['def', 'connectionLost', '(', 'self', ',', 'r...   \n",
      "364457      80.0  ['def', '_validate_filters_ndb', '(', 'cls', '...   \n",
      "364612     392.0  ['def', '_split_ns_by_scatter', '(', 'cls', ',...   \n",
      "392728     108.0  ['def', 'orientnii', '(', 'imfile', ')', ':', ...   \n",
      "\n",
      "        cyclomatic_complexity data_type            method_name  nloc  \\\n",
      "67892                     4.0       src     updateRouterStatus  13.0   \n",
      "173843                    3.0       src         connectionLost  12.0   \n",
      "364457                    5.0       src  _validate_filters_ndb  14.0   \n",
      "364612                    1.0       src   _split_ns_by_scatter   6.0   \n",
      "392728                    3.0       src              orientnii  12.0   \n",
      "\n",
      "        parameter_count partition  token_count  \n",
      "67892               1.0     train         60.0  \n",
      "173843              2.0     train         76.0  \n",
      "364457              3.0     train         78.0  \n",
      "364612              6.0     train         15.0  \n",
      "392728              1.0     train        108.0  \n"
     ]
    }
   ],
   "source": [
    "metrics_df, error_indices = compute_metrics(samples['code'])\n",
    "print(f'Error indices: {error_indices}')\n",
    "error_records = samples.loc[error_indices, :]\n",
    "print(f'Error records:\\n{error_records}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PythonAnalyzer in module __main__ object:\n",
      "\n",
      "class PythonAnalyzer(builtins.object)\n",
      " |  Class aimed to obtain metrics from a dataset of python source code records.\n",
      " |  Metrics computation is performed via an open source library.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  compute_and_save_metrics_for_df(self, df_series, destination_path)\n",
      " |      Computes metrics (static analysis) for a pandas df column (series).\n",
      " |      Additionaly, exports metrics results to a csv file located at the specified path\n",
      " |      \n",
      " |      Params:\n",
      " |      # df_series: Pandas DF column containing source code records\n",
      " |      # destination_path: string indicating full path (including filename) for the exported file\n",
      " |      \n",
      " |      Returns:\n",
      " |      Tuple comprising\n",
      " |      \n",
      " |      - Pandas DataFrame with computed metrics\n",
      " |      - List of records' indices for which metrics could not be computed\n",
      " |  \n",
      " |  compute_metrics_for_df_series(self, df_series)\n",
      " |      Computes metrics (static analysis) for a collection of source code records\n",
      " |      \n",
      " |      Params:\n",
      " |      # df_series: Pandas DF column containing source code records\n",
      " |      \n",
      " |      Returns:\n",
      " |      Tuple comprising\n",
      " |      \n",
      " |      - Pandas DataFrame with computed metrics\n",
      " |      - List of records' indices for which metrics could not be computed\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_analyzer = PythonAnalyzer()\n",
    "help(py_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a problem computing metrics for 5 records.\n"
     ]
    }
   ],
   "source": [
    "metrics_df, error_indices = py_analyzer.compute_metrics_for_df_series(samples['code'])\n",
    "\n",
    "samples.loc[error_indices, :]\n",
    "\n",
    "error_records = samples.loc[error_indices, ['code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67892</th>\n",
       "      <td>def updateRouterStatus(self):\\n        \"\"\"forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173843</th>\n",
       "      <td>def connectionLost(self, reason):\\n        \"\"\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364457</th>\n",
       "      <td>def _validate_filters_ndb(cls, filters, model_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364612</th>\n",
       "      <td>def _split_ns_by_scatter(cls,\\n               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392728</th>\n",
       "      <td>def orientnii(imfile):\\n    '''Get the orienta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     code\n",
       "67892   def updateRouterStatus(self):\\n        \"\"\"forc...\n",
       "173843  def connectionLost(self, reason):\\n        \"\"\"...\n",
       "364457  def _validate_filters_ndb(cls, filters, model_...\n",
       "364612  def _split_ns_by_scatter(cls,\\n               ...\n",
       "392728  def orientnii(imfile):\\n    '''Get the orienta..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample', 'loc', 'lloc', 'sloc', 'comments', 'multi', 'blank',\n",
       "       'single_comments', 'h1', 'h2', 'N1', 'N2', 'vocabulary', 'length',\n",
       "       'calculated_length', 'volume', 'difficulty', 'effort', 'time', 'bugs',\n",
       "       'complexity', 'maint_idx', 'maint_idx_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further information can be found at the <a href=\"https://radon.readthedocs.io/en/latest/\"> documentation page </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radon package groups the provided metrics into the following categories:\n",
    "\n",
    "<ul>\n",
    "    <li>Raw metrics</li> \n",
    "    <li>Cyclomatic Complexity (i.e. McCabe’s Complexity)</li>\n",
    "    <li>Halstead metrics</li>\n",
    "    <li>Maintainability Index</li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw metrics\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        loc: Total number of lines of code\n",
    "    </li>\n",
    "    <li>\n",
    "        lloc: The number of logical lines of code. (Each logical line contains exactly one statement)\n",
    "    </li>\n",
    "    <li>\n",
    "        sloc: Number of source lines of code. ()\n",
    "    </li>\n",
    "    <li>\n",
    "        comments: Number of comment lines. (Single comment lines #, multi-line strings are not counted as comments but as strings)\n",
    "    </li>\n",
    "    <li>\n",
    "        multi: Number of lines corresponding to multi-line strings\n",
    "    </li>\n",
    "    <li>\n",
    "        blank: Number of blank lines\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclomatic complexity\n",
    "\n",
    "<ul>\n",
    "    <li>complexity: number of decisions a block of code contains plus 1</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Halstead metrics\n",
    "\n",
    "More detailed info. available at: <a href=\"https://radon.readthedocs.io/en/latest/intro.html#halstead-metrics\">Radon documentation - Halstead metrics</a>\n",
    "<ul>\n",
    "    <li>h1: Number of distinct operators</li>\n",
    "    <li>h2: Number of distintct operands</li>\n",
    "    <li>N1: Total number of operators</li>\n",
    "    <li>N2: Total number of operands</li>\n",
    "    <li>vocabulary</li>\n",
    "    <li>length</li>\n",
    "    <li>calculated_length</li>\n",
    "    <li>volume</li>\n",
    "    <li>difficulty </li>\n",
    "    <li>effort </li>\n",
    "    <li>time</li>\n",
    "    <li>bugs</li>\n",
    "    \n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintainability index\n",
    "\n",
    "Detailed formulation of the calculation can be found at: <a href=\"https://radon.readthedocs.io/en/latest/intro.html#maintainability-index\">Radon documentation about maintainability index</a>\n",
    "\n",
    "<ul>\n",
    "    <li>maint_idx: Maintainability index score</li>\n",
    "    <li>maint_idx_rank: Ranking given the maintainability index score </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0.0_mgmnt.prep.i.ipynb.\n",
      "Converted 0.1_mgmnt.prep.conv.ipynb.\n",
      "Converted 0.3_mgmnt.prep.bpe.ipynb.\n",
      "Converted 0.6_mgmnt.prep.nltk.ipynb.\n",
      "Converted 0.7_metrics_module_python.ipynb.\n",
      "Converted 1.0_exp.i.ipynb.\n",
      "Converted 1.1_exp.info-[inspect].ipynb.\n",
      "Converted 1.1_exp.info.ipynb.\n",
      "Converted 1.2_exp.csnc.ipynb.\n",
      "Converted 1.2_exp.gen.code.ipynb.\n",
      "Converted 1.3_exp.csnc_python.ipynb.\n",
      "Converted 2.0_repr.codebert.ipynb.\n",
      "Converted 2.0_repr.i.ipynb.\n",
      "Converted 2.1_repr.codeberta.ipynb.\n",
      "Converted 2.1_repr.roberta.train.ipynb.\n",
      "Converted 2.2_repr.roberta.eval.ipynb.\n",
      "Converted 2.3_repr.word2vec.train.ipynb.\n",
      "Converted 2.6_repr.word2vec.eval.ipynb.\n",
      "Converted 2.7_repr.distmetrics.ipynb.\n",
      "Converted 2.8_repr.sentence_transformers.ipynb.\n",
      "Converted 3.1_mining.unsupervised.traceability.eda.ipynb.\n",
      "Converted 3.2_mining.unsupervised.eda.traceability.d2v.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "h\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "Converted 3.2_mining.unsupervised.mutual_information.traceability.approach.sacp-w2v.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "h\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "E\n",
      "Converted 3.2_mining.unsupervised.mutual_information.traceability.approach.sacp.w2v.ipynb.\n",
      "Converted 3.2_mutual_information_theory.eval.ipynb.\n",
      "Converted 3.4_facade.ipynb.\n",
      "Converted 4.0_mining.ir.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.d2v.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp-2.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp3.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp4.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp5.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp6.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp7.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp8.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v.ipynb.\n",
      "Converted 6.0_desc.stats.ipynb.\n",
      "Converted 6.0_eval.mining.ir.unsupervised.x2v.ipynb.\n",
      "Converted 6.1_desc.metrics.java.ipynb.\n",
      "Converted 6.1_desc.metrics.main.ipynb.\n",
      "Converted 6.1_desc.metrics.se.ipynb.\n",
      "Converted 6.2_desc.metrics.java.ipynb.\n",
      "Converted 6.2_desc.metrics.main.ipynb.\n",
      "Converted 7.0_inf.i.ipynb.\n",
      "Converted 7.1_inf.bayesian.ipynb.\n",
      "Converted 7.2_inf.causal.ipynb.\n",
      "Converted 7.3_statistical_analysis.ipynb.\n",
      "Converted 8.0_interpretability.i.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
