{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mgmnt.prep.files_mgmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#Logging configuration\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## files_mgmnt\n",
    "\n",
    "> Module to handle loading of data sources (e.g. csv, jsonl) and related files (e.g., np serialized arrays).\n",
    "\n",
    "> @Alvaro May 20th 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _check_file_existence(file_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validates the existence of a file\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    if not path.exists():\n",
    "        logging.error('Provided file cannot be found.')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _check_dir_existence(path: PosixPath):\n",
    "    \"\"\"\n",
    "    Validates the existence of a given directory\n",
    "    \"\"\"\n",
    "    if not path.exists():\n",
    "        msg = \"Provided directory cannot be found.\"\n",
    "        logging.error(msg)\n",
    "        raise Exception(msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_file_name(full_dir: str):\n",
    "    \"\"\"\n",
    "    Retrieves the filename of a path\n",
    "    \"\"\"\n",
    "    path = Path(full_dir)\n",
    "    return Path(path.name).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_files_list(directory: str, file_extension: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of files (with a specific extension) within a directory.\n",
    "    :param directory: Directory to extract list of files\n",
    "    :param file_extension: File extension of files to include in the list\n",
    "    \n",
    "    :return: List of files within the directoy with the provided extension\n",
    "    \"\"\"\n",
    "    path = Path(directory)\n",
    "    _check_dir_existence(path)\n",
    "    \n",
    "    return list(path.glob(f'**/*.{file_extension}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True) \n",
    "                      for f in file_list], sort=False)\n",
    "\n",
    "def jsonl_to_dataframe(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets a DataFrame from a jsonl file\n",
    "    :param file_path: Location of the jsonl file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    _check_file_existence(file_path)\n",
    "    return pd.read_json(file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def csv_to_dataframe(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Gets a DataFrame from a csv file\"\"\"\n",
    "    \n",
    "    _check_file_existence(file_path)\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def load_np_vectors(path: str) -> np.array:\n",
    "    \"\"\"\n",
    "    :param path: Location of the .npy files to be loaded\n",
    "    \n",
    "    :return: Np array corresponding to the loaded vectors\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        msg = \"Vectors could not be found\"\n",
    "        logging.error(msg)\n",
    "        raise Exception(msg)\n",
    "    return np.load(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_vector_paths_4_sample_set(set_name: str, base_path: str) -> List[PosixPath]:\n",
    "    \"\"\"\n",
    "    Gets the files for a given directory containing sample set\n",
    "    :param set_name: Str indicating the name of the directory for a given set of samples\n",
    "    :param base_path: Str indicating the location directory of samples\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    vectors_path = f\"{base_path}/{set_name}\"\n",
    "    path = Path(vectors_path)\n",
    "    \n",
    "    # TODO: Validate existence of directory\n",
    "    \n",
    "    # Iterate over all the samples for a set\n",
    "    for sample_directory in path.iterdir():\n",
    "        vectors_path = list(sample_directory.rglob('*-ft_vecs.npy'))\n",
    "        if len(vectors_path) == 0:\n",
    "            logging.warning(f\"Could not load vectors for sample {str(directory)}\")\n",
    "            continue\n",
    "            \n",
    "        paths.append(vectors_path[0])\n",
    "        \n",
    "    return paths   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0.1_mgmnt.prep.ipynb.\n",
      "Converted 0.2_mgmnt.prep.files_mgmnt.ipynb.\n",
      "Converted 0.3_mgmnt.prep.bpe_tokenization.ipynb.\n",
      "Converted 0.4_mgmnt.prep.tokenization_counting.ipynb.\n",
      "Converted 1.1_exp.info.ipynb.\n",
      "Converted 1.2_exp.desc.metrics.java.ipynb.\n",
      "Converted 1.4_exp.metrics_python.ipynb.\n",
      "Converted 1.5_exp.metrics_java.ipynb.\n",
      "Converted 2.0_repr.codebert.ipynb.\n",
      "Converted 2.0_repr.i.ipynb.\n",
      "Converted 2.1_repr.codeberta.ipynb.\n",
      "Converted 2.1_repr.roberta.train.ipynb.\n",
      "Converted 2.2_repr.roberta.eval.ipynb.\n",
      "Converted 2.3_repr.word2vec.train.ipynb.\n",
      "Converted 2.6_repr.word2vec.eval.ipynb.\n",
      "Converted 2.7_repr.distmetrics.ipynb.\n",
      "Converted 2.8_repr.sentence_transformers.ipynb.\n",
      "Converted 3.1_traceability.unsupervised.eda.ipynb.\n",
      "Converted 3.2_traceability.unsupervised.approach.d2v.ipynb.\n",
      "Converted 3.2_traceability.unsupervised.approach.w2v.ipynb.\n",
      "Converted 4.0_infoxplainer.ir.ipynb.\n",
      "Converted 4.1_infoxplainer.ir.unsupervised.d2v.ipynb.\n",
      "Converted 4.2_infoxplainer.ir.unsupervised.w2v.ipynb.\n",
      "Converted 4.3_infoxplainer.ir.eval.x2v.ipynb.\n",
      "Converted 4.4_infoxplainer.causality.eval.traceability.ipynb.\n",
      "Converted 4.5_infoxplainer.description.eval.traceability.ipynb.\n",
      "Converted 4.6_infoxplainer.prediction.eval.traceability.ipynb.\n",
      "Converted 5.0_utils.clusterization.ipynb.\n",
      "Converted 5.1_utils.visualization.ipynb.\n",
      "Converted 5.2_utils.distances.ipynb.\n",
      "Converted 8.1_codexplainer.error_checker.ipynb.\n",
      "Converted 8.4_codexplainer.metrics_example.ipynb.\n",
      "Converted 8.5_codexplainer.d2v_vectorization.ipynb.\n",
      "Converted 8.6_codexplainer.prototypes_criticisms.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
