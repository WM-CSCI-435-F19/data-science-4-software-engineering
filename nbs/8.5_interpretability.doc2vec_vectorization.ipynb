{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp interpretability.d2v_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d2v_vectorization\n",
    "\n",
    "> Use doc2vec models to get distributed representation (embedding vectors) for source code\n",
    "\n",
    "> @Alvaro 15 April 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "Doc2Vec model is not trained, just loaded and used through gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def check_file_existence(path):\n",
    "    if not os.path.exists(path):\n",
    "        logging.error('Provided file cannot be found.')\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def configure_dirs(base_path: str, config_name: str, dataset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs configuration of directories for storing vectors\n",
    "    :param base_path:\n",
    "    :param config_name:\n",
    "    :param dataset_name:\n",
    "    \n",
    "    :return: Full configuration path\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    base_path.mkdir(exist_ok=True)\n",
    "\n",
    "    full_path = base_path / config_name\n",
    "    full_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    full_path = full_path / dataset_name\n",
    "    full_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    return str(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer class is defined abstract in order to provide alternatives for tokenization (SentencePiece and HuggingFace's Tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizer(ABC):\n",
    "    def __init__(self, tkzr_path:str, d2v_path: str):\n",
    "        \"\"\"\n",
    "        Default constructor for Vectorizer class\n",
    "        \"\"\"\n",
    "        self.tkzr_path = tkzr_path\n",
    "        self.d2v_path = d2v_path\n",
    "        \n",
    "        self._load_tokenizer_model(self.tkzr_path)\n",
    "        self._load_doc2vec_model(d2v_path)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def tokenize_df(self, df: pd.DataFrame, code_column: str):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _load_tokenizer_model(self, model_path: str):\n",
    "        pass\n",
    "    \n",
    "    def _load_doc2vec_model(self, model_path: str):\n",
    "        \"\"\"\n",
    "        :param model_path: Path to the model file\n",
    "        :return: Gensim Doc2Vec model (corresponding to the loaded model)\n",
    "        \"\"\"\n",
    "        if not check_file_existence(model_path):\n",
    "            msg = 'Doc2vec model could no be loaded'\n",
    "            logging.error('Doc2vec model could no be loaded')\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        model = gensim.models.Doc2Vec.load(model_path)\n",
    "        self.d2v_model = model    \n",
    "        \n",
    "    def infer_d2v(self, df: pd.DataFrame, tokenized_column: str, out_path: str,\n",
    "                  config_name: str, sample_set_name: str, steps: int=200) -> tuple:\n",
    "        \"\"\"\n",
    "        Performs vectorization via Doc2Vec model \n",
    "        :param df: Pandas DataFrame containing source code\n",
    "        :param tokenized_column: Column name of the column corresponding to source code tokenized\n",
    "                                 with the appropriate implementation\n",
    "        :param out_path: String indicating the base location for storing vectors\n",
    "        :param config_name: String indicating the model from which the samples came from\n",
    "        :param sample_set_name: String indicating the base name for identifying the set of\n",
    "                                 samples being processed\n",
    "        :param steps: Steps for the doc2vec infere\n",
    "        :return: Tuple containing (idx of the input DF, obtained vectors)\n",
    "        \"\"\"\n",
    "        df_inferred = df.copy()\n",
    "        \n",
    "        inferred_vecs = np.array([self.d2v_model.infer_vector(tok_snippet, steps=200) \\\n",
    "                                  for tok_snippet in df[tokenized_column].values])\n",
    "        \n",
    "        indices = np.array(df.index)\n",
    "        \n",
    "        dest_path = configure_dirs(out_path, config_name, sample_set_name)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        ts = str(datetime.timestamp(now))\n",
    "        \n",
    "        file_name = f\"{dest_path}/{self.tok_name}-{ts}\"\n",
    "        \n",
    "        np.save(f\"{file_name}-idx\", indices)\n",
    "        np.save(f\"{file_name}-ft_vecs\", inferred_vecs)\n",
    "        \n",
    "        return indices, inferred_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizerSP(Doc2VecVectorizer):\n",
    "    \"\"\"\n",
    "    Class to perform vectorization via Doc2Vec model\n",
    "    leveraging SentencePiece to tokenizer sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, sp_path: str, d2v_path: str):\n",
    "        \"\"\"\n",
    "        :param sp_path: Path to the SentencePiece saved model\n",
    "        :param d2v_path: Path to the Doc2Vec saved model\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(sp_path, d2v_path)\n",
    "        self.tok_name = \"sp\"\n",
    "    \n",
    "    def _load_tokenizer_model(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Loads the sentence piece model stored in the specified path \n",
    "        :param model_path: Path to the model file\n",
    "        :return: SentencePieceProcessor object (corresponding to loaded model)\n",
    "        \"\"\"\n",
    "        if not check_file_existence(model_path):\n",
    "            msg = 'Sentence piece model could no be loaded'\n",
    "            logging.error(msg)\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        sp_processor = spm.SentencePieceProcessor()\n",
    "        sp_processor.load(model_path)\n",
    "        self.tokenizer = sp_processor\n",
    "        \n",
    "    def tokenize_df(self, df: pd.DataFrame, code_column: str):\n",
    "        \"\"\"\n",
    "        Performs processing for a DataFrame containing source code\n",
    "        :param df: Pandas DataFrame\n",
    "        :param code_column: Name corresponding to the column containing source code\n",
    "        :return: DataFrame containing the processed code using SentencePiece\n",
    "        \"\"\"\n",
    "        result_df = df[code_column].apply(lambda snippet: self.__sp_encode_as_pieces(snippet))\n",
    "        return result_df\n",
    "    \n",
    "    def __sp_encode_as_pieces(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Performs tokenization of given text using SentencePieceProcesor\n",
    "        :param txt: String to be encoded (tokenized)\n",
    "        :return: List of the subword tokens\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode_as_pieces(txt)\n",
    "    \n",
    "    def __sp_encode_as_ids(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Performs encoding of given text using SentencePieceProcesor\n",
    "        :param txt: String to be encoded\n",
    "        :return: List of the subword tokens (ids)\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode_as_ids(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizerHF(Doc2VecVectorizer):\n",
    "    \"\"\"\n",
    "    Class to perform vectorization via Doc2Vec model\n",
    "    leveraging HF's Tokenizer\n",
    "    \"\"\"\n",
    "    def __init__(self, tkzr_path: str, d2v_path: str):\n",
    "        \"\"\"\n",
    "        :param tkzr_path: Path to the HF Tokenizer saved model\n",
    "        :param d2v_path: Path to the Doc2Vec saved model\n",
    "        \"\"\"\n",
    "        super().__init__(tkzr_path, d2v_path)\n",
    "        self.tok_name = \"hf\"\n",
    "        \n",
    "    def _load_tokenizer_model(self, path: str) -> Tokenizer:\n",
    "        \"\"\"\n",
    "        Function to load a saved HuggingFace tokenizer\n",
    "\n",
    "        :param path: Path containing the tokenizer file\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not check_file_existence(path):\n",
    "            msg = 'HuggingFace tokenizer could no be loaded.'\n",
    "            logging.error(msg)\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        self.tokenizer = Tokenizer.from_file(path)\n",
    "    \n",
    "    def tokenize_df(self, df: pd.DataFrame, code_column: str):\n",
    "        \"\"\"\n",
    "        Performs processing for a DataFrame containing source code\n",
    "        :param df: Pandas DataFrame\n",
    "        :param code_column: Name corresponding to the column containing source code\n",
    "        :return: DataFrame containing the processed code using SentencePiece\n",
    "        \"\"\"\n",
    "        result_df = df[code_column].apply(lambda snippet: self.__encode_string_as_tokens(snippet))\n",
    "        return result_df\n",
    "    \n",
    "    def __encode_string_as_tokens(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Perform tokenization using HF Tokenizer\n",
    "        \n",
    "        :return: List containing obtained tokens\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode(txt).tokens\n",
    "    \n",
    "    def __encode_string_as_ids(self, txt: str) -> list:\n",
    "        \"\"\"\n",
    "        Perform tokenization using HF Tokenizer\n",
    "        \n",
    "        :return: List containing obtained ids (of tokens)\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode(txt).ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Searchnet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df = pd.read_csv(\"/tf/main/dvc-ds4se/code/searchnet/[codesearchnet-java-1597073966.81902].csv\",  header=0, index_col=0, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "      <th>bpe32k</th>\n",
       "      <th>code_len</th>\n",
       "      <th>bpe32_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/internal/observers/...</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>protected final void fastPathOrderedEmit(U val...</td>\n",
       "      <td>['protected', 'final', 'void', 'fastPathOrdere...</td>\n",
       "      <td>Makes sure the fast-path emits in order.\\n@par...</td>\n",
       "      <td>['Makes', 'sure', 'the', 'fast', '-', 'path', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁protected', '▁final', '▁void', '▁fast', 'Pa...</td>\n",
       "      <td>134</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@CheckReturnValue\\n    @NonNull\\n    @Schedule...</td>\n",
       "      <td>['@', 'CheckReturnValue', '@', 'NonNull', '@',...</td>\n",
       "      <td>Mirrors the one ObservableSource in an Iterabl...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...</td>\n",
       "      <td>63</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings(\"unchecked\")\\n    @CheckRetu...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '\"unchecked\"', ...</td>\n",
       "      <td>Mirrors the one ObservableSource in an array o...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings({ \"unchecked\", \"rawtypes\" })...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '{', '\"unchecke...</td>\n",
       "      <td>Concatenates elements of each ObservableSource...</td>\n",
       "      <td>['Concatenates', 'elements', 'of', 'each', 'Ob...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings({ \"unchecked\", \"rawtypes\" })...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '{', '\"unchecke...</td>\n",
       "      <td>Returns an Observable that emits the items emi...</td>\n",
       "      <td>['Returns', 'an', 'Observable', 'that', 'emits...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               repo                                               path  \\\n",
       "0  ReactiveX/RxJava  src/main/java/io/reactivex/internal/observers/...   \n",
       "1  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "2  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "3  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "4  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "1  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "2  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "3  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "4  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "\n",
       "                                                code  \\\n",
       "0  protected final void fastPathOrderedEmit(U val...   \n",
       "1  @CheckReturnValue\\n    @NonNull\\n    @Schedule...   \n",
       "2  @SuppressWarnings(\"unchecked\")\\n    @CheckRetu...   \n",
       "3  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })...   \n",
       "4  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })...   \n",
       "\n",
       "                                         code_tokens  \\\n",
       "0  ['protected', 'final', 'void', 'fastPathOrdere...   \n",
       "1  ['@', 'CheckReturnValue', '@', 'NonNull', '@',...   \n",
       "2  ['@', 'SuppressWarnings', '(', '\"unchecked\"', ...   \n",
       "3  ['@', 'SuppressWarnings', '(', '{', '\"unchecke...   \n",
       "4  ['@', 'SuppressWarnings', '(', '{', '\"unchecke...   \n",
       "\n",
       "                                           docstring  \\\n",
       "0  Makes sure the fast-path emits in order.\\n@par...   \n",
       "1  Mirrors the one ObservableSource in an Iterabl...   \n",
       "2  Mirrors the one ObservableSource in an array o...   \n",
       "3  Concatenates elements of each ObservableSource...   \n",
       "4  Returns an Observable that emits the items emi...   \n",
       "\n",
       "                                    docstring_tokens language partition  \\\n",
       "0  ['Makes', 'sure', 'the', 'fast', '-', 'path', ...     java      test   \n",
       "1  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "2  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "3  ['Concatenates', 'elements', 'of', 'each', 'Ob...     java      test   \n",
       "4  ['Returns', 'an', 'Observable', 'that', 'emits...     java      test   \n",
       "\n",
       "                                              bpe32k  code_len  bpe32_len  \n",
       "0  ['▁protected', '▁final', '▁void', '▁fast', 'Pa...       134        138  \n",
       "1  ['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...        63         71  \n",
       "2  ['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...       107        109  \n",
       "3  ['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...        79         83  \n",
       "4  ['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...        91        112  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples = java_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "      <th>bpe32k</th>\n",
       "      <th>code_len</th>\n",
       "      <th>bpe32_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21155</th>\n",
       "      <td>duracloud/duracloud</td>\n",
       "      <td>durastore/src/main/java/org/duracloud/durastor...</td>\n",
       "      <td>https://github.com/duracloud/duracloud/blob/dc...</td>\n",
       "      <td>public void addSpace(String spaceID, Map&lt;Strin...</td>\n",
       "      <td>['public', 'void', 'addSpace', '(', 'String', ...</td>\n",
       "      <td>Adds a space.\\n\\n@param spaceID\\n@param storeID</td>\n",
       "      <td>['Adds', 'a', 'space', '.']</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁void', '▁add', 'Space', '(', 'St...</td>\n",
       "      <td>110</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29011</th>\n",
       "      <td>JOML-CI/JOML</td>\n",
       "      <td>src/org/joml/Intersectiond.java</td>\n",
       "      <td>https://github.com/JOML-CI/JOML/blob/ce2652fc2...</td>\n",
       "      <td>public static int intersectRayAar(double origi...</td>\n",
       "      <td>['public', 'static', 'int', 'intersectRayAar',...</td>\n",
       "      <td>Determine whether the given ray with the origi...</td>\n",
       "      <td>['Determine', 'whether', 'the', 'given', 'ray'...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁static', '▁int', '▁intersect', '...</td>\n",
       "      <td>360</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25379</th>\n",
       "      <td>Azure/azure-sdk-for-java</td>\n",
       "      <td>datalakeanalytics/resource-manager/v2015_10_01...</td>\n",
       "      <td>https://github.com/Azure/azure-sdk-for-java/bl...</td>\n",
       "      <td>public Observable&lt;DataLakeAnalyticsAccountInne...</td>\n",
       "      <td>['public', 'Observable', '&lt;', 'DataLakeAnalyti...</td>\n",
       "      <td>Gets details of the specified Data Lake Analyt...</td>\n",
       "      <td>['Gets', 'details', 'of', 'the', 'specified', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁Observable', '&lt;', 'Data', 'L', '...</td>\n",
       "      <td>62</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9456</th>\n",
       "      <td>googleads/googleads-java-lib</td>\n",
       "      <td>modules/ads_lib/src/main/java/com/google/api/a...</td>\n",
       "      <td>https://github.com/googleads/googleads-java-li...</td>\n",
       "      <td>ReportBodyProvider getReportBodyProvider(Repor...</td>\n",
       "      <td>['ReportBodyProvider', 'getReportBodyProvider'...</td>\n",
       "      <td>Returns the {@link ReportBodyProvider} for the...</td>\n",
       "      <td>['Returns', 'the', '{', '@link', 'ReportBodyPr...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁Report', 'Body', 'Provider', '▁get', 'Repor...</td>\n",
       "      <td>93</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18462</th>\n",
       "      <td>ops4j/org.ops4j.pax.logging</td>\n",
       "      <td>pax-logging-api/src/main/java/org/ops4j/pax/lo...</td>\n",
       "      <td>https://github.com/ops4j/org.ops4j.pax.logging...</td>\n",
       "      <td>public void warn( String format, Object[] argA...</td>\n",
       "      <td>['public', 'void', 'warn', '(', 'String', 'for...</td>\n",
       "      <td>Log a message at the WARN level according to t...</td>\n",
       "      <td>['Log', 'a', 'message', 'at', 'the', 'WARN', '...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁void', '▁warn', '(', '▁String', ...</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               repo  \\\n",
       "21155           duracloud/duracloud   \n",
       "29011                  JOML-CI/JOML   \n",
       "25379      Azure/azure-sdk-for-java   \n",
       "9456   googleads/googleads-java-lib   \n",
       "18462   ops4j/org.ops4j.pax.logging   \n",
       "\n",
       "                                                    path  \\\n",
       "21155  durastore/src/main/java/org/duracloud/durastor...   \n",
       "29011                    src/org/joml/Intersectiond.java   \n",
       "25379  datalakeanalytics/resource-manager/v2015_10_01...   \n",
       "9456   modules/ads_lib/src/main/java/com/google/api/a...   \n",
       "18462  pax-logging-api/src/main/java/org/ops4j/pax/lo...   \n",
       "\n",
       "                                                     url  \\\n",
       "21155  https://github.com/duracloud/duracloud/blob/dc...   \n",
       "29011  https://github.com/JOML-CI/JOML/blob/ce2652fc2...   \n",
       "25379  https://github.com/Azure/azure-sdk-for-java/bl...   \n",
       "9456   https://github.com/googleads/googleads-java-li...   \n",
       "18462  https://github.com/ops4j/org.ops4j.pax.logging...   \n",
       "\n",
       "                                                    code  \\\n",
       "21155  public void addSpace(String spaceID, Map<Strin...   \n",
       "29011  public static int intersectRayAar(double origi...   \n",
       "25379  public Observable<DataLakeAnalyticsAccountInne...   \n",
       "9456   ReportBodyProvider getReportBodyProvider(Repor...   \n",
       "18462  public void warn( String format, Object[] argA...   \n",
       "\n",
       "                                             code_tokens  \\\n",
       "21155  ['public', 'void', 'addSpace', '(', 'String', ...   \n",
       "29011  ['public', 'static', 'int', 'intersectRayAar',...   \n",
       "25379  ['public', 'Observable', '<', 'DataLakeAnalyti...   \n",
       "9456   ['ReportBodyProvider', 'getReportBodyProvider'...   \n",
       "18462  ['public', 'void', 'warn', '(', 'String', 'for...   \n",
       "\n",
       "                                               docstring  \\\n",
       "21155    Adds a space.\\n\\n@param spaceID\\n@param storeID   \n",
       "29011  Determine whether the given ray with the origi...   \n",
       "25379  Gets details of the specified Data Lake Analyt...   \n",
       "9456   Returns the {@link ReportBodyProvider} for the...   \n",
       "18462  Log a message at the WARN level according to t...   \n",
       "\n",
       "                                        docstring_tokens language partition  \\\n",
       "21155                        ['Adds', 'a', 'space', '.']     java     train   \n",
       "29011  ['Determine', 'whether', 'the', 'given', 'ray'...     java     train   \n",
       "25379  ['Gets', 'details', 'of', 'the', 'specified', ...     java     train   \n",
       "9456   ['Returns', 'the', '{', '@link', 'ReportBodyPr...     java     train   \n",
       "18462  ['Log', 'a', 'message', 'at', 'the', 'WARN', '...     java     train   \n",
       "\n",
       "                                                  bpe32k  code_len  bpe32_len  \n",
       "21155  ['▁public', '▁void', '▁add', 'Space', '(', 'St...       110        140  \n",
       "29011  ['▁public', '▁static', '▁int', '▁intersect', '...       360        483  \n",
       "25379  ['▁public', '▁Observable', '<', 'Data', 'L', '...        62         88  \n",
       "9456   ['▁Report', 'Body', 'Provider', '▁get', 'Repor...        93        113  \n",
       "18462  ['▁public', '▁void', '▁warn', '(', '▁String', ...        53         51  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16751, 21794, 23928, 22323,  1666, 19402, 28651, 24093,  6367,\n",
       "        2260])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(java_samples.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"bpe32k_path\": \"/tf/main/dvc-ds4se/models/bpe/sentencepiece/deprecated/java_bpe_32k.model\",\n",
    "    \"doc2vec_java_path\": \"/tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\",\n",
    "    \"hf_tokenizer\": \"/tf/main/nbs/tokenizer.json\",\n",
    "    \"vectors_storage_path\": \"/tf/main/dvc-ds4se/results/d2v_vectors\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure directories to store obtained vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test vectorization with Doc2Vec (based on SentencePiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-20 23:35:16,033 : INFO : loading Doc2Vec object from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n",
      "2021-05-20 23:35:16,644 : INFO : loading vocabulary recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.vocabulary.* with mmap=None\n",
      "2021-05-20 23:35:16,645 : INFO : loading trainables recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.trainables.* with mmap=None\n",
      "2021-05-20 23:35:16,646 : INFO : loading wv recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.wv.* with mmap=None\n",
      "2021-05-20 23:35:16,648 : INFO : loading docvecs recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.* with mmap=None\n",
      "2021-05-20 23:35:16,649 : INFO : loading vectors_docs from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.vectors_docs.npy with mmap=None\n",
      "2021-05-20 23:35:16,910 : INFO : loaded /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Doc2VecVectorizerSP(params['bpe32k_path'], params[\"doc2vec_java_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = vectorizer.tokenize_df(java_samples, 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples['bpe32k-tokens'] = tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, vectors = vectorizer.infer_d2v(java_samples, 'bpe32k-tokens', params[\"vectors_storage_path\"],\n",
    "                                        \"human_trn\", \"10-sample-20052021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test vectorization with Doc2Vec (based on HuggingFace's Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-20 23:35:57,802 : INFO : loading Doc2Vec object from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n",
      "2021-05-20 23:35:58,417 : INFO : loading vocabulary recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.vocabulary.* with mmap=None\n",
      "2021-05-20 23:35:58,418 : INFO : loading trainables recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.trainables.* with mmap=None\n",
      "2021-05-20 23:35:58,419 : INFO : loading wv recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.wv.* with mmap=None\n",
      "2021-05-20 23:35:58,421 : INFO : loading docvecs recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.* with mmap=None\n",
      "2021-05-20 23:35:58,422 : INFO : loading vectors_docs from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.vectors_docs.npy with mmap=None\n",
      "2021-05-20 23:35:58,671 : INFO : loaded /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n"
     ]
    }
   ],
   "source": [
    "hf_vectorizer = Doc2VecVectorizerHF(params['hf_tokenizer'], params[\"doc2vec_java_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = hf_vectorizer.tokenize_df(java_samples, 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples['bpe-hf-tokens'] = tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, vectors = hf_vectorizer.infer_d2v(java_samples, 'bpe-hf-tokens', params[\"vectors_storage_path\"],\n",
    "                                        \"human_trn\", \"10-sample-20052021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export code as module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0.0_mgmnt.prep.i.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "Converted 0.10_error_checker.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "Converted 0.11_info_theory_processing.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "Converted 0.12_doc2vec_vectorization.ipynb.\n",
      "Converted 0.13_data_mgmnt.ipynb.\n",
      "Converted 0.1_mgmnt.prep.conv.ipynb.\n",
      "Converted 0.3_mgmnt.prep.bpe.ipynb.\n",
      "Converted 0.6_mgmnt.prep.nltk.ipynb.\n",
      "Converted 0.7_metrics_module_python.ipynb.\n",
      "Converted 0.8_metrics_module_java.ipynb.\n",
      "Converted 0.9_metrics_example.ipynb.\n",
      "Converted 1.0_exp.i.ipynb.\n",
      "Converted 1.1_exp.info-[inspect].ipynb.\n",
      "Converted 1.1_exp.info.ipynb.\n",
      "Converted 1.2_exp.csnc.ipynb.\n",
      "Converted 1.2_exp.gen.code.ipynb.\n",
      "Converted 1.3_exp.csnc_python.ipynb.\n",
      "Converted 2.0_repr.codebert.ipynb.\n",
      "Converted 2.0_repr.i.ipynb.\n",
      "Converted 2.1_repr.codeberta.ipynb.\n",
      "Converted 2.1_repr.roberta.train.ipynb.\n",
      "Converted 2.2_repr.roberta.eval.ipynb.\n",
      "Converted 2.3_repr.word2vec.train.ipynb.\n",
      "Converted 2.6_repr.word2vec.eval.ipynb.\n",
      "Converted 2.7_repr.distmetrics.ipynb.\n",
      "Converted 2.8_repr.sentence_transformers.ipynb.\n",
      "Converted 3.1_mining.unsupervised.traceability.eda.ipynb.\n",
      "Converted 3.2_mining.unsupervised.eda.traceability.d2v.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "h\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "Converted 3.2_mining.unsupervised.mutual_information.traceability.approach.sacp-w2v.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "h\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "E\n",
      "Converted 3.2_mining.unsupervised.mutual_information.traceability.approach.sacp.w2v.ipynb.\n",
      "Converted 3.2_mutual_information_theory.eval.ipynb.\n",
      "Converted 3.4_facade.ipynb.\n",
      "Converted 4.0_mining.ir.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.d2v.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp4.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp5.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp6.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v.ipynb.\n",
      "Converted 6.0_desc.stats.ipynb.\n",
      "Converted 6.0_eval.mining.ir.unsupervised.x2v.ipynb.\n",
      "Converted 6.1_desc.metrics.java.ipynb.\n",
      "Converted 6.1_desc.metrics.main.ipynb.\n",
      "Converted 6.1_desc.metrics.se.ipynb.\n",
      "Converted 6.2_desc.metrics.java.ipynb.\n",
      "Converted 6.2_desc.metrics.main.ipynb.\n",
      "Converted 7.0_inf.i.ipynb.\n",
      "Converted 7.1_inf.bayesian.ipynb.\n",
      "Converted 7.2_inf.causal.ipynb.\n",
      "Converted 7.3_statistical_analysis.ipynb.\n",
      "Converted 8.0_interpretability.i.ipynb.\n",
      "Converted 9.0_ds.causality.eval.traceability.ipynb.\n",
      "Converted 9.0_ds.description.eval.traceability.ipynb.\n",
      "Converted 9.0_ds.prediction.eval.traceability.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
