{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment.mining.ir.unsupervised.w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting Neural Unsupervised Approaches for Software Information Retrieval [w2v]\n",
    "\n",
    "> Just Paper. Full Experimentation. This module is dedicated to experiment with word2vec. Consider to Copy the entire notebook for a new and separeted empirical evaluation. \n",
    "> Implementing mutual information analysis\n",
    "> Author: @danaderp April 2020\n",
    "> Author: @danielrc Nov 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This copy is for Cisco purposes. It was adapted to process private github data from cisco. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds4se.mining.ir import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prg import prg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ds4se as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifacts Similarity with BasicSequenceVectorization\n",
    "\n",
    "We test diferent similarities based on [blog](https://www.kdnuggets.com/2017/08/comparing-distance-measurements-python-scipy.html) and [blog2](https://www.kdnuggets.com/2019/01/comparison-text-distance-metrics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experients Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../dvc-ds4se/' #dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiments 1.0.2 <<-- word2vec\n",
    "path_model_prefix = path_data+'models/bpe/sentencepiece/wiki_py_java_bpe_8k'\n",
    "path_to_trained_model = path_data+'/models/wv/bpe8k/[word2vec-Java-Py-SK-500-20E-8k-1594090297.869643].model'\n",
    "def sacp_params():\n",
    "        return {\n",
    "        \"vectorizationType\": VectorizationType.word2vec,\n",
    "        \"linkType\": LinkType.issue2src,\n",
    "        \"system\": 'sacp-python-common',\n",
    "        \"path_to_trained_model\": path_to_trained_model,\n",
    "        \"source_type\": SoftwareArtifacts.PR.value,\n",
    "        \"target_type\": SoftwareArtifacts.PY.value,\n",
    "        \"system_path_config\": {\n",
    "            \"system_path\": '/tf/data/cisco/sacp_data/[sacp-python-common-all-corpus-1596383717.992744].csv',\n",
    "            \"sep\": '~',\n",
    "            \"names\": ['ids','bpe8k'],\n",
    "            \"prep\": Preprocessing.bpe\n",
    "        },\n",
    "        \"path_mappings\": \"/tf/data/cisco/sacp_data/sacp-pr-mappings.csv\",\n",
    "        \"saving_path\": path_data + 'metrics/traceability/experiments1.0.x/',\n",
    "        \"names\": ['Source','Target','Linked?'],\n",
    "        \"model_prefix\": path_model_prefix\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizationType': <VectorizationType.word2vec: 1>,\n",
       " 'linkType': <LinkType.issue2src: 3>,\n",
       " 'system': 'sacp-python-common',\n",
       " 'path_to_trained_model': '../dvc-ds4se//models/wv/bpe8k/[word2vec-Java-Py-SK-500-20E-8k-1594090297.869643].model',\n",
       " 'source_type': 'pr',\n",
       " 'target_type': 'py',\n",
       " 'system_path_config': {'system_path': '/tf/data/cisco/sacp_data/[sacp-python-common-all-corpus-1596383717.992744].csv',\n",
       "  'sep': '~',\n",
       "  'names': ['ids', 'bpe8k'],\n",
       "  'prep': <Preprocessing.bpe: 2>},\n",
       " 'path_mappings': '/tf/data/cisco/sacp_data/sacp-pr-mappings.csv',\n",
       " 'saving_path': '../dvc-ds4se/metrics/traceability/experiments1.0.x/',\n",
       " 'names': ['Source', 'Target', 'Linked?'],\n",
       " 'model_prefix': '../dvc-ds4se/models/bpe/sentencepiece/wiki_py_java_bpe_8k'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = sacp_params()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifacts Similarity with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:10:17,818 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:17,899 : INFO : built Dictionary(2193 unique tokens: ['#', '28', '29', '3', '4)']...) from 362 documents (total 205581 corpus positions)\n",
      "2020-12-26 19:10:17,929 : INFO : bpe preprocessing documents, dictionary, and vocab for the test corpus\n",
      "2020-12-26 19:10:17,930 : INFO : loading Word2Vec object from ../dvc-ds4se//models/wv/bpe8k/[word2vec-Java-Py-SK-500-20E-8k-1594090297.869643].model\n",
      "2020-12-26 19:10:18,144 : INFO : loading wv recursively from ../dvc-ds4se//models/wv/bpe8k/[word2vec-Java-Py-SK-500-20E-8k-1594090297.869643].model.wv.* with mmap=None\n",
      "2020-12-26 19:10:18,145 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-12-26 19:10:18,147 : INFO : loading vocabulary recursively from ../dvc-ds4se//models/wv/bpe8k/[word2vec-Java-Py-SK-500-20E-8k-1594090297.869643].model.vocabulary.* with mmap=None\n",
      "2020-12-26 19:10:18,147 : INFO : loading trainables recursively from ../dvc-ds4se//models/wv/bpe8k/[word2vec-Java-Py-SK-500-20E-8k-1594090297.869643].model.trainables.* with mmap=None\n",
      "2020-12-26 19:10:18,148 : INFO : setting ignored attribute cum_table to None\n",
      "2020-12-26 19:10:18,149 : INFO : loaded ../dvc-ds4se//models/wv/bpe8k/[word2vec-Java-Py-SK-500-20E-8k-1594090297.869643].model\n",
      "2020-12-26 19:10:18,161 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-12-26 19:10:18,170 : INFO : constructing a sparse term similarity matrix using <gensim.models.keyedvectors.WordEmbeddingSimilarityIndex object at 0x7fa088aabf60>\n",
      "2020-12-26 19:10:18,172 : INFO : iterating over columns in dictionary order\n",
      "2020-12-26 19:10:18,175 : INFO : PROGRESS: at 0.05% columns (1 / 2193, 0.045600% density, 0.045600% projected density)\n",
      "2020-12-26 19:10:21,134 : INFO : PROGRESS: at 45.65% columns (1001 / 2193, 1.856776% density, 4.013542% projected density)\n",
      "2020-12-26 19:10:22,944 : INFO : PROGRESS: at 91.24% columns (2001 / 2193, 2.687218% density, 2.940687% projected density)\n",
      "2020-12-26 19:10:23,209 : INFO : constructed a sparse term similarity matrix with 2.775672% density\n"
     ]
    }
   ],
   "source": [
    "#[step 1]Creating the Vectorization Class\n",
    "word2vec = ds.mining.ir.Word2VecSeqVect( params = parameters, logging = logging )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:10:23,304 : INFO : Removed 0 and 1 OOV words from document 1 and 2 (respectively).\n",
      "2020-12-26 19:10:23,305 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:23,306 : INFO : built Dictionary(281 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1717 corpus positions)\n",
      "2020-12-26 19:10:23,504 : INFO : token count processed\n",
      "2020-12-26 19:10:23,510 : INFO : frequencies processed\n",
      "2020-12-26 19:10:24,257 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:24,258 : INFO : entropies processed\n",
      "2020-12-26 19:10:24,259 : INFO : extropies processed\n",
      "2020-12-26 19:10:24,264 : INFO : token count processed\n",
      "2020-12-26 19:10:24,266 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:24,269 : INFO : alphabet_target #8010\n",
      "2020-12-26 19:10:24,270 : INFO : vocab #8006\n",
      "2020-12-26 19:10:24,271 : INFO : diff #set()\n",
      "2020-12-26 19:10:25,778 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:26,528 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/auth_utility.py')[[1.181488237149921, 0.45840265510965295], [0.7532500773668289, 0.24674992], [3.0220552088742, 1.3359632893587228], [4.715813838426509, 6.895875762815869, 7.025431310787958, 4.5862582904544205, 2.309617472361449, 0.1295555479720889]]\n",
      "2020-12-26 19:10:26,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:26,539 : INFO : built Dictionary(346 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2730 corpus positions)\n",
      "2020-12-26 19:10:26,806 : INFO : token count processed\n",
      "2020-12-26 19:10:26,817 : INFO : frequencies processed\n",
      "2020-12-26 19:10:27,566 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:27,567 : INFO : entropies processed\n",
      "2020-12-26 19:10:27,568 : INFO : extropies processed\n",
      "2020-12-26 19:10:27,571 : INFO : token count processed\n",
      "2020-12-26 19:10:27,572 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:27,573 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:27,574 : INFO : vocab #8006\n",
      "2020-12-26 19:10:27,576 : INFO : diff #set()\n",
      "2020-12-26 19:10:29,087 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:29,834 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/bandit/bandit.py')[[1.2111964106566204, 0.45224386001198663], [0.7703734338283539, 0.22962657], [3.0849625007211556, 1.3480058660457088], [4.715813838426509, 7.046810312550396, 7.230038299999112, 4.532585850977792, 2.514224461572603, 0.18322798744871616]]\n",
      "2020-12-26 19:10:29,840 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:29,842 : INFO : built Dictionary(288 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2750 corpus positions)\n",
      "2020-12-26 19:10:30,037 : INFO : token count processed\n",
      "2020-12-26 19:10:30,043 : INFO : frequencies processed\n",
      "2020-12-26 19:10:30,811 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:30,812 : INFO : entropies processed\n",
      "2020-12-26 19:10:30,813 : INFO : extropies processed\n",
      "2020-12-26 19:10:30,815 : INFO : token count processed\n",
      "2020-12-26 19:10:30,817 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:30,818 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:30,819 : INFO : vocab #8006\n",
      "2020-12-26 19:10:30,821 : INFO : diff #set()\n",
      "2020-12-26 19:10:32,327 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:33,076 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/bandit/banditReport.py')[[1.2127164093659522, 0.4519331965755825], [0.7907019704580307, 0.20929803], [2.8553885422075336, 1.3250186770664762], [4.715813838426509, 6.426571231608991, 6.503141955126307, 4.639243114909193, 1.7873281166997979, 0.07657072351731653]]\n",
      "2020-12-26 19:10:33,080 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:33,082 : INFO : built Dictionary(173 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 873 corpus positions)\n",
      "2020-12-26 19:10:33,187 : INFO : token count processed\n",
      "2020-12-26 19:10:33,194 : INFO : frequencies processed\n",
      "2020-12-26 19:10:33,941 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:33,942 : INFO : entropies processed\n",
      "2020-12-26 19:10:33,943 : INFO : extropies processed\n",
      "2020-12-26 19:10:33,946 : INFO : token count processed\n",
      "2020-12-26 19:10:33,948 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:33,950 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:33,951 : INFO : vocab #8006\n",
      "2020-12-26 19:10:33,953 : INFO : diff #set()\n",
      "2020-12-26 19:10:35,461 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:36,212 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/cave/caveCa.py')[[1.1862514849103578, 0.4574039203184362], [0.783485621213913, 0.21651438], [2.725480556997868, 1.3192201298976012], [4.715813838426509, 6.098070142413432, 6.273486599138093, 4.540397381701848, 1.5576727607115837, 0.175416456724661]]\n",
      "2020-12-26 19:10:36,215 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:36,217 : INFO : built Dictionary(148 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 549 corpus positions)\n",
      "2020-12-26 19:10:36,301 : INFO : token count processed\n",
      "2020-12-26 19:10:36,307 : INFO : frequencies processed\n",
      "2020-12-26 19:10:37,055 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:37,056 : INFO : entropies processed\n",
      "2020-12-26 19:10:37,056 : INFO : extropies processed\n",
      "2020-12-26 19:10:37,058 : INFO : token count processed\n",
      "2020-12-26 19:10:37,060 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:37,061 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:37,062 : INFO : vocab #8006\n",
      "2020-12-26 19:10:37,064 : INFO : diff #set()\n",
      "2020-12-26 19:10:38,672 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:39,420 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/cave/caveSsl.py')[[1.1825833225525813, 0.4581726569918426], [0.7760003358125687, 0.22399966], [2.584962500721156, 1.315172029168969], [4.715813838426509, 5.941919007331087, 6.1657052985693594, 4.492027547188237, 1.44989146014285, 0.2237862912382722]]\n",
      "2020-12-26 19:10:39,426 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:39,428 : INFO : built Dictionary(240 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2589 corpus positions)\n",
      "2020-12-26 19:10:39,587 : INFO : token count processed\n",
      "2020-12-26 19:10:39,593 : INFO : frequencies processed\n",
      "2020-12-26 19:10:40,357 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:40,358 : INFO : entropies processed\n",
      "2020-12-26 19:10:40,359 : INFO : extropies processed\n",
      "2020-12-26 19:10:40,362 : INFO : token count processed\n",
      "2020-12-26 19:10:40,363 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:40,364 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:40,365 : INFO : vocab #8006\n",
      "2020-12-26 19:10:40,367 : INFO : diff #set()\n",
      "2020-12-26 19:10:41,876 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:42,628 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/cave/caveZap.py')[[1.2022989083521785, 0.45407096929827206], [0.7890220433473587, 0.21097796], [3.0220552088742, 1.3359632893587228], [4.715813838426509, 6.3389906976029495, 6.433231839691082, 4.621572696338376, 1.7174180012645728, 0.09424114208813261]]\n",
      "2020-12-26 19:10:42,633 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:42,636 : INFO : built Dictionary(221 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1709 corpus positions)\n",
      "2020-12-26 19:10:42,789 : INFO : token count processed\n",
      "2020-12-26 19:10:42,795 : INFO : frequencies processed\n",
      "2020-12-26 19:10:43,553 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:43,554 : INFO : entropies processed\n",
      "2020-12-26 19:10:43,555 : INFO : extropies processed\n",
      "2020-12-26 19:10:43,557 : INFO : token count processed\n",
      "2020-12-26 19:10:43,558 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:43,560 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:43,560 : INFO : vocab #8006\n",
      "2020-12-26 19:10:43,562 : INFO : diff #set()\n",
      "2020-12-26 19:10:45,075 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:45,824 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/csbcicd_report/aggregator.py')[[1.203488322329097, 0.45382586776906336], [0.7691089063882828, 0.2308911], [2.128085278891394, 1.2238339714721667], [4.715813838426509, 6.424670910428789, 6.552783147793116, 4.587701601062182, 1.8369693093666069, 0.1281122373643271]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:10:45,838 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:45,845 : INFO : built Dictionary(403 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 7612 corpus positions)\n",
      "2020-12-26 19:10:46,197 : INFO : token count processed\n",
      "2020-12-26 19:10:46,205 : INFO : frequencies processed\n",
      "2020-12-26 19:10:46,956 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:46,956 : INFO : entropies processed\n",
      "2020-12-26 19:10:46,957 : INFO : extropies processed\n",
      "2020-12-26 19:10:46,966 : INFO : token count processed\n",
      "2020-12-26 19:10:46,969 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:46,970 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:46,970 : INFO : vocab #8006\n",
      "2020-12-26 19:10:46,972 : INFO : diff #set()\n",
      "2020-12-26 19:10:48,477 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:49,227 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicd_func.py')[[1.1745287293982174, 0.45986975774596534], [0.7554298490285873, 0.24457015], [3.391892644680931, 1.3610937789874011], [4.715813838426509, 6.856857092706523, 6.931939735496357, 4.6407311956366755, 2.2161258970698476, 0.0750826427898339]]\n",
      "2020-12-26 19:10:49,234 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:49,237 : INFO : built Dictionary(310 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 3217 corpus positions)\n",
      "2020-12-26 19:10:49,466 : INFO : token count processed\n",
      "2020-12-26 19:10:49,476 : INFO : frequencies processed\n",
      "2020-12-26 19:10:50,224 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:50,225 : INFO : entropies processed\n",
      "2020-12-26 19:10:50,226 : INFO : extropies processed\n",
      "2020-12-26 19:10:50,232 : INFO : token count processed\n",
      "2020-12-26 19:10:50,236 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:50,238 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:50,239 : INFO : vocab #8006\n",
      "2020-12-26 19:10:50,240 : INFO : diff #set()\n",
      "2020-12-26 19:10:51,750 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:52,498 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicdReport.py')[[1.199286740586935, 0.45469286998616876], [0.7758591771125793, 0.22414082], [3.2516291673878226, 1.3589504783379556], [4.715813838426509, 6.553499792717194, 6.683893769405158, 4.585419861738545, 1.9680799309786483, 0.13039397668796404]]\n",
      "2020-12-26 19:10:52,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:52,504 : INFO : built Dictionary(216 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 843 corpus positions)\n",
      "2020-12-26 19:10:52,640 : INFO : token count processed\n",
      "2020-12-26 19:10:52,650 : INFO : frequencies processed\n",
      "2020-12-26 19:10:53,403 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:53,404 : INFO : entropies processed\n",
      "2020-12-26 19:10:53,405 : INFO : extropies processed\n",
      "2020-12-26 19:10:53,410 : INFO : token count processed\n",
      "2020-12-26 19:10:53,412 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:53,414 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:53,414 : INFO : vocab #8006\n",
      "2020-12-26 19:10:53,417 : INFO : diff #set()\n",
      "2020-12-26 19:10:54,928 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:55,679 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/ctsm2csdl.py')[[1.109909639803058, 0.47395394624261805], [0.6103235185146332, 0.38967648], [2.446439344671015, 1.2856945251022456], [4.715813838426509, 6.637223258470346, 6.799893125582672, 4.553143971314183, 2.084079287156163, 0.16266986711232612]]\n",
      "2020-12-26 19:10:55,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:55,689 : INFO : built Dictionary(410 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 3279 corpus positions)\n",
      "2020-12-26 19:10:56,045 : INFO : token count processed\n",
      "2020-12-26 19:10:56,051 : INFO : frequencies processed\n",
      "2020-12-26 19:10:56,802 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:56,803 : INFO : entropies processed\n",
      "2020-12-26 19:10:56,804 : INFO : extropies processed\n",
      "2020-12-26 19:10:56,807 : INFO : token count processed\n",
      "2020-12-26 19:10:56,808 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:56,809 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:10:56,810 : INFO : vocab #8006\n",
      "2020-12-26 19:10:56,812 : INFO : diff #set()\n",
      "2020-12-26 19:10:58,427 : INFO : alphabet #8006\n",
      "2020-12-26 19:10:59,175 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/custom_scan/customScan.py')[[1.1865588165481662, 0.4573396299390018], [0.7576670944690704, 0.2423329], [3.41041725276052, 1.3615443860042815], [4.715813838426509, 7.250907518628656, 7.408189769044308, 4.558531588010857, 2.692375930617799, 0.15728225041565214]]\n",
      "2020-12-26 19:10:59,178 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:10:59,180 : INFO : built Dictionary(82 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 153 corpus positions)\n",
      "2020-12-26 19:10:59,220 : INFO : token count processed\n",
      "2020-12-26 19:10:59,226 : INFO : frequencies processed\n",
      "2020-12-26 19:10:59,988 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:10:59,989 : INFO : entropies processed\n",
      "2020-12-26 19:10:59,990 : INFO : extropies processed\n",
      "2020-12-26 19:10:59,994 : INFO : token count processed\n",
      "2020-12-26 19:10:59,996 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:10:59,999 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:11:00,000 : INFO : vocab #8006\n",
      "2020-12-26 19:11:00,002 : INFO : diff #set()\n",
      "2020-12-26 19:11:01,541 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:02,295 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/fireException.py')[[1.2203418699292667, 0.4503810938050981], [0.8007517009973526, 0.1992483], [0.0, 0.0], [4.715813838426509, 5.304981337622145, 5.988069969617877, 4.0327252064307775, 1.2722561311913676, 0.6830886319957319]]\n",
      "2020-12-26 19:11:02,299 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:02,301 : INFO : built Dictionary(173 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 609 corpus positions)\n",
      "2020-12-26 19:11:02,405 : INFO : token count processed\n",
      "2020-12-26 19:11:02,411 : INFO : frequencies processed\n",
      "2020-12-26 19:11:03,182 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:03,183 : INFO : entropies processed\n",
      "2020-12-26 19:11:03,184 : INFO : extropies processed\n",
      "2020-12-26 19:11:03,186 : INFO : token count processed\n",
      "2020-12-26 19:11:03,188 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:03,189 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:03,190 : INFO : vocab #8006\n",
      "2020-12-26 19:11:03,192 : INFO : diff #set()\n",
      "2020-12-26 19:11:04,709 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:05,464 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/gosec/gosec_display.py')[[1.2136826213998653, 0.4517359400723987], [0.7855042964220047, 0.2144957], [2.2516291673878226, 1.2667563532600834], [4.715813838426509, 6.525221949271511, 6.766735168226997, 4.474300619471023, 2.050921329800488, 0.24151321895548605]]\n",
      "2020-12-26 19:11:05,471 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:05,475 : INFO : built Dictionary(359 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 3157 corpus positions)\n",
      "2020-12-26 19:11:05,763 : INFO : token count processed\n",
      "2020-12-26 19:11:05,773 : INFO : frequencies processed\n",
      "2020-12-26 19:11:06,526 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:06,527 : INFO : entropies processed\n",
      "2020-12-26 19:11:06,528 : INFO : extropies processed\n",
      "2020-12-26 19:11:06,531 : INFO : token count processed\n",
      "2020-12-26 19:11:06,532 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:06,534 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:06,534 : INFO : vocab #8006\n",
      "2020-12-26 19:11:06,536 : INFO : diff #set()\n",
      "2020-12-26 19:11:08,068 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:08,824 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/gosec/gosec_report.py')[[1.2110651729552504, 0.45227070293157695], [0.7756415158510208, 0.22435848], [2.9852281360342516, 1.3330291169122896], [4.715813838426509, 6.900194567319838, 7.012694601080394, 4.603313804665953, 2.2968807626538847, 0.11250003376055595]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:11:08,832 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:08,836 : INFO : built Dictionary(285 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 3614 corpus positions)\n",
      "2020-12-26 19:11:09,047 : INFO : token count processed\n",
      "2020-12-26 19:11:09,057 : INFO : frequencies processed\n",
      "2020-12-26 19:11:09,806 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:09,807 : INFO : entropies processed\n",
      "2020-12-26 19:11:09,808 : INFO : extropies processed\n",
      "2020-12-26 19:11:09,811 : INFO : token count processed\n",
      "2020-12-26 19:11:09,813 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:09,816 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:09,817 : INFO : vocab #8006\n",
      "2020-12-26 19:11:09,821 : INFO : diff #set()\n",
      "2020-12-26 19:11:11,330 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:12,079 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/harden_check/harden_func.py')[[1.1792813427781998, 0.4588668660491426], [0.7691298574209213, 0.23087014], [2.8150724101159437, 1.319227277293269], [4.715813838426509, 6.350617617253523, 6.470665925122299, 4.595765530557733, 1.7548520866957897, 0.1200483078687764]]\n",
      "2020-12-26 19:11:12,084 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:12,088 : INFO : built Dictionary(295 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1802 corpus positions)\n",
      "2020-12-26 19:11:12,291 : INFO : token count processed\n",
      "2020-12-26 19:11:12,302 : INFO : frequencies processed\n",
      "2020-12-26 19:11:13,056 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:13,057 : INFO : entropies processed\n",
      "2020-12-26 19:11:13,058 : INFO : extropies processed\n",
      "2020-12-26 19:11:13,060 : INFO : token count processed\n",
      "2020-12-26 19:11:13,062 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:13,063 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:13,064 : INFO : vocab #8006\n",
      "2020-12-26 19:11:13,066 : INFO : diff #set()\n",
      "2020-12-26 19:11:14,696 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:15,446 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/harden_check/hardenPostCheck.py')[[1.1470317253089668, 0.46575930304713864], [0.6757840514183044, 0.32421595], [3.327819531114783, 1.3601165249282494], [4.715813838426509, 6.941677454537802, 7.085027084312992, 4.57246420865132, 2.369213245886483, 0.14334962977518995]]\n",
      "2020-12-26 19:11:15,451 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:15,454 : INFO : built Dictionary(230 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1601 corpus positions)\n",
      "2020-12-26 19:11:15,611 : INFO : token count processed\n",
      "2020-12-26 19:11:15,622 : INFO : frequencies processed\n",
      "2020-12-26 19:11:16,381 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:16,382 : INFO : entropies processed\n",
      "2020-12-26 19:11:16,383 : INFO : extropies processed\n",
      "2020-12-26 19:11:16,386 : INFO : token count processed\n",
      "2020-12-26 19:11:16,388 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:16,390 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:16,391 : INFO : vocab #8006\n",
      "2020-12-26 19:11:16,394 : INFO : diff #set()\n",
      "2020-12-26 19:11:17,923 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:18,669 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/harden_check/hardenReport.py')[[1.2094428118803378, 0.45260279859832797], [0.7876405864953995, 0.21235941], [2.9219280948873623, 1.3359016564230495], [4.715813838426509, 6.494384552966903, 6.6227510015824205, 4.5874473898109915, 1.906937163155911, 0.12836644861551783]]\n",
      "2020-12-26 19:11:18,677 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:18,682 : INFO : built Dictionary(395 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 3732 corpus positions)\n",
      "2020-12-26 19:11:19,012 : INFO : token count processed\n",
      "2020-12-26 19:11:19,022 : INFO : frequencies processed\n",
      "2020-12-26 19:11:19,774 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:19,775 : INFO : entropies processed\n",
      "2020-12-26 19:11:19,776 : INFO : extropies processed\n",
      "2020-12-26 19:11:19,779 : INFO : token count processed\n",
      "2020-12-26 19:11:19,780 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:19,782 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:11:19,782 : INFO : vocab #8006\n",
      "2020-12-26 19:11:19,784 : INFO : diff #set()\n",
      "2020-12-26 19:11:21,296 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:22,046 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/psb_mapping.py')[[1.2014917919294608, 0.4542374419318488], [0.7921446859836578, 0.20785531], [2.807354922057604, 1.3343545280186873], [4.715813838426509, 6.562992713112968, 6.73910627333788, 4.5397002782015985, 2.0232924349113706, 0.17611356022491176]]\n",
      "2020-12-26 19:11:22,055 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:22,060 : INFO : built Dictionary(414 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 4171 corpus positions)\n",
      "2020-12-26 19:11:22,390 : INFO : token count processed\n",
      "2020-12-26 19:11:22,402 : INFO : frequencies processed\n",
      "2020-12-26 19:11:23,151 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:23,151 : INFO : entropies processed\n",
      "2020-12-26 19:11:23,152 : INFO : extropies processed\n",
      "2020-12-26 19:11:23,155 : INFO : token count processed\n",
      "2020-12-26 19:11:23,157 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:23,158 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:23,159 : INFO : vocab #8006\n",
      "2020-12-26 19:11:23,161 : INFO : diff #set()\n",
      "2020-12-26 19:11:24,669 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:25,420 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push.py')[[1.1922415538327455, 0.45615411232930847], [0.7604604959487915, 0.2395395], [3.7345216647797517, 1.3834830067024522], [4.715813838426509, 6.963414455813236, 7.108007822624357, 4.571220471615389, 2.3921939841978475, 0.14459336681112056]]\n",
      "2020-12-26 19:11:25,432 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:25,435 : INFO : built Dictionary(477 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 6760 corpus positions)\n",
      "2020-12-26 19:11:25,886 : INFO : token count processed\n",
      "2020-12-26 19:11:25,895 : INFO : frequencies processed\n",
      "2020-12-26 19:11:26,645 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:26,646 : INFO : entropies processed\n",
      "2020-12-26 19:11:26,647 : INFO : extropies processed\n",
      "2020-12-26 19:11:26,651 : INFO : token count processed\n",
      "2020-12-26 19:11:26,652 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:26,653 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:26,654 : INFO : vocab #8006\n",
      "2020-12-26 19:11:26,656 : INFO : diff #set()\n",
      "2020-12-26 19:11:28,270 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:29,025 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push_func.py')[[1.16976719707536, 0.46087893731083457], [0.7564401775598526, 0.24355982], [3.6421498816369033, 1.374004064933263], [4.715813838426509, 6.923627972311028, 6.999129774654236, 4.6403120360833015, 2.2833159362277264, 0.07550180234320791]]\n",
      "2020-12-26 19:11:29,040 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:29,047 : INFO : built Dictionary(533 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 7996 corpus positions)\n",
      "2020-12-26 19:11:29,541 : INFO : token count processed\n",
      "2020-12-26 19:11:29,550 : INFO : frequencies processed\n",
      "2020-12-26 19:11:30,298 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:30,298 : INFO : entropies processed\n",
      "2020-12-26 19:11:30,299 : INFO : extropies processed\n",
      "2020-12-26 19:11:30,304 : INFO : token count processed\n",
      "2020-12-26 19:11:30,305 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:30,306 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:30,307 : INFO : vocab #8006\n",
      "2020-12-26 19:11:30,309 : INFO : diff #set()\n",
      "2020-12-26 19:11:31,822 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:32,575 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/spotbugs/spotbugs.py')[[1.1820215444900797, 0.4582906170313235], [0.7573775351047516, 0.24262246], [3.41041725276052, 1.3615443860042815], [4.715813838426509, 7.229383614478795, 7.343224745264356, 4.6019727076409485, 2.627410906837847, 0.1138411307855609]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:11:32,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:32,580 : INFO : built Dictionary(149 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 405 corpus positions)\n",
      "2020-12-26 19:11:32,672 : INFO : token count processed\n",
      "2020-12-26 19:11:32,682 : INFO : frequencies processed\n",
      "2020-12-26 19:11:33,439 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:33,440 : INFO : entropies processed\n",
      "2020-12-26 19:11:33,440 : INFO : extropies processed\n",
      "2020-12-26 19:11:33,444 : INFO : token count processed\n",
      "2020-12-26 19:11:33,446 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:33,448 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:33,449 : INFO : vocab #8006\n",
      "2020-12-26 19:11:33,452 : INFO : diff #set()\n",
      "2020-12-26 19:11:34,961 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:35,712 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/spotbugs/spotbugsdisplay.py')[[1.1852122600421335, 0.45762144862793275], [0.7675705552101135, 0.23242944], [1.9219280948873623, 1.2148067842293933], [4.715813838426509, 6.400449261283311, 6.668142743399179, 4.44812035631064, 1.9523289049726698, 0.2676934821158685]]\n",
      "2020-12-26 19:11:35,715 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:35,717 : INFO : built Dictionary(51 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 70 corpus positions)\n",
      "2020-12-26 19:11:35,741 : INFO : token count processed\n",
      "2020-12-26 19:11:35,746 : INFO : ---------------> NO SHARED INFORMATION <-------------------------\n",
      "2020-12-26 19:11:35,747 : INFO : frequencies processed\n",
      "2020-12-26 19:11:35,750 : INFO : token count processed\n",
      "2020-12-26 19:11:35,752 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:35,755 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:11:35,755 : INFO : vocab #8006\n",
      "2020-12-26 19:11:35,758 : INFO : diff #set()\n",
      "2020-12-26 19:11:37,288 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:38,040 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/template/__init__.py')[[1.2280463455734871, 0.4488236979391043], [0.8299210965633392, 0.1700789], [nan, nan], [4.715813838426509, 4.271370634378849, 5.443721113150085, 3.5434633596552736, 0.7279072747235755, 1.1723504787712358]]\n",
      "2020-12-26 19:11:38,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:38,069 : INFO : built Dictionary(658 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 14551 corpus positions)\n",
      "2020-12-26 19:11:38,814 : INFO : token count processed\n",
      "2020-12-26 19:11:38,821 : INFO : frequencies processed\n",
      "2020-12-26 19:11:39,570 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:39,571 : INFO : entropies processed\n",
      "2020-12-26 19:11:39,571 : INFO : extropies processed\n",
      "2020-12-26 19:11:39,578 : INFO : token count processed\n",
      "2020-12-26 19:11:39,579 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:39,581 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:39,582 : INFO : vocab #8006\n",
      "2020-12-26 19:11:39,583 : INFO : diff #set()\n",
      "2020-12-26 19:11:41,092 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:41,842 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/binary_scan_func.py')[[1.180985341951703, 0.45850835435011583], [0.7401731312274933, 0.25982687], [3.8442328987631917, 1.3833695570116156], [4.715813838426509, 7.369295554021139, 7.523248803736717, 4.561860588710932, 2.8074349653102075, 0.15395324971557756]]\n",
      "2020-12-26 19:11:41,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:41,857 : INFO : built Dictionary(461 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 4876 corpus positions)\n",
      "2020-12-26 19:11:42,247 : INFO : token count processed\n",
      "2020-12-26 19:11:42,257 : INFO : frequencies processed\n",
      "2020-12-26 19:11:43,006 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:43,007 : INFO : entropies processed\n",
      "2020-12-26 19:11:43,008 : INFO : extropies processed\n",
      "2020-12-26 19:11:43,011 : INFO : token count processed\n",
      "2020-12-26 19:11:43,012 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:43,014 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:43,015 : INFO : vocab #8006\n",
      "2020-12-26 19:11:43,016 : INFO : diff #set()\n",
      "2020-12-26 19:11:44,525 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:45,276 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/binaryScan.py')[[1.1715204017442862, 0.4605068408276268], [0.7250369787216187, 0.27496302], [3.720128777433187, 1.37769016883465], [4.715813838426509, 7.271825719524831, 7.416829561008921, 4.570809996942419, 2.7010157225824116, 0.1450038414840904]]\n",
      "2020-12-26 19:11:45,285 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:45,287 : INFO : built Dictionary(431 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 4168 corpus positions)\n",
      "2020-12-26 19:11:45,666 : INFO : token count processed\n",
      "2020-12-26 19:11:45,676 : INFO : frequencies processed\n",
      "2020-12-26 19:11:46,427 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:46,428 : INFO : entropies processed\n",
      "2020-12-26 19:11:46,429 : INFO : extropies processed\n",
      "2020-12-26 19:11:46,435 : INFO : token count processed\n",
      "2020-12-26 19:11:46,437 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:46,440 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:46,441 : INFO : vocab #8006\n",
      "2020-12-26 19:11:46,444 : INFO : diff #set()\n",
      "2020-12-26 19:11:47,971 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:48,721 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/blackduck.py')[[1.1744145653877256, 0.4598939024406725], [0.721191793680191, 0.2788082], [3.3918926446809317, 1.361093778987401], [4.715813838426509, 7.141932166468383, 7.28752704071649, 4.570218964178403, 2.5717132022899802, 0.1455948742481068]]\n",
      "2020-12-26 19:11:48,725 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:48,726 : INFO : built Dictionary(184 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 674 corpus positions)\n",
      "2020-12-26 19:11:48,839 : INFO : token count processed\n",
      "2020-12-26 19:11:48,845 : INFO : frequencies processed\n",
      "2020-12-26 19:11:49,607 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:49,608 : INFO : entropies processed\n",
      "2020-12-26 19:11:49,609 : INFO : extropies processed\n",
      "2020-12-26 19:11:49,611 : INFO : token count processed\n",
      "2020-12-26 19:11:49,612 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:49,614 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:49,615 : INFO : vocab #8006\n",
      "2020-12-26 19:11:49,616 : INFO : diff #set()\n",
      "2020-12-26 19:11:51,123 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:51,977 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/bom.py')[[1.1784651588426378, 0.4590387851469124], [0.7597729116678238, 0.24022709], [2.521640636343318, 1.2998438251349493], [4.715813838426509, 6.521729764375934, 6.754865190668651, 4.482678412133792, 2.039051352242142, 0.23313542629271744]]\n",
      "2020-12-26 19:11:51,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:51,982 : INFO : built Dictionary(179 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 835 corpus positions)\n",
      "2020-12-26 19:11:52,086 : INFO : token count processed\n",
      "2020-12-26 19:11:52,093 : INFO : frequencies processed\n",
      "2020-12-26 19:11:52,860 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:52,861 : INFO : entropies processed\n",
      "2020-12-26 19:11:52,862 : INFO : extropies processed\n",
      "2020-12-26 19:11:52,864 : INFO : token count processed\n",
      "2020-12-26 19:11:52,865 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:52,867 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:52,868 : INFO : vocab #8006\n",
      "2020-12-26 19:11:52,869 : INFO : diff #set()\n",
      "2020-12-26 19:11:54,382 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:55,134 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/bom_bd.py')[[1.1761681737911032, 0.4595233089260284], [0.7586087733507156, 0.24139123], [1.9219280948873623, 1.2148067842293933], [4.715813838426509, 6.387061504963217, 6.587408605644519, 4.515466737745207, 1.87159476721801, 0.20034710068130224]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:11:55,140 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:55,142 : INFO : built Dictionary(385 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2101 corpus positions)\n",
      "2020-12-26 19:11:55,442 : INFO : token count processed\n",
      "2020-12-26 19:11:55,451 : INFO : frequencies processed\n",
      "2020-12-26 19:11:56,198 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:56,199 : INFO : entropies processed\n",
      "2020-12-26 19:11:56,200 : INFO : extropies processed\n",
      "2020-12-26 19:11:56,202 : INFO : token count processed\n",
      "2020-12-26 19:11:56,204 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:56,205 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:56,206 : INFO : vocab #8006\n",
      "2020-12-26 19:11:56,207 : INFO : diff #set()\n",
      "2020-12-26 19:11:57,722 : INFO : alphabet #8006\n",
      "2020-12-26 19:11:58,472 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/corona_lite/corona_lite.py')[[1.1845354222462463, 0.4577632341487743], [0.7483652532100677, 0.25163475], [3.5068905956085183, 1.3728719392429896], [4.715813838426509, 7.267710126411932, 7.440815741844035, 4.542708222994405, 2.7250019034175255, 0.17310561543210312]]\n",
      "2020-12-26 19:11:58,477 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:11:58,481 : INFO : built Dictionary(327 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1956 corpus positions)\n",
      "2020-12-26 19:11:58,742 : INFO : token count processed\n",
      "2020-12-26 19:11:58,753 : INFO : frequencies processed\n",
      "2020-12-26 19:11:59,501 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:11:59,502 : INFO : entropies processed\n",
      "2020-12-26 19:11:59,502 : INFO : extropies processed\n",
      "2020-12-26 19:11:59,507 : INFO : token count processed\n",
      "2020-12-26 19:11:59,509 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:11:59,512 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:11:59,512 : INFO : vocab #8006\n",
      "2020-12-26 19:11:59,515 : INFO : diff #set()\n",
      "2020-12-26 19:12:01,034 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:01,782 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/corona_lite/corona_lite_func.py')[[1.1890605617321919, 0.45681696408102357], [0.7718770503997803, 0.22812295], [3.121928094887362, 1.3519647487142497], [4.715813838426509, 7.097365282615124, 7.24505890868613, 4.568120212355503, 2.5292450702596208, 0.147693626071006]]\n",
      "2020-12-26 19:12:01,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:01,788 : INFO : built Dictionary(163 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 618 corpus positions)\n",
      "2020-12-26 19:12:01,892 : INFO : token count processed\n",
      "2020-12-26 19:12:01,904 : INFO : frequencies processed\n",
      "2020-12-26 19:12:02,655 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:02,656 : INFO : entropies processed\n",
      "2020-12-26 19:12:02,657 : INFO : extropies processed\n",
      "2020-12-26 19:12:02,660 : INFO : token count processed\n",
      "2020-12-26 19:12:02,662 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:02,664 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:02,665 : INFO : vocab #8006\n",
      "2020-12-26 19:12:02,668 : INFO : diff #set()\n",
      "2020-12-26 19:12:04,190 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:04,941 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/cve.py')[[1.2135852474044038, 0.45175581160588946], [0.7871968448162079, 0.21280316], [1.9219280948873623, 1.2148067842293933], [4.715813838426509, 6.249195780135539, 6.5103317651499815, 4.454677853412067, 1.794517926723472, 0.2611359850144428]]\n",
      "2020-12-26 19:12:04,945 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:04,947 : INFO : built Dictionary(160 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 768 corpus positions)\n",
      "2020-12-26 19:12:05,048 : INFO : token count processed\n",
      "2020-12-26 19:12:05,054 : INFO : frequencies processed\n",
      "2020-12-26 19:12:05,817 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:05,818 : INFO : entropies processed\n",
      "2020-12-26 19:12:05,818 : INFO : extropies processed\n",
      "2020-12-26 19:12:05,820 : INFO : token count processed\n",
      "2020-12-26 19:12:05,822 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:05,823 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:05,824 : INFO : vocab #8006\n",
      "2020-12-26 19:12:05,825 : INFO : diff #set()\n",
      "2020-12-26 19:12:07,335 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:08,088 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/cve_bd.py')[[1.2087975778333573, 0.4527350129480471], [0.7767198830842972, 0.22328012], [1.5, 1.1225562489182657], [4.715813838426509, 6.199441725113713, 6.423059890884513, 4.4921956726557095, 1.7072460524580038, 0.22361816577079985]]\n",
      "2020-12-26 19:12:08,104 : INFO : Removed 0 and 1 OOV words from document 1 and 2 (respectively).\n",
      "2020-12-26 19:12:08,105 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:08,109 : INFO : built Dictionary(527 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 8374 corpus positions)\n",
      "2020-12-26 19:12:08,644 : INFO : token count processed\n",
      "2020-12-26 19:12:08,650 : INFO : frequencies processed\n",
      "2020-12-26 19:12:09,401 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:09,402 : INFO : entropies processed\n",
      "2020-12-26 19:12:09,403 : INFO : extropies processed\n",
      "2020-12-26 19:12:09,414 : INFO : token count processed\n",
      "2020-12-26 19:12:09,415 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:09,417 : INFO : alphabet_target #8010\n",
      "2020-12-26 19:12:09,417 : INFO : vocab #8006\n",
      "2020-12-26 19:12:09,419 : INFO : diff #set()\n",
      "2020-12-26 19:12:10,940 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:11,795 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/HubRestApi.py')[[1.2029817555447966, 0.45393022320001025], [0.7713046669960022, 0.22869533], [3.41041725276052, 1.3615443860042815], [4.715813838426509, 7.157650486588366, 7.268726999659666, 4.6047373253552095, 2.552913161233157, 0.11107651307129984]]\n",
      "2020-12-26 19:12:11,804 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:11,807 : INFO : built Dictionary(356 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 3817 corpus positions)\n",
      "2020-12-26 19:12:12,077 : INFO : token count processed\n",
      "2020-12-26 19:12:12,083 : INFO : frequencies processed\n",
      "2020-12-26 19:12:12,831 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:12,832 : INFO : entropies processed\n",
      "2020-12-26 19:12:12,833 : INFO : extropies processed\n",
      "2020-12-26 19:12:12,839 : INFO : token count processed\n",
      "2020-12-26 19:12:12,841 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:12,842 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:12,843 : INFO : vocab #8006\n",
      "2020-12-26 19:12:12,846 : INFO : diff #set()\n",
      "2020-12-26 19:12:14,383 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:15,133 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/ipCentralScan.py')[[1.1749189904132016, 0.4597872400801536], [0.7331132590770721, 0.26688674], [3.2927701939369904, 1.3562369015699551], [4.715813838426509, 6.807408309196005, 6.9247762736679075, 4.598445873954608, 2.208962435241398, 0.11736796447190212]]\n",
      "2020-12-26 19:12:15,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:15,137 : INFO : built Dictionary(134 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 327 corpus positions)\n",
      "2020-12-26 19:12:15,204 : INFO : token count processed\n",
      "2020-12-26 19:12:15,210 : INFO : frequencies processed\n",
      "2020-12-26 19:12:15,984 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:15,985 : INFO : entropies processed\n",
      "2020-12-26 19:12:15,986 : INFO : extropies processed\n",
      "2020-12-26 19:12:15,988 : INFO : token count processed\n",
      "2020-12-26 19:12:15,989 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:15,990 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:15,991 : INFO : vocab #8006\n",
      "2020-12-26 19:12:15,993 : INFO : diff #set()\n",
      "2020-12-26 19:12:17,507 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:18,258 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/ipcReport.py')[[1.2057052361838316, 0.45336973571778577], [0.7782622128725052, 0.22173779], [1.584962500721156, 1.1699250014423124], [4.715813838426509, 6.206464900680334, 6.516516855303512, 4.405761883803332, 1.8007030168770024, 0.3100519546231775]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:12:18,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:18,263 : INFO : built Dictionary(301 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1183 corpus positions)\n",
      "2020-12-26 19:12:18,470 : INFO : token count processed\n",
      "2020-12-26 19:12:18,481 : INFO : frequencies processed\n",
      "2020-12-26 19:12:19,230 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:19,230 : INFO : entropies processed\n",
      "2020-12-26 19:12:19,231 : INFO : extropies processed\n",
      "2020-12-26 19:12:19,233 : INFO : token count processed\n",
      "2020-12-26 19:12:19,235 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:19,236 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:19,237 : INFO : vocab #8006\n",
      "2020-12-26 19:12:19,239 : INFO : diff #set()\n",
      "2020-12-26 19:12:20,751 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:21,503 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/rest_request.py')[[1.1931199697474597, 0.4559714077635029], [0.7668265253305435, 0.23317347], [2.663532754804255, 1.307883000782319], [4.715813838426509, 7.072405114331329, 7.293099385905864, 4.495119566851973, 2.577285547479355, 0.22069427157453525]]\n",
      "2020-12-26 19:12:21,513 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:21,516 : INFO : built Dictionary(572 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 5219 corpus positions)\n",
      "2020-12-26 19:12:22,083 : INFO : token count processed\n",
      "2020-12-26 19:12:22,090 : INFO : frequencies processed\n",
      "2020-12-26 19:12:22,840 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:22,841 : INFO : entropies processed\n",
      "2020-12-26 19:12:22,842 : INFO : extropies processed\n",
      "2020-12-26 19:12:22,845 : INFO : token count processed\n",
      "2020-12-26 19:12:22,846 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:22,848 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:22,849 : INFO : vocab #8006\n",
      "2020-12-26 19:12:22,850 : INFO : diff #set()\n",
      "2020-12-26 19:12:24,366 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:25,120 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/run_ipcentral_automation.py')[[1.1966103112547457, 0.45524688419985654], [0.7624613642692566, 0.23753864], [3.6901165175936654, 1.3778211807876932], [4.715813838426509, 7.438474602856903, 7.643715167595129, 4.5105732736882835, 2.92790132916862, 0.20524056473822583]]\n",
      "2020-12-26 19:12:25,123 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:25,126 : INFO : built Dictionary(186 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 685 corpus positions)\n",
      "2020-12-26 19:12:25,250 : INFO : token count processed\n",
      "2020-12-26 19:12:25,257 : INFO : frequencies processed\n",
      "2020-12-26 19:12:26,011 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:26,012 : INFO : entropies processed\n",
      "2020-12-26 19:12:26,014 : INFO : extropies processed\n",
      "2020-12-26 19:12:26,018 : INFO : token count processed\n",
      "2020-12-26 19:12:26,021 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:26,022 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:26,023 : INFO : vocab #8006\n",
      "2020-12-26 19:12:26,026 : INFO : diff #set()\n",
      "2020-12-26 19:12:27,543 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:28,401 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/tpsd_triage.py')[[1.2095770277891935, 0.4525753062343142], [0.7753945738077164, 0.22460543], [1.9219280948873623, 1.2148067842293933], [4.715813838426509, 6.517838464869326, 6.7605177014874736, 4.473134601808362, 2.044703863060964, 0.24267923661814716]]\n",
      "2020-12-26 19:12:28,408 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:28,409 : INFO : built Dictionary(309 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2355 corpus positions)\n",
      "2020-12-26 19:12:28,645 : INFO : token count processed\n",
      "2020-12-26 19:12:28,655 : INFO : frequencies processed\n",
      "2020-12-26 19:12:29,405 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:29,406 : INFO : entropies processed\n",
      "2020-12-26 19:12:29,406 : INFO : extropies processed\n",
      "2020-12-26 19:12:29,411 : INFO : token count processed\n",
      "2020-12-26 19:12:29,413 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:29,416 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:29,417 : INFO : vocab #8006\n",
      "2020-12-26 19:12:29,420 : INFO : diff #set()\n",
      "2020-12-26 19:12:30,933 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:31,686 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/unused/bd_image.py')[[1.162577362980277, 0.4624112030017214], [0.7071625292301178, 0.29283747], [3.182005814760214, 1.3495612861500508], [4.715813838426509, 6.828798019994871, 6.9910466494435415, 4.5535652089778385, 2.275232811017032, 0.1622486294486709]]\n",
      "2020-12-26 19:12:31,690 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:31,691 : INFO : built Dictionary(190 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 822 corpus positions)\n",
      "2020-12-26 19:12:31,804 : INFO : token count processed\n",
      "2020-12-26 19:12:31,818 : INFO : frequencies processed\n",
      "2020-12-26 19:12:32,567 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:32,568 : INFO : entropies processed\n",
      "2020-12-26 19:12:32,569 : INFO : extropies processed\n",
      "2020-12-26 19:12:32,573 : INFO : token count processed\n",
      "2020-12-26 19:12:32,575 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:32,577 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:32,578 : INFO : vocab #8006\n",
      "2020-12-26 19:12:32,581 : INFO : diff #set()\n",
      "2020-12-26 19:12:34,094 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:34,842 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/unused/ipc.py')[[1.213135102566921, 0.4518476973412706], [0.7814854830503464, 0.21851452], [1.9182958340544896, 1.2183406773511978], [4.715813838426509, 6.41691623234547, 6.652733968355996, 4.479996102415983, 1.9369201299294865, 0.23581773601052625]]\n",
      "2020-12-26 19:12:34,850 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:34,855 : INFO : built Dictionary(337 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 3803 corpus positions)\n",
      "2020-12-26 19:12:35,105 : INFO : token count processed\n",
      "2020-12-26 19:12:35,115 : INFO : frequencies processed\n",
      "2020-12-26 19:12:35,866 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:35,867 : INFO : entropies processed\n",
      "2020-12-26 19:12:35,868 : INFO : extropies processed\n",
      "2020-12-26 19:12:35,875 : INFO : token count processed\n",
      "2020-12-26 19:12:35,877 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:35,880 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:35,881 : INFO : vocab #8006\n",
      "2020-12-26 19:12:35,882 : INFO : diff #set()\n",
      "2020-12-26 19:12:37,393 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:38,143 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/third_party/UploadBom.py')[[1.1517415692248119, 0.4647398248481396], [0.7435263097286224, 0.2564737], [3.572469458770136, 1.3725136963533666], [4.715813838426509, 6.872469634872497, 6.99686289286319, 4.591420580435818, 2.2810490544366804, 0.12439325799069234]]\n",
      "2020-12-26 19:12:38,146 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:38,148 : INFO : built Dictionary(121 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 228 corpus positions)\n",
      "2020-12-26 19:12:38,211 : INFO : token count processed\n",
      "2020-12-26 19:12:38,219 : INFO : frequencies processed\n",
      "2020-12-26 19:12:38,966 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:38,967 : INFO : entropies processed\n",
      "2020-12-26 19:12:38,968 : INFO : extropies processed\n",
      "2020-12-26 19:12:38,970 : INFO : token count processed\n",
      "2020-12-26 19:12:38,971 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:38,973 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:38,973 : INFO : vocab #8006\n",
      "2020-12-26 19:12:38,975 : INFO : diff #set()\n",
      "2020-12-26 19:12:40,483 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:41,235 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/webex_send_func.py')[[1.1788713149779635, 0.45895321725785976], [0.7787990123033524, 0.22120099], [2.0, 1.2451124978365313], [4.715813838426509, 6.198484194628611, 6.577971353432921, 4.336326679622199, 1.8621575150064116, 0.3794871588043103]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:12:41,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:41,243 : INFO : built Dictionary(257 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1460 corpus positions)\n",
      "2020-12-26 19:12:41,423 : INFO : token count processed\n",
      "2020-12-26 19:12:41,432 : INFO : frequencies processed\n",
      "2020-12-26 19:12:42,290 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:42,291 : INFO : entropies processed\n",
      "2020-12-26 19:12:42,291 : INFO : extropies processed\n",
      "2020-12-26 19:12:42,294 : INFO : token count processed\n",
      "2020-12-26 19:12:42,295 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:42,296 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:42,297 : INFO : vocab #8006\n",
      "2020-12-26 19:12:42,299 : INFO : diff #set()\n",
      "2020-12-26 19:12:43,810 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:44,561 : INFO : Computed distances or similarities ('295', 'sacp-python-common/sacp_python_common/webexSend.py')[[1.1010706009882134, 0.47594783322828943], [0.6494757831096649, 0.35052422], [3.039148671903071, 1.3416265543077694], [4.715813838426509, 6.830230257253655, 7.005540891096775, 4.5405032045833895, 2.2897270526702656, 0.17531063384311985]]\n",
      "2020-12-26 19:12:44,565 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:44,566 : INFO : built Dictionary(168 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 358 corpus positions)\n",
      "2020-12-26 19:12:44,663 : INFO : token count processed\n",
      "2020-12-26 19:12:44,669 : INFO : frequencies processed\n",
      "2020-12-26 19:12:45,419 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:45,420 : INFO : entropies processed\n",
      "2020-12-26 19:12:45,421 : INFO : extropies processed\n",
      "2020-12-26 19:12:45,423 : INFO : token count processed\n",
      "2020-12-26 19:12:45,424 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:45,426 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:45,426 : INFO : vocab #8006\n",
      "2020-12-26 19:12:45,428 : INFO : diff #set()\n",
      "2020-12-26 19:12:46,940 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:47,689 : INFO : Computed distances or similarities ('295', 'sacp-python-common/setup.py')[[1.217213191207559, 0.4510166203076623], [0.7896310687065125, 0.21036893], [1.0, 1.0], [4.715813838426509, 6.56009527974789, 6.916862578757774, 4.359046539416626, 2.201048740331265, 0.356767299009884]]\n",
      "2020-12-26 19:12:47,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:47,696 : INFO : built Dictionary(233 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1406 corpus positions)\n",
      "2020-12-26 19:12:47,853 : INFO : token count processed\n",
      "2020-12-26 19:12:47,864 : INFO : frequencies processed\n",
      "2020-12-26 19:12:48,615 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:48,616 : INFO : entropies processed\n",
      "2020-12-26 19:12:48,617 : INFO : extropies processed\n",
      "2020-12-26 19:12:48,619 : INFO : token count processed\n",
      "2020-12-26 19:12:48,621 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:48,622 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:48,623 : INFO : vocab #8006\n",
      "2020-12-26 19:12:48,624 : INFO : diff #set()\n",
      "2020-12-26 19:12:50,135 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:50,886 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/bandit/test_bandit.py')[[1.2084959283177785, 0.4527968501901222], [0.7754712998867035, 0.2245287], [2.1556390622295662, 1.2407663947533207], [4.715813838426509, 6.5612688259621, 6.745564180308445, 4.531518484080163, 2.029750341881936, 0.1842953543463457]]\n",
      "2020-12-26 19:12:50,890 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:50,891 : INFO : built Dictionary(144 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 415 corpus positions)\n",
      "2020-12-26 19:12:50,975 : INFO : token count processed\n",
      "2020-12-26 19:12:50,982 : INFO : frequencies processed\n",
      "2020-12-26 19:12:51,731 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:51,732 : INFO : entropies processed\n",
      "2020-12-26 19:12:51,733 : INFO : extropies processed\n",
      "2020-12-26 19:12:51,735 : INFO : token count processed\n",
      "2020-12-26 19:12:51,737 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:51,738 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:51,739 : INFO : vocab #8006\n",
      "2020-12-26 19:12:51,740 : INFO : diff #set()\n",
      "2020-12-26 19:12:53,248 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:53,999 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/cave/test_cave_ca.py')[[1.206624584930781, 0.4531808477205781], [0.7701010853052139, 0.22989891], [1.5, 1.1225562489182657], [4.715813838426509, 6.195832554153221, 6.499202434810009, 4.412443957769721, 1.7833885963834994, 0.3033698806567875]]\n",
      "2020-12-26 19:12:54,002 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:54,003 : INFO : built Dictionary(133 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 412 corpus positions)\n",
      "2020-12-26 19:12:54,071 : INFO : token count processed\n",
      "2020-12-26 19:12:54,077 : INFO : frequencies processed\n",
      "2020-12-26 19:12:54,826 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:54,827 : INFO : entropies processed\n",
      "2020-12-26 19:12:54,827 : INFO : extropies processed\n",
      "2020-12-26 19:12:54,829 : INFO : token count processed\n",
      "2020-12-26 19:12:54,831 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:54,832 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:54,833 : INFO : vocab #8006\n",
      "2020-12-26 19:12:54,834 : INFO : diff #set()\n",
      "2020-12-26 19:12:56,338 : INFO : alphabet #8006\n",
      "2020-12-26 19:12:57,087 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/cave/test_cave_ssl.py')[[1.1999990303883168, 0.4545456548785352], [0.7698160856962204, 0.23018391], [1.9219280948873623, 1.2148067842293933], [4.715813838426509, 6.137714254194409, 6.430665204748693, 4.422862887872227, 1.7148513663221836, 0.29295095055428355]]\n",
      "2020-12-26 19:12:57,090 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:12:57,092 : INFO : built Dictionary(135 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 509 corpus positions)\n",
      "2020-12-26 19:12:57,174 : INFO : token count processed\n",
      "2020-12-26 19:12:57,184 : INFO : frequencies processed\n",
      "2020-12-26 19:12:57,931 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:12:57,932 : INFO : entropies processed\n",
      "2020-12-26 19:12:57,933 : INFO : extropies processed\n",
      "2020-12-26 19:12:57,935 : INFO : token count processed\n",
      "2020-12-26 19:12:57,937 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:12:57,938 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:12:57,939 : INFO : vocab #8006\n",
      "2020-12-26 19:12:57,940 : INFO : diff #set()\n",
      "2020-12-26 19:12:59,448 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:00,198 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/cave/test_cave_zap.py')[[1.1938114333212217, 0.45582769093608705], [0.7765865474939346, 0.22341345], [1.9219280948873623, 1.2148067842293933], [4.715813838426509, 6.132560039014329, 6.384139591091134, 4.464234286349705, 1.6683257526646242, 0.25157955207680427]]\n",
      "2020-12-26 19:13:00,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:00,227 : INFO : built Dictionary(403 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 11681 corpus positions)\n",
      "2020-12-26 19:13:00,587 : INFO : token count processed\n",
      "2020-12-26 19:13:00,596 : INFO : frequencies processed\n",
      "2020-12-26 19:13:01,340 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:01,340 : INFO : entropies processed\n",
      "2020-12-26 19:13:01,341 : INFO : extropies processed\n",
      "2020-12-26 19:13:01,352 : INFO : token count processed\n",
      "2020-12-26 19:13:01,354 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:01,355 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:01,356 : INFO : vocab #8006\n",
      "2020-12-26 19:13:01,357 : INFO : diff #set()\n",
      "2020-12-26 19:13:02,870 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:03,619 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/csbcicdReport/test_csbcicd_func.py')[[1.2178372527411043, 0.4508897119317769], [0.8064588159322739, 0.19354118], [3.095795255000934, 1.3487605247277434], [4.715813838426509, 6.7569795334181375, 6.853225092151353, 4.6195682796932935, 2.137411253724844, 0.09624555873321583]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:13:03,627 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:03,630 : INFO : built Dictionary(286 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2996 corpus positions)\n",
      "2020-12-26 19:13:03,832 : INFO : token count processed\n",
      "2020-12-26 19:13:03,841 : INFO : frequencies processed\n",
      "2020-12-26 19:13:04,694 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:04,695 : INFO : entropies processed\n",
      "2020-12-26 19:13:04,696 : INFO : extropies processed\n",
      "2020-12-26 19:13:04,702 : INFO : token count processed\n",
      "2020-12-26 19:13:04,704 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:04,707 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:04,708 : INFO : vocab #8006\n",
      "2020-12-26 19:13:04,710 : INFO : diff #set()\n",
      "2020-12-26 19:13:06,221 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:06,972 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/csbcicdReport/test_csbcicdReport.py')[[1.2056184579202696, 0.4533875731811403], [0.7819917649030685, 0.21800824], [2.2359263506290326, 1.2653331222512114], [4.715813838426509, 6.51553992472357, 6.619788937063756, 4.6115648260863225, 1.9039750986372468, 0.10424901234018602]]\n",
      "2020-12-26 19:13:06,977 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:06,979 : INFO : built Dictionary(253 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1497 corpus positions)\n",
      "2020-12-26 19:13:07,157 : INFO : token count processed\n",
      "2020-12-26 19:13:07,168 : INFO : frequencies processed\n",
      "2020-12-26 19:13:07,922 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:07,923 : INFO : entropies processed\n",
      "2020-12-26 19:13:07,923 : INFO : extropies processed\n",
      "2020-12-26 19:13:07,926 : INFO : token count processed\n",
      "2020-12-26 19:13:07,927 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:07,928 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:07,929 : INFO : vocab #8006\n",
      "2020-12-26 19:13:07,931 : INFO : diff #set()\n",
      "2020-12-26 19:13:09,441 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:10,190 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/custom_scan/test_customScan.py')[[1.1877588332027549, 0.4570887726852675], [0.7645094394683838, 0.23549056], [2.9219280948873623, 1.3359016564230495], [4.715813838426509, 6.655076556612047, 6.79379502057987, 4.577095374458688, 2.0779811821533603, 0.13871846396782228]]\n",
      "2020-12-26 19:13:10,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:10,197 : INFO : built Dictionary(255 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1459 corpus positions)\n",
      "2020-12-26 19:13:10,378 : INFO : token count processed\n",
      "2020-12-26 19:13:10,384 : INFO : frequencies processed\n",
      "2020-12-26 19:13:11,136 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:11,136 : INFO : entropies processed\n",
      "2020-12-26 19:13:11,137 : INFO : extropies processed\n",
      "2020-12-26 19:13:11,139 : INFO : token count processed\n",
      "2020-12-26 19:13:11,141 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:11,142 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:11,143 : INFO : vocab #8006\n",
      "2020-12-26 19:13:11,144 : INFO : diff #set()\n",
      "2020-12-26 19:13:12,654 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:13,409 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/gosec/test_gosec.py')[[1.2044124200165687, 0.4536356223181159], [0.7606734186410904, 0.23932658], [2.6464393446710157, 1.3017576173934455], [4.715813838426509, 6.781699187074322, 6.916869323972243, 4.580643701528588, 2.2010554855457336, 0.135170136897921]]\n",
      "2020-12-26 19:13:13,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:13,415 : INFO : built Dictionary(209 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1214 corpus positions)\n",
      "2020-12-26 19:13:13,547 : INFO : token count processed\n",
      "2020-12-26 19:13:13,555 : INFO : frequencies processed\n",
      "2020-12-26 19:13:14,305 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:14,306 : INFO : entropies processed\n",
      "2020-12-26 19:13:14,307 : INFO : extropies processed\n",
      "2020-12-26 19:13:14,309 : INFO : token count processed\n",
      "2020-12-26 19:13:14,310 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:14,311 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:14,312 : INFO : vocab #8006\n",
      "2020-12-26 19:13:14,313 : INFO : diff #set()\n",
      "2020-12-26 19:13:15,821 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:16,570 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/gosec/test_gosec_display.py')[[1.1990564393746623, 0.4547404887363265], [0.759181797504425, 0.2408182], [2.128085278891394, 1.2238339714721667], [4.715813838426509, 6.622578715814259, 6.764918047739635, 4.573474506501134, 2.0491042093131258, 0.14233933192537584]]\n",
      "2020-12-26 19:13:16,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:16,576 : INFO : built Dictionary(232 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1154 corpus positions)\n",
      "2020-12-26 19:13:16,727 : INFO : token count processed\n",
      "2020-12-26 19:13:16,734 : INFO : frequencies processed\n",
      "2020-12-26 19:13:17,483 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:17,484 : INFO : entropies processed\n",
      "2020-12-26 19:13:17,485 : INFO : extropies processed\n",
      "2020-12-26 19:13:17,487 : INFO : token count processed\n",
      "2020-12-26 19:13:17,488 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:17,489 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:17,490 : INFO : vocab #8006\n",
      "2020-12-26 19:13:17,492 : INFO : diff #set()\n",
      "2020-12-26 19:13:19,005 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:19,770 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/harden_check/test_HardenPostCheck.py')[[1.1976378354557864, 0.4550340296596694], [0.7573454678058624, 0.24265453], [2.5032583347756456, 1.2991301890771523], [4.715813838426509, 6.734422462155908, 6.892376384049456, 4.557859916532962, 2.1765625456229465, 0.15795392189354818]]\n",
      "2020-12-26 19:13:19,775 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:19,776 : INFO : built Dictionary(248 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1337 corpus positions)\n",
      "2020-12-26 19:13:19,934 : INFO : token count processed\n",
      "2020-12-26 19:13:19,940 : INFO : frequencies processed\n",
      "2020-12-26 19:13:20,695 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:20,696 : INFO : entropies processed\n",
      "2020-12-26 19:13:20,697 : INFO : extropies processed\n",
      "2020-12-26 19:13:20,699 : INFO : token count processed\n",
      "2020-12-26 19:13:20,700 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:20,702 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:20,703 : INFO : vocab #8006\n",
      "2020-12-26 19:13:20,704 : INFO : diff #set()\n",
      "2020-12-26 19:13:22,214 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:22,963 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/security_results_push/test_security_results_push.py')[[1.191567307166356, 0.45629445042825356], [0.752338781952858, 0.24766122], [2.75, 1.3226647836567116], [4.715813838426509, 6.765450962587388, 6.89257159654156, 4.588693204472336, 2.176757758115051, 0.1271206339541724]]\n",
      "2020-12-26 19:13:22,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:22,989 : INFO : built Dictionary(410 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 10280 corpus positions)\n",
      "2020-12-26 19:13:23,335 : INFO : token count processed\n",
      "2020-12-26 19:13:23,361 : INFO : frequencies processed\n",
      "2020-12-26 19:13:24,212 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:24,213 : INFO : entropies processed\n",
      "2020-12-26 19:13:24,214 : INFO : extropies processed\n",
      "2020-12-26 19:13:24,225 : INFO : token count processed\n",
      "2020-12-26 19:13:24,227 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:24,228 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:24,229 : INFO : vocab #8006\n",
      "2020-12-26 19:13:24,231 : INFO : diff #set()\n",
      "2020-12-26 19:13:25,739 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:26,488 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/security_results_push/test_security_results_push_func.py')[[1.2140061202060428, 0.4516699348179474], [0.8145739883184433, 0.18542601], [3.2516291673878226, 1.3589504783379556], [4.715813838426509, 6.638430409424932, 6.723144146584628, 4.631100101266813, 2.007330308158118, 0.08471373715969577]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:13:26,495 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:26,499 : INFO : built Dictionary(340 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2879 corpus positions)\n",
      "2020-12-26 19:13:26,759 : INFO : token count processed\n",
      "2020-12-26 19:13:26,770 : INFO : frequencies processed\n",
      "2020-12-26 19:13:27,518 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:27,519 : INFO : entropies processed\n",
      "2020-12-26 19:13:27,520 : INFO : extropies processed\n",
      "2020-12-26 19:13:27,522 : INFO : token count processed\n",
      "2020-12-26 19:13:27,524 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:27,525 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:27,526 : INFO : vocab #8006\n",
      "2020-12-26 19:13:27,528 : INFO : diff #set()\n",
      "2020-12-26 19:13:29,039 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:29,790 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/spotbugs/test_spotbugs.py')[[1.18013057124019, 0.4586881231756406], [0.7568213045597076, 0.2431787], [2.4193819456463714, 1.2761517340193214], [4.715813838426509, 6.921683529042006, 7.0264289167911755, 4.61106845067734, 2.310615078364666, 0.10474538774916997]]\n",
      "2020-12-26 19:13:29,793 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:29,795 : INFO : built Dictionary(173 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 653 corpus positions)\n",
      "2020-12-26 19:13:29,906 : INFO : token count processed\n",
      "2020-12-26 19:13:29,914 : INFO : frequencies processed\n",
      "2020-12-26 19:13:30,671 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:30,672 : INFO : entropies processed\n",
      "2020-12-26 19:13:30,673 : INFO : extropies processed\n",
      "2020-12-26 19:13:30,677 : INFO : token count processed\n",
      "2020-12-26 19:13:30,679 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:30,682 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:30,683 : INFO : vocab #8006\n",
      "2020-12-26 19:13:30,686 : INFO : diff #set()\n",
      "2020-12-26 19:13:32,200 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:32,952 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/spotbugs/test_spotbugsdisplay.py')[[1.1809258954272674, 0.4585208521283062], [0.7568956613540649, 0.24310434], [1.584962500721156, 1.1699250014423124], [4.715813838426509, 6.443188759664073, 6.651052813352631, 4.507949784737951, 1.935238974926122, 0.20786405368855831]]\n",
      "2020-12-26 19:13:32,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:32,958 : INFO : built Dictionary(224 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 850 corpus positions)\n",
      "2020-12-26 19:13:33,105 : INFO : token count processed\n",
      "2020-12-26 19:13:33,112 : INFO : frequencies processed\n",
      "2020-12-26 19:13:33,863 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:33,863 : INFO : entropies processed\n",
      "2020-12-26 19:13:33,864 : INFO : extropies processed\n",
      "2020-12-26 19:13:33,866 : INFO : token count processed\n",
      "2020-12-26 19:13:33,869 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:33,871 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:33,872 : INFO : vocab #8006\n",
      "2020-12-26 19:13:33,876 : INFO : diff #set()\n",
      "2020-12-26 19:13:35,388 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:36,138 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/test_auth_utility.py')[[1.1917833242832299, 0.45624947909804275], [0.7533175945281982, 0.2466824], [2.807354922057604, 1.3343545280186873], [4.715813838426509, 6.898279638545452, 7.053893889970212, 4.560199587001749, 2.3380800515437024, 0.15561425142476004]]\n",
      "2020-12-26 19:13:36,152 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:36,155 : INFO : built Dictionary(293 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 8507 corpus positions)\n",
      "2020-12-26 19:13:36,374 : INFO : token count processed\n",
      "2020-12-26 19:13:36,381 : INFO : frequencies processed\n",
      "2020-12-26 19:13:37,133 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:37,134 : INFO : entropies processed\n",
      "2020-12-26 19:13:37,135 : INFO : extropies processed\n",
      "2020-12-26 19:13:37,139 : INFO : token count processed\n",
      "2020-12-26 19:13:37,141 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:37,142 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:37,143 : INFO : vocab #8006\n",
      "2020-12-26 19:13:37,145 : INFO : diff #set()\n",
      "2020-12-26 19:13:38,661 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:39,410 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_binary_scan_func.py')[[1.1951822359543878, 0.4555430449560081], [0.7685955613851547, 0.23140444], [3.4182958340544896, 1.369895090630202], [4.715813838426509, 6.408340164694879, 6.437934937585806, 4.686219065535583, 1.7221210991592963, 0.029594772890926713]]\n",
      "2020-12-26 19:13:39,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:39,418 : INFO : built Dictionary(229 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1524 corpus positions)\n",
      "2020-12-26 19:13:39,576 : INFO : token count processed\n",
      "2020-12-26 19:13:39,587 : INFO : frequencies processed\n",
      "2020-12-26 19:13:40,445 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:40,446 : INFO : entropies processed\n",
      "2020-12-26 19:13:40,447 : INFO : extropies processed\n",
      "2020-12-26 19:13:40,449 : INFO : token count processed\n",
      "2020-12-26 19:13:40,451 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:40,452 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:40,453 : INFO : vocab #8006\n",
      "2020-12-26 19:13:40,454 : INFO : diff #set()\n",
      "2020-12-26 19:13:41,969 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:42,718 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_BinaryScan.py')[[1.1950918744047971, 0.4555617975084308], [0.7975607067346573, 0.2024393], [2.725480556997868, 1.3192201298976014], [4.715813838426509, 6.443827478732862, 6.66043046355516, 4.499210853604211, 1.944616625128651, 0.21660298482229834]]\n",
      "2020-12-26 19:13:42,723 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:42,724 : INFO : built Dictionary(238 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1494 corpus positions)\n",
      "2020-12-26 19:13:42,888 : INFO : token count processed\n",
      "2020-12-26 19:13:42,894 : INFO : frequencies processed\n",
      "2020-12-26 19:13:43,657 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:43,658 : INFO : entropies processed\n",
      "2020-12-26 19:13:43,658 : INFO : extropies processed\n",
      "2020-12-26 19:13:43,661 : INFO : token count processed\n",
      "2020-12-26 19:13:43,662 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:43,664 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:43,664 : INFO : vocab #8006\n",
      "2020-12-26 19:13:43,666 : INFO : diff #set()\n",
      "2020-12-26 19:13:45,179 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:45,931 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_blackduck.py')[[1.1947450494354432, 0.4556337877409638], [0.7793501019477844, 0.2206499], [2.6464393446710153, 1.3017576173934455], [4.715813838426509, 6.509540793861948, 6.70799867041087, 4.517355961877588, 1.9921848319843605, 0.19845787654892177]]\n",
      "2020-12-26 19:13:45,936 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:45,939 : INFO : built Dictionary(247 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1448 corpus positions)\n",
      "2020-12-26 19:13:46,105 : INFO : token count processed\n",
      "2020-12-26 19:13:46,116 : INFO : frequencies processed\n",
      "2020-12-26 19:13:46,872 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:46,873 : INFO : entropies processed\n",
      "2020-12-26 19:13:46,874 : INFO : extropies processed\n",
      "2020-12-26 19:13:46,876 : INFO : token count processed\n",
      "2020-12-26 19:13:46,878 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:46,879 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:46,880 : INFO : vocab #8006\n",
      "2020-12-26 19:13:46,882 : INFO : diff #set()\n",
      "2020-12-26 19:13:48,394 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:49,144 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_bom.py')[[1.1416326384249182, 0.4669334889925185], [0.7363897562026978, 0.26361024], [2.6464393446710153, 1.3017576173934455], [4.715813838426509, 6.70060831439398, 6.904227376878676, 4.512194775941813, 2.188413538452167, 0.2036190624846963]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:13:49,149 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:49,151 : INFO : built Dictionary(223 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1602 corpus positions)\n",
      "2020-12-26 19:13:49,282 : INFO : token count processed\n",
      "2020-12-26 19:13:49,288 : INFO : frequencies processed\n",
      "2020-12-26 19:13:50,036 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:50,037 : INFO : entropies processed\n",
      "2020-12-26 19:13:50,038 : INFO : extropies processed\n",
      "2020-12-26 19:13:50,040 : INFO : token count processed\n",
      "2020-12-26 19:13:50,042 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:50,043 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:50,044 : INFO : vocab #8006\n",
      "2020-12-26 19:13:50,046 : INFO : diff #set()\n",
      "2020-12-26 19:13:51,554 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:52,304 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_bom_bd.py')[[1.1348193391625108, 0.468423712327948], [0.7221333086490631, 0.2778667], [2.4193819456463714, 1.2761517340193214], [4.715813838426509, 6.3789777505465235, 6.516909505375114, 4.577882083597919, 1.801095666948605, 0.13793175482859077]]\n",
      "2020-12-26 19:13:52,307 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:52,309 : INFO : built Dictionary(158 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 315 corpus positions)\n",
      "2020-12-26 19:13:52,400 : INFO : token count processed\n",
      "2020-12-26 19:13:52,409 : INFO : frequencies processed\n",
      "2020-12-26 19:13:53,164 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:53,165 : INFO : entropies processed\n",
      "2020-12-26 19:13:53,166 : INFO : extropies processed\n",
      "2020-12-26 19:13:53,168 : INFO : token count processed\n",
      "2020-12-26 19:13:53,169 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:53,170 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:53,171 : INFO : vocab #8006\n",
      "2020-12-26 19:13:53,173 : INFO : diff #set()\n",
      "2020-12-26 19:13:54,787 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:55,550 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_corona_lite.py')[[1.208313823738742, 0.4528341892580149], [0.7658608108758926, 0.23413919], [0.9182958340544896, 0.9182958340544896], [4.715813838426509, 6.594537906629094, 6.878834834112146, 4.431516910943458, 2.1630209956856365, 0.2842969274830516]]\n",
      "2020-12-26 19:13:55,555 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:55,558 : INFO : built Dictionary(235 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1442 corpus positions)\n",
      "2020-12-26 19:13:55,725 : INFO : token count processed\n",
      "2020-12-26 19:13:55,736 : INFO : frequencies processed\n",
      "2020-12-26 19:13:56,488 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:56,489 : INFO : entropies processed\n",
      "2020-12-26 19:13:56,489 : INFO : extropies processed\n",
      "2020-12-26 19:13:56,492 : INFO : token count processed\n",
      "2020-12-26 19:13:56,493 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:56,494 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:56,495 : INFO : vocab #8006\n",
      "2020-12-26 19:13:56,497 : INFO : diff #set()\n",
      "2020-12-26 19:13:58,008 : INFO : alphabet #8006\n",
      "2020-12-26 19:13:58,759 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_corona_lite_func.py')[[1.1951183651386996, 0.45555629977922146], [0.7860361188650131, 0.21396388], [3.121928094887362, 1.3519647487142497], [4.715813838426509, 6.507928811366327, 6.626418831951208, 4.5973238178416285, 1.9106049935246983, 0.1184900205848809]]\n",
      "2020-12-26 19:13:58,764 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:13:58,766 : INFO : built Dictionary(255 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1722 corpus positions)\n",
      "2020-12-26 19:13:58,947 : INFO : token count processed\n",
      "2020-12-26 19:13:58,953 : INFO : frequencies processed\n",
      "2020-12-26 19:13:59,720 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:13:59,721 : INFO : entropies processed\n",
      "2020-12-26 19:13:59,722 : INFO : extropies processed\n",
      "2020-12-26 19:13:59,725 : INFO : token count processed\n",
      "2020-12-26 19:13:59,726 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:13:59,727 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:13:59,728 : INFO : vocab #8006\n",
      "2020-12-26 19:13:59,730 : INFO : diff #set()\n",
      "2020-12-26 19:14:01,238 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:01,988 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_cve.py')[[1.190273913817111, 0.4565638999266739], [0.7896317094564438, 0.21036829], [2.4193819456463714, 1.2761517340193214], [4.715813838426509, 6.54238466446361, 6.770789622332256, 4.487408880557863, 2.0549757839057463, 0.228404957868646]]\n",
      "2020-12-26 19:14:01,993 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:01,996 : INFO : built Dictionary(235 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1633 corpus positions)\n",
      "2020-12-26 19:14:02,157 : INFO : token count processed\n",
      "2020-12-26 19:14:02,167 : INFO : frequencies processed\n",
      "2020-12-26 19:14:02,921 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:02,922 : INFO : entropies processed\n",
      "2020-12-26 19:14:02,923 : INFO : extropies processed\n",
      "2020-12-26 19:14:02,928 : INFO : token count processed\n",
      "2020-12-26 19:14:02,930 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:14:02,933 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:02,934 : INFO : vocab #8006\n",
      "2020-12-26 19:14:02,937 : INFO : diff #set()\n",
      "2020-12-26 19:14:04,441 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:05,190 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_cve_bd.py')[[1.1671257232526286, 0.4614406950507258], [0.7424375712871552, 0.25756243], [2.1556390622295662, 1.2407663947533207], [4.715813838426509, 6.426532968077849, 6.568811255714042, 4.573535550790316, 1.8529974172875328, 0.1422782876361932]]\n",
      "2020-12-26 19:14:05,196 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:05,197 : INFO : built Dictionary(217 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1903 corpus positions)\n",
      "2020-12-26 19:14:05,328 : INFO : token count processed\n",
      "2020-12-26 19:14:05,334 : INFO : frequencies processed\n",
      "2020-12-26 19:14:06,083 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:06,084 : INFO : entropies processed\n",
      "2020-12-26 19:14:06,085 : INFO : extropies processed\n",
      "2020-12-26 19:14:06,087 : INFO : token count processed\n",
      "2020-12-26 19:14:06,088 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:14:06,090 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:06,091 : INFO : vocab #8006\n",
      "2020-12-26 19:14:06,092 : INFO : diff #set()\n",
      "2020-12-26 19:14:07,603 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:08,352 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_ipCentralScan.py')[[1.216146518046212, 0.45123370312248795], [0.7890865653753281, 0.21091343], [2.2359263506290326, 1.2653331222512114], [4.715813838426509, 6.40953838450538, 6.588560935357365, 4.536791287574524, 1.8727470969308557, 0.17902255085198515]]\n",
      "2020-12-26 19:14:08,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:08,358 : INFO : built Dictionary(202 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 795 corpus positions)\n",
      "2020-12-26 19:14:08,491 : INFO : token count processed\n",
      "2020-12-26 19:14:08,497 : INFO : frequencies processed\n",
      "2020-12-26 19:14:09,252 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:09,253 : INFO : entropies processed\n",
      "2020-12-26 19:14:09,254 : INFO : extropies processed\n",
      "2020-12-26 19:14:09,256 : INFO : token count processed\n",
      "2020-12-26 19:14:09,258 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:14:09,259 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:09,260 : INFO : vocab #8006\n",
      "2020-12-26 19:14:09,261 : INFO : diff #set()\n",
      "2020-12-26 19:14:10,776 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:11,524 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_ipcReport.py')[[1.181684401505537, 0.45836143821256636], [0.7478910684585571, 0.25210893], [1.3709505944546687, 1.0438561897747245], [4.715813838426509, 6.513136741171774, 6.751473179795802, 4.477477399802481, 2.0356593413692927, 0.2383364386240281]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:14:11,530 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:11,534 : INFO : built Dictionary(307 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2311 corpus positions)\n",
      "2020-12-26 19:14:11,751 : INFO : token count processed\n",
      "2020-12-26 19:14:11,757 : INFO : frequencies processed\n",
      "2020-12-26 19:14:12,506 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:12,507 : INFO : entropies processed\n",
      "2020-12-26 19:14:12,508 : INFO : extropies processed\n",
      "2020-12-26 19:14:12,513 : INFO : token count processed\n",
      "2020-12-26 19:14:12,516 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:14:12,518 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:12,519 : INFO : vocab #8006\n",
      "2020-12-26 19:14:12,521 : INFO : diff #set()\n",
      "2020-12-26 19:14:14,023 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:14,772 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_triage.py')[[1.1660923168647246, 0.461660840682651], [0.743288516998291, 0.25671148], [2.8453509366224368, 1.321020357168122], [4.715813838426509, 6.770302123271581, 6.997599237968656, 4.488516723729434, 2.281785399542146, 0.22729711469707414]]\n",
      "2020-12-26 19:14:14,776 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:14,779 : INFO : built Dictionary(227 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 1564 corpus positions)\n",
      "2020-12-26 19:14:14,923 : INFO : token count processed\n",
      "2020-12-26 19:14:14,933 : INFO : frequencies processed\n",
      "2020-12-26 19:14:15,686 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:15,687 : INFO : entropies processed\n",
      "2020-12-26 19:14:15,688 : INFO : extropies processed\n",
      "2020-12-26 19:14:15,693 : INFO : token count processed\n",
      "2020-12-26 19:14:15,695 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:14:15,698 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:15,699 : INFO : vocab #8006\n",
      "2020-12-26 19:14:15,702 : INFO : diff #set()\n",
      "2020-12-26 19:14:17,324 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:18,073 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/test_UploadBom.py')[[1.1226108414005502, 0.47111791784695484], [0.7300638854503632, 0.2699361], [3.0220552088742, 1.3359632893587228], [4.715813838426509, 6.592422117733454, 6.767943325580166, 4.540292630579797, 2.052129487153657, 0.1755212078467121]]\n",
      "2020-12-26 19:14:18,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:18,080 : INFO : built Dictionary(252 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2017 corpus positions)\n",
      "2020-12-26 19:14:18,253 : INFO : token count processed\n",
      "2020-12-26 19:14:18,263 : INFO : frequencies processed\n",
      "2020-12-26 19:14:19,012 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:19,013 : INFO : entropies processed\n",
      "2020-12-26 19:14:19,014 : INFO : extropies processed\n",
      "2020-12-26 19:14:19,019 : INFO : token count processed\n",
      "2020-12-26 19:14:19,022 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:14:19,024 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:19,025 : INFO : vocab #8006\n",
      "2020-12-26 19:14:19,027 : INFO : diff #set()\n",
      "2020-12-26 19:14:20,542 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:21,295 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/unused/test_bd_image.py')[[1.106468652173219, 0.4747281660082203], [0.6637933850288391, 0.33620661], [2.8453509366224363, 1.3210203571681218], [4.715813838426509, 6.446379772539096, 6.568740824530941, 4.593452786434664, 1.852926986104432, 0.12236105199184522]]\n",
      "2020-12-26 19:14:21,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:21,303 : INFO : built Dictionary(255 unique tokens: ['#', '28', '29', '3', '4)']...) from 2 documents (total 2288 corpus positions)\n",
      "2020-12-26 19:14:21,480 : INFO : token count processed\n",
      "2020-12-26 19:14:21,487 : INFO : frequencies processed\n",
      "2020-12-26 19:14:22,235 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:22,236 : INFO : entropies processed\n",
      "2020-12-26 19:14:22,237 : INFO : extropies processed\n",
      "2020-12-26 19:14:22,239 : INFO : token count processed\n",
      "2020-12-26 19:14:22,240 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:14:22,242 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:22,242 : INFO : vocab #8006\n",
      "2020-12-26 19:14:22,244 : INFO : diff #set()\n",
      "2020-12-26 19:14:23,758 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:24,510 : INFO : Computed distances or similarities ('295', 'sacp-python-common/test/python/third_party/unused/test_ipc.py')[[1.097742597783646, 0.47670290962129597], [0.6400602757930756, 0.35993972], [2.4193819456463714, 1.2761517340193214], [4.715813838426509, 6.3302275852634216, 6.518912006448802, 4.52712941724113, 1.8030981680222924, 0.1886844211853802]]\n",
      "2020-12-26 19:14:24,516 : INFO : Removed 0 and 1 OOV words from document 1 and 2 (respectively).\n",
      "2020-12-26 19:14:24,517 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:24,521 : INFO : built Dictionary(381 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2070 corpus positions)\n",
      "2020-12-26 19:14:25,961 : INFO : token count processed\n",
      "2020-12-26 19:14:25,973 : INFO : frequencies processed\n",
      "2020-12-26 19:14:26,724 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:26,725 : INFO : entropies processed\n",
      "2020-12-26 19:14:26,726 : INFO : extropies processed\n",
      "2020-12-26 19:14:26,729 : INFO : token count processed\n",
      "2020-12-26 19:14:26,730 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:26,732 : INFO : alphabet_target #8010\n",
      "2020-12-26 19:14:26,733 : INFO : vocab #8006\n",
      "2020-12-26 19:14:26,736 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:28,252 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:29,007 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/auth_utility.py')[[0.7548421267558686, 0.5698518315426324], [0.20116567611694336, 0.7988343], [5.499520776183553, 1.4164660748440379], [6.969615971743114, 6.895875762815869, 7.293342232917551, 6.572149501641432, 0.32372626117443737, 0.3974664701016817]]\n",
      "2020-12-26 19:14:29,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:29,019 : INFO : built Dictionary(429 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3083 corpus positions)\n",
      "2020-12-26 19:14:30,952 : INFO : token count processed\n",
      "2020-12-26 19:14:30,963 : INFO : frequencies processed\n",
      "2020-12-26 19:14:31,712 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:31,713 : INFO : entropies processed\n",
      "2020-12-26 19:14:31,714 : INFO : extropies processed\n",
      "2020-12-26 19:14:31,717 : INFO : token count processed\n",
      "2020-12-26 19:14:31,718 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:31,719 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:31,720 : INFO : vocab #8006\n",
      "2020-12-26 19:14:31,722 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:33,232 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:33,983 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/bandit/bandit.py')[[0.7722903748912908, 0.5642416243790401], [0.21435034275054932, 0.78564966], [5.857608786675703, 1.4217213199548366], [6.969615971743114, 7.046810312550396, 7.407061503266429, 6.60936478102708, 0.43744553152331545, 0.36025119071603307]]\n",
      "2020-12-26 19:14:33,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:33,992 : INFO : built Dictionary(367 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3103 corpus positions)\n",
      "2020-12-26 19:14:35,169 : INFO : token count processed\n",
      "2020-12-26 19:14:35,179 : INFO : frequencies processed\n",
      "2020-12-26 19:14:35,932 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:35,933 : INFO : entropies processed\n",
      "2020-12-26 19:14:35,933 : INFO : extropies processed\n",
      "2020-12-26 19:14:35,936 : INFO : token count processed\n",
      "2020-12-26 19:14:35,937 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:35,940 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:35,941 : INFO : vocab #8006\n",
      "2020-12-26 19:14:35,944 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:37,469 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:38,216 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/bandit/banditReport.py')[[0.7726087138769363, 0.5641402934395285], [0.2302340269088745, 0.769766], [5.893195601689986, 1.4213740367666414], [6.969615971743114, 6.426571231608991, 6.770579108155078, 6.625608095197026, -0.1990368635880353, 0.34400787654608767]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:14:38,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:38,222 : INFO : built Dictionary(281 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1226 corpus positions)\n",
      "2020-12-26 19:14:38,862 : INFO : token count processed\n",
      "2020-12-26 19:14:38,873 : INFO : frequencies processed\n",
      "2020-12-26 19:14:39,622 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:39,623 : INFO : entropies processed\n",
      "2020-12-26 19:14:39,624 : INFO : extropies processed\n",
      "2020-12-26 19:14:39,626 : INFO : token count processed\n",
      "2020-12-26 19:14:39,627 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:39,629 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:39,630 : INFO : vocab #8006\n",
      "2020-12-26 19:14:39,631 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:41,248 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:41,997 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/cave/caveCa.py')[[0.7339145395464175, 0.5767296929533762], [0.19568073749542236, 0.80431926], [5.357399447468701, 1.4125889196486772], [6.969615971743114, 6.098070142413432, 6.821503483561587, 6.246182630594959, -0.14811248818152656, 0.723433341148155]]\n",
      "2020-12-26 19:14:42,001 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:42,003 : INFO : built Dictionary(262 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 902 corpus positions)\n",
      "2020-12-26 19:14:42,559 : INFO : token count processed\n",
      "2020-12-26 19:14:42,570 : INFO : frequencies processed\n",
      "2020-12-26 19:14:43,319 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:43,320 : INFO : entropies processed\n",
      "2020-12-26 19:14:43,321 : INFO : extropies processed\n",
      "2020-12-26 19:14:43,325 : INFO : token count processed\n",
      "2020-12-26 19:14:43,328 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:43,330 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:43,331 : INFO : vocab #8006\n",
      "2020-12-26 19:14:43,333 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:44,848 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:45,597 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/cave/caveSsl.py')[[0.739484763160824, 0.5748828740430566], [0.1892862319946289, 0.81071377], [5.195719587558326, 1.4075357177680148], [6.969615971743114, 5.941919007331087, 6.846652473904406, 6.064882505169795, -0.12296349783870753, 0.9047334665733189]]\n",
      "2020-12-26 19:14:45,603 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:45,608 : INFO : built Dictionary(339 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2942 corpus positions)\n",
      "2020-12-26 19:14:46,585 : INFO : token count processed\n",
      "2020-12-26 19:14:46,596 : INFO : frequencies processed\n",
      "2020-12-26 19:14:47,344 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:47,345 : INFO : entropies processed\n",
      "2020-12-26 19:14:47,346 : INFO : extropies processed\n",
      "2020-12-26 19:14:47,349 : INFO : token count processed\n",
      "2020-12-26 19:14:47,350 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:47,352 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:47,352 : INFO : vocab #8006\n",
      "2020-12-26 19:14:47,354 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:48,867 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:49,614 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/cave/caveZap.py')[[0.772331883947914, 0.5642284095078597], [0.2174728512763977, 0.78252715], [5.551936548617075, 1.4164306443636172], [6.969615971743114, 6.3389906976029495, 6.737658044934138, 6.570948624411924, -0.23195792680897576, 0.39866734733118836]]\n",
      "2020-12-26 19:14:49,620 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:49,624 : INFO : built Dictionary(333 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2062 corpus positions)\n",
      "2020-12-26 19:14:50,586 : INFO : token count processed\n",
      "2020-12-26 19:14:50,596 : INFO : frequencies processed\n",
      "2020-12-26 19:14:51,344 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:51,345 : INFO : entropies processed\n",
      "2020-12-26 19:14:51,346 : INFO : extropies processed\n",
      "2020-12-26 19:14:51,349 : INFO : token count processed\n",
      "2020-12-26 19:14:51,350 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:51,351 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:51,352 : INFO : vocab #8006\n",
      "2020-12-26 19:14:51,354 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:52,867 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:53,617 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/csbcicd_report/aggregator.py')[[0.8386395845105035, 0.543880382226312], [0.24508345127105713, 0.75491655], [5.178757070762124, 1.4070704885111112], [6.969615971743114, 6.424670910428789, 6.971017280547468, 6.423269601624435, 0.0014013088043540733, 0.5463463701186786]]\n",
      "2020-12-26 19:14:53,631 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:53,635 : INFO : built Dictionary(473 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 7965 corpus positions)\n",
      "2020-12-26 19:14:55,795 : INFO : token count processed\n",
      "2020-12-26 19:14:55,804 : INFO : frequencies processed\n",
      "2020-12-26 19:14:56,553 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:14:56,554 : INFO : entropies processed\n",
      "2020-12-26 19:14:56,555 : INFO : extropies processed\n",
      "2020-12-26 19:14:56,559 : INFO : token count processed\n",
      "2020-12-26 19:14:56,560 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:14:56,561 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:14:56,562 : INFO : vocab #8006\n",
      "2020-12-26 19:14:56,564 : INFO : diff #{'```'}\n",
      "2020-12-26 19:14:58,073 : INFO : alphabet #8006\n",
      "2020-12-26 19:14:58,824 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicd_func.py')[[0.7218248334119118, 0.5807791713739154], [0.19125980138778687, 0.8087402], [6.106459982162127, 1.4247070669630757], [6.969615971743114, 6.856857092706523, 7.031137049452983, 6.7953360149966535, 0.06152107770986959, 0.17427995674646013]]\n",
      "2020-12-26 19:14:58,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:14:58,836 : INFO : built Dictionary(410 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3570 corpus positions)\n",
      "2020-12-26 19:15:00,581 : INFO : token count processed\n",
      "2020-12-26 19:15:00,597 : INFO : frequencies processed\n",
      "2020-12-26 19:15:01,356 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:01,357 : INFO : entropies processed\n",
      "2020-12-26 19:15:01,358 : INFO : extropies processed\n",
      "2020-12-26 19:15:01,365 : INFO : token count processed\n",
      "2020-12-26 19:15:01,367 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:01,369 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:01,370 : INFO : vocab #8006\n",
      "2020-12-26 19:15:01,372 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:02,992 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:03,741 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicdReport.py')[[0.8388264995459181, 0.5438250972818486], [0.26387321949005127, 0.7361268], [5.613435459717364, 1.418770277196348], [6.969615971743114, 6.553499792717194, 6.936464286453746, 6.586651478006561, -0.03315168528936763, 0.3829644937365524]]\n",
      "2020-12-26 19:15:03,745 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:03,749 : INFO : built Dictionary(331 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1196 corpus positions)\n",
      "2020-12-26 19:15:04,650 : INFO : token count processed\n",
      "2020-12-26 19:15:04,661 : INFO : frequencies processed\n",
      "2020-12-26 19:15:05,412 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:05,413 : INFO : entropies processed\n",
      "2020-12-26 19:15:05,413 : INFO : extropies processed\n",
      "2020-12-26 19:15:05,416 : INFO : token count processed\n",
      "2020-12-26 19:15:05,417 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:05,418 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:05,419 : INFO : vocab #8006\n",
      "2020-12-26 19:15:05,421 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:06,930 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:07,679 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/ctsm2csdl.py')[[0.8889631266399491, 0.5293909584030794], [0.36808091402053833, 0.6319191], [5.217039470898392, 1.4095844212206912], [6.969615971743114, 6.637223258470346, 7.332284507592063, 6.274554722621397, 0.3626685358489494, 0.695061249121717]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:15:07,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:07,692 : INFO : built Dictionary(485 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3632 corpus positions)\n",
      "2020-12-26 19:15:10,050 : INFO : token count processed\n",
      "2020-12-26 19:15:10,056 : INFO : frequencies processed\n",
      "2020-12-26 19:15:10,806 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:10,807 : INFO : entropies processed\n",
      "2020-12-26 19:15:10,808 : INFO : extropies processed\n",
      "2020-12-26 19:15:10,814 : INFO : token count processed\n",
      "2020-12-26 19:15:10,816 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:10,819 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:10,820 : INFO : vocab #8006\n",
      "2020-12-26 19:15:10,823 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:12,341 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:13,094 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/custom_scan/customScan.py')[[0.738563479372932, 0.5751875107607124], [0.21449440717697144, 0.7855056], [6.027224236686537, 1.4239535969420671], [6.969615971743114, 7.250907518628656, 7.538873538487505, 6.681649951884265, 0.5692575667443913, 0.28796601985884873]]\n",
      "2020-12-26 19:15:13,097 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:13,098 : INFO : built Dictionary(236 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 506 corpus positions)\n",
      "2020-12-26 19:15:13,370 : INFO : token count processed\n",
      "2020-12-26 19:15:13,381 : INFO : frequencies processed\n",
      "2020-12-26 19:15:14,129 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:14,130 : INFO : entropies processed\n",
      "2020-12-26 19:15:14,131 : INFO : extropies processed\n",
      "2020-12-26 19:15:14,135 : INFO : token count processed\n",
      "2020-12-26 19:15:14,138 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:14,140 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:15:14,141 : INFO : vocab #8006\n",
      "2020-12-26 19:15:14,145 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:15,658 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:16,407 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/fireException.py')[[1.00948034027138, 0.4976410965359085], [0.443523645401001, 0.55647635], [3.760017277849653, 1.3727204111507156], [6.969615971743114, 5.304981337622145, 7.157249970486978, 5.117347338878281, 0.18763399874386444, 1.852268632864833]]\n",
      "2020-12-26 19:15:16,410 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:16,412 : INFO : built Dictionary(299 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 962 corpus positions)\n",
      "2020-12-26 19:15:17,104 : INFO : token count processed\n",
      "2020-12-26 19:15:17,116 : INFO : frequencies processed\n",
      "2020-12-26 19:15:17,862 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:17,863 : INFO : entropies processed\n",
      "2020-12-26 19:15:17,864 : INFO : extropies processed\n",
      "2020-12-26 19:15:17,866 : INFO : token count processed\n",
      "2020-12-26 19:15:17,868 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:17,869 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:17,870 : INFO : vocab #8006\n",
      "2020-12-26 19:15:17,871 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:19,498 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:20,248 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/gosec/gosec_display.py')[[0.8899193517689716, 0.529123107324128], [0.2830464839935303, 0.7169535], [4.7744621706311365, 1.3953099566021276], [6.969615971743114, 6.525221949271511, 7.3451097424809895, 6.1497281785336355, 0.3754937707378758, 0.8198877932094781]]\n",
      "2020-12-26 19:15:20,255 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:20,258 : INFO : built Dictionary(428 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3510 corpus positions)\n",
      "2020-12-26 19:15:21,908 : INFO : token count processed\n",
      "2020-12-26 19:15:21,918 : INFO : frequencies processed\n",
      "2020-12-26 19:15:22,666 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:22,667 : INFO : entropies processed\n",
      "2020-12-26 19:15:22,668 : INFO : extropies processed\n",
      "2020-12-26 19:15:22,670 : INFO : token count processed\n",
      "2020-12-26 19:15:22,672 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:22,673 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:22,674 : INFO : vocab #8006\n",
      "2020-12-26 19:15:22,677 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:24,204 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:24,954 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/gosec/gosec_report.py')[[0.747281314524128, 0.5723176867328601], [0.22202682495117188, 0.7779732], [6.060670089890447, 1.4241390496475144], [6.969615971743114, 6.900194567319838, 7.184983032607802, 6.68482750645515, 0.21536706086468804, 0.28478846528796353]]\n",
      "2020-12-26 19:15:24,962 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:24,967 : INFO : built Dictionary(376 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3967 corpus positions)\n",
      "2020-12-26 19:15:26,300 : INFO : token count processed\n",
      "2020-12-26 19:15:26,310 : INFO : frequencies processed\n",
      "2020-12-26 19:15:27,059 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:27,059 : INFO : entropies processed\n",
      "2020-12-26 19:15:27,060 : INFO : extropies processed\n",
      "2020-12-26 19:15:27,063 : INFO : token count processed\n",
      "2020-12-26 19:15:27,065 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:27,068 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:27,069 : INFO : vocab #8006\n",
      "2020-12-26 19:15:27,072 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:28,591 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:29,340 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/harden_check/harden_func.py')[[0.7552066096466865, 0.5697334971871457], [0.23024481534957886, 0.7697552], [5.624315006850891, 1.4178882011326046], [6.969615971743114, 6.350617617253523, 6.7023911939565455, 6.617842395040091, -0.26722477778656817, 0.3517735767030228]]\n",
      "2020-12-26 19:15:29,346 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:29,350 : INFO : built Dictionary(385 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2155 corpus positions)\n",
      "2020-12-26 19:15:30,644 : INFO : token count processed\n",
      "2020-12-26 19:15:30,654 : INFO : frequencies processed\n",
      "2020-12-26 19:15:31,406 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:31,407 : INFO : entropies processed\n",
      "2020-12-26 19:15:31,407 : INFO : extropies processed\n",
      "2020-12-26 19:15:31,410 : INFO : token count processed\n",
      "2020-12-26 19:15:31,411 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:31,412 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:31,413 : INFO : vocab #8006\n",
      "2020-12-26 19:15:31,415 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:32,925 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:33,676 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/harden_check/hardenPostCheck.py')[[0.7819205464154058, 0.5611922495711981], [0.23243683576583862, 0.76756316], [5.766627213004697, 1.4204871607543832], [6.969615971743114, 6.941677454537802, 7.343840869823321, 6.567452556457596, 0.3742248980802074, 0.4021634152855187]]\n",
      "2020-12-26 19:15:33,681 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:33,685 : INFO : built Dictionary(330 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1954 corpus positions)\n",
      "2020-12-26 19:15:34,638 : INFO : token count processed\n",
      "2020-12-26 19:15:34,644 : INFO : frequencies processed\n",
      "2020-12-26 19:15:35,388 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:35,389 : INFO : entropies processed\n",
      "2020-12-26 19:15:35,389 : INFO : extropies processed\n",
      "2020-12-26 19:15:35,391 : INFO : token count processed\n",
      "2020-12-26 19:15:35,393 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:35,394 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:35,395 : INFO : vocab #8006\n",
      "2020-12-26 19:15:35,396 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:36,903 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:37,650 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/harden_check/hardenReport.py')[[0.7517493804297852, 0.5708579156195583], [0.19885915517807007, 0.80114084], [5.488142528657786, 1.415446425448492], [6.969615971743114, 6.494384552966903, 6.973641162782878, 6.490359361927139, 0.004025191039763953, 0.47925660981597495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:15:37,658 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:37,663 : INFO : built Dictionary(461 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 4085 corpus positions)\n",
      "2020-12-26 19:15:39,567 : INFO : token count processed\n",
      "2020-12-26 19:15:39,573 : INFO : frequencies processed\n",
      "2020-12-26 19:15:40,323 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:40,324 : INFO : entropies processed\n",
      "2020-12-26 19:15:40,324 : INFO : extropies processed\n",
      "2020-12-26 19:15:40,327 : INFO : token count processed\n",
      "2020-12-26 19:15:40,329 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:40,330 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:15:40,331 : INFO : vocab #8006\n",
      "2020-12-26 19:15:40,332 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:41,842 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:42,591 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/psb_mapping.py')[[0.726475276091692, 0.5792147816120192], [0.21779769659042358, 0.7822023], [6.034788560882858, 1.423101881181189], [6.969615971743114, 6.562992713112968, 6.9131744401177295, 6.619434244738353, -0.05644153162538412, 0.35018172700476136]]\n",
      "2020-12-26 19:15:42,601 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:42,606 : INFO : built Dictionary(488 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 4524 corpus positions)\n",
      "2020-12-26 19:15:44,758 : INFO : token count processed\n",
      "2020-12-26 19:15:44,768 : INFO : frequencies processed\n",
      "2020-12-26 19:15:45,516 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:45,517 : INFO : entropies processed\n",
      "2020-12-26 19:15:45,518 : INFO : extropies processed\n",
      "2020-12-26 19:15:45,525 : INFO : token count processed\n",
      "2020-12-26 19:15:45,527 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:45,530 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:45,531 : INFO : vocab #8006\n",
      "2020-12-26 19:15:45,532 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:47,040 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:47,789 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push.py')[[0.7787071186370648, 0.5622061043789213], [0.22848045825958252, 0.77151954], [6.067680789026885, 1.4245494067443174], [6.969615971743114, 6.963414455813236, 7.253900308237156, 6.679130119319194, 0.28428433649404194, 0.29048585242391933]]\n",
      "2020-12-26 19:15:47,802 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:47,809 : INFO : built Dictionary(537 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 7113 corpus positions)\n",
      "2020-12-26 19:15:50,515 : INFO : token count processed\n",
      "2020-12-26 19:15:50,523 : INFO : frequencies processed\n",
      "2020-12-26 19:15:51,271 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:51,272 : INFO : entropies processed\n",
      "2020-12-26 19:15:51,273 : INFO : extropies processed\n",
      "2020-12-26 19:15:51,282 : INFO : token count processed\n",
      "2020-12-26 19:15:51,284 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:51,286 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:51,287 : INFO : vocab #8006\n",
      "2020-12-26 19:15:51,288 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:52,908 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:53,660 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push_func.py')[[0.6865084435314381, 0.5929409982117051], [0.17367196083068848, 0.82632804], [6.2251244448178475, 1.4260743662451398], [6.969615971743114, 6.923627972311028, 7.086177137385608, 6.807066806668534, 0.1165611656424943, 0.16254916507458006]]\n",
      "2020-12-26 19:15:53,675 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:53,683 : INFO : built Dictionary(587 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 8349 corpus positions)\n",
      "2020-12-26 19:15:56,758 : INFO : token count processed\n",
      "2020-12-26 19:15:56,764 : INFO : frequencies processed\n",
      "2020-12-26 19:15:57,513 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:15:57,514 : INFO : entropies processed\n",
      "2020-12-26 19:15:57,515 : INFO : extropies processed\n",
      "2020-12-26 19:15:57,519 : INFO : token count processed\n",
      "2020-12-26 19:15:57,521 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:15:57,522 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:15:57,523 : INFO : vocab #8006\n",
      "2020-12-26 19:15:57,525 : INFO : diff #{'```'}\n",
      "2020-12-26 19:15:59,036 : INFO : alphabet #8006\n",
      "2020-12-26 19:15:59,785 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/spotbugs/spotbugs.py')[[0.7179450164964221, 0.5820908063981003], [0.18805336952209473, 0.81194663], [6.260981888565995, 1.4262718773496132], [6.969615971743114, 7.229383614478795, 7.40731386795802, 6.791685718263889, 0.43769789621490673, 0.1779302534792251]]\n",
      "2020-12-26 19:15:59,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:15:59,790 : INFO : built Dictionary(286 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 758 corpus positions)\n",
      "2020-12-26 19:16:00,395 : INFO : token count processed\n",
      "2020-12-26 19:16:00,407 : INFO : frequencies processed\n",
      "2020-12-26 19:16:01,158 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:01,159 : INFO : entropies processed\n",
      "2020-12-26 19:16:01,160 : INFO : extropies processed\n",
      "2020-12-26 19:16:01,164 : INFO : token count processed\n",
      "2020-12-26 19:16:01,167 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:01,169 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:01,170 : INFO : vocab #8006\n",
      "2020-12-26 19:16:01,172 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:02,695 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:03,445 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/spotbugs/spotbugsdisplay.py')[[0.878278828628776, 0.5324023168221742], [0.2804937958717346, 0.7195062], [4.662003176732793, 1.403648271909085], [6.969615971743114, 6.400449261283311, 7.324265039440475, 6.045800193585948, 0.3546490676973617, 0.9238157781571648]]\n",
      "2020-12-26 19:16:03,448 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:03,451 : INFO : built Dictionary(209 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 423 corpus positions)\n",
      "2020-12-26 19:16:03,587 : INFO : token count processed\n",
      "2020-12-26 19:16:03,599 : INFO : frequencies processed\n",
      "2020-12-26 19:16:04,350 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:04,351 : INFO : entropies processed\n",
      "2020-12-26 19:16:04,352 : INFO : extropies processed\n",
      "2020-12-26 19:16:04,354 : INFO : token count processed\n",
      "2020-12-26 19:16:04,355 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:04,356 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:16:04,357 : INFO : vocab #8006\n",
      "2020-12-26 19:16:04,359 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:05,869 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:06,619 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/template/__init__.py')[[1.100430922334992, 0.4760927814223604], [0.4731888771057129, 0.5268111], [3.3371753411230767, 1.3498156511278132], [6.969615971743114, 4.271370634378849, 7.018769197779928, 4.2222174083420345, 0.0491532260368146, 2.747398563401079]]\n",
      "2020-12-26 19:16:06,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:06,649 : INFO : built Dictionary(721 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 14904 corpus positions)\n",
      "2020-12-26 19:16:12,171 : INFO : token count processed\n",
      "2020-12-26 19:16:12,177 : INFO : frequencies processed\n",
      "2020-12-26 19:16:12,924 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:12,925 : INFO : entropies processed\n",
      "2020-12-26 19:16:12,926 : INFO : extropies processed\n",
      "2020-12-26 19:16:12,932 : INFO : token count processed\n",
      "2020-12-26 19:16:12,934 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:12,935 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:12,936 : INFO : vocab #8006\n",
      "2020-12-26 19:16:12,938 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:14,462 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:15,214 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/binary_scan_func.py')[[0.7422278937525489, 0.5739777233425648], [0.19746696949005127, 0.80253303], [6.182582737654725, 1.4253736543136706], [6.969615971743114, 7.369295554021139, 7.567069602142404, 6.771841923621849, 0.5974536303992908, 0.1977740481212651]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:16:15,224 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:15,230 : INFO : built Dictionary(543 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 5229 corpus positions)\n",
      "2020-12-26 19:16:17,800 : INFO : token count processed\n",
      "2020-12-26 19:16:17,811 : INFO : frequencies processed\n",
      "2020-12-26 19:16:18,558 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:18,559 : INFO : entropies processed\n",
      "2020-12-26 19:16:18,560 : INFO : extropies processed\n",
      "2020-12-26 19:16:18,568 : INFO : token count processed\n",
      "2020-12-26 19:16:18,570 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:18,573 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:18,574 : INFO : vocab #8006\n",
      "2020-12-26 19:16:18,577 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:20,097 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:20,847 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/binaryScan.py')[[0.7886828420490507, 0.5590706057505622], [0.22635149955749512, 0.7736485], [5.931215773655787, 1.4227088183327135], [6.969615971743114, 7.271825719524831, 7.537599471870313, 6.7038422193976315, 0.5679835001271991, 0.2657737523454822]]\n",
      "2020-12-26 19:16:20,857 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:20,862 : INFO : built Dictionary(513 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 4521 corpus positions)\n",
      "2020-12-26 19:16:23,329 : INFO : token count processed\n",
      "2020-12-26 19:16:23,338 : INFO : frequencies processed\n",
      "2020-12-26 19:16:24,085 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:24,086 : INFO : entropies processed\n",
      "2020-12-26 19:16:24,087 : INFO : extropies processed\n",
      "2020-12-26 19:16:24,094 : INFO : token count processed\n",
      "2020-12-26 19:16:24,097 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:24,099 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:24,100 : INFO : vocab #8006\n",
      "2020-12-26 19:16:24,102 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:25,724 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:26,473 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/blackduck.py')[[0.7956156693633712, 0.5569120480857389], [0.2309895157814026, 0.7690105], [5.905653928308855, 1.422517959073529], [6.969615971743114, 7.141932166468383, 7.430352311810518, 6.6811958264009785, 0.46073634006740427, 0.2884201453421351]]\n",
      "2020-12-26 19:16:26,478 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:26,479 : INFO : built Dictionary(304 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1027 corpus positions)\n",
      "2020-12-26 19:16:27,204 : INFO : token count processed\n",
      "2020-12-26 19:16:27,216 : INFO : frequencies processed\n",
      "2020-12-26 19:16:27,963 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:27,964 : INFO : entropies processed\n",
      "2020-12-26 19:16:27,965 : INFO : extropies processed\n",
      "2020-12-26 19:16:27,969 : INFO : token count processed\n",
      "2020-12-26 19:16:27,971 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:27,974 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:27,975 : INFO : vocab #8006\n",
      "2020-12-26 19:16:27,978 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:29,494 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:30,244 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/bom.py')[[0.8401233199725737, 0.5434418384605356], [0.25576072931289673, 0.7442393], [5.084787108355195, 1.4074103831424405], [6.969615971743114, 6.521729764375934, 7.286028436076367, 6.2053173000426805, 0.3164124643332533, 0.7642986717004332]]\n",
      "2020-12-26 19:16:30,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:30,251 : INFO : built Dictionary(301 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1188 corpus positions)\n",
      "2020-12-26 19:16:30,964 : INFO : token count processed\n",
      "2020-12-26 19:16:30,975 : INFO : frequencies processed\n",
      "2020-12-26 19:16:31,726 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:31,727 : INFO : entropies processed\n",
      "2020-12-26 19:16:31,727 : INFO : extropies processed\n",
      "2020-12-26 19:16:31,731 : INFO : token count processed\n",
      "2020-12-26 19:16:31,733 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:31,735 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:31,736 : INFO : vocab #8006\n",
      "2020-12-26 19:16:31,738 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:33,265 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:34,016 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/bom_bd.py')[[0.8466000726926123, 0.541535774198175], [0.264509379863739, 0.7354906], [4.938944667340221, 1.406198282731965], [6.969615971743114, 6.387061504963217, 7.150170036227515, 6.206507440478815, 0.1805540644844017, 0.7631085312642982]]\n",
      "2020-12-26 19:16:34,023 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:34,027 : INFO : built Dictionary(473 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2454 corpus positions)\n",
      "2020-12-26 19:16:36,225 : INFO : token count processed\n",
      "2020-12-26 19:16:36,235 : INFO : frequencies processed\n",
      "2020-12-26 19:16:36,985 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:36,986 : INFO : entropies processed\n",
      "2020-12-26 19:16:36,987 : INFO : extropies processed\n",
      "2020-12-26 19:16:36,990 : INFO : token count processed\n",
      "2020-12-26 19:16:36,991 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:36,992 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:36,993 : INFO : vocab #8006\n",
      "2020-12-26 19:16:36,995 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:38,503 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:39,253 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/corona_lite/corona_lite.py')[[0.7962712975454295, 0.5567087785494769], [0.23968493938446045, 0.76031506], [5.82169682900442, 1.4211245261162686], [6.969615971743114, 7.267710126411932, 7.629456307986903, 6.607869790168142, 0.6598403362437892, 0.3617461815749712]]\n",
      "2020-12-26 19:16:39,259 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:39,263 : INFO : built Dictionary(427 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2309 corpus positions)\n",
      "2020-12-26 19:16:41,022 : INFO : token count processed\n",
      "2020-12-26 19:16:41,033 : INFO : frequencies processed\n",
      "2020-12-26 19:16:41,781 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:41,782 : INFO : entropies processed\n",
      "2020-12-26 19:16:41,783 : INFO : extropies processed\n",
      "2020-12-26 19:16:41,789 : INFO : token count processed\n",
      "2020-12-26 19:16:41,791 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:41,794 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:41,794 : INFO : vocab #8006\n",
      "2020-12-26 19:16:41,796 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:43,315 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:44,067 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/corona_lite/corona_lite_func.py')[[0.7859658683976486, 0.5599211147843438], [0.22893500328063965, 0.771065], [5.504698060431486, 1.4167757645843144], [6.969615971743114, 7.097365282615124, 7.473213307700745, 6.5937679466574926, 0.5035973359576316, 0.3758480250856211]]\n",
      "2020-12-26 19:16:44,072 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:44,075 : INFO : built Dictionary(291 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 971 corpus positions)\n",
      "2020-12-26 19:16:44,747 : INFO : token count processed\n",
      "2020-12-26 19:16:44,757 : INFO : frequencies processed\n",
      "2020-12-26 19:16:45,507 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:45,508 : INFO : entropies processed\n",
      "2020-12-26 19:16:45,508 : INFO : extropies processed\n",
      "2020-12-26 19:16:45,511 : INFO : token count processed\n",
      "2020-12-26 19:16:45,512 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:45,513 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:45,514 : INFO : vocab #8006\n",
      "2020-12-26 19:16:45,516 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:47,129 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:47,878 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/cve.py')[[0.8808932186355942, 0.5316622921982797], [0.27184081077575684, 0.7281592], [4.759143618741562, 1.3983291172991565], [6.969615971743114, 6.249195780135539, 7.169427421341534, 6.049384330537118, 0.19981144959842023, 0.9202316412059952]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:16:47,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:47,885 : INFO : built Dictionary(287 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1121 corpus positions)\n",
      "2020-12-26 19:16:48,506 : INFO : token count processed\n",
      "2020-12-26 19:16:48,517 : INFO : frequencies processed\n",
      "2020-12-26 19:16:49,267 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:49,268 : INFO : entropies processed\n",
      "2020-12-26 19:16:49,269 : INFO : extropies processed\n",
      "2020-12-26 19:16:49,271 : INFO : token count processed\n",
      "2020-12-26 19:16:49,272 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:49,274 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:16:49,275 : INFO : vocab #8006\n",
      "2020-12-26 19:16:49,276 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:50,787 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:51,542 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/cve_bd.py')[[0.8839373330450505, 0.5308032185888463], [0.2826056480407715, 0.71739435], [4.795709546067493, 1.4024408687593357], [6.969615971743114, 6.199441725113713, 7.073326068417693, 6.095731628439134, 0.10371009667457898, 0.8738843433039793]]\n",
      "2020-12-26 19:16:51,557 : INFO : Removed 0 and 1 OOV words from document 1 and 2 (respectively).\n",
      "2020-12-26 19:16:51,558 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:51,567 : INFO : built Dictionary(593 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 8727 corpus positions)\n",
      "2020-12-26 19:16:54,586 : INFO : token count processed\n",
      "2020-12-26 19:16:54,594 : INFO : frequencies processed\n",
      "2020-12-26 19:16:55,341 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:16:55,342 : INFO : entropies processed\n",
      "2020-12-26 19:16:55,343 : INFO : extropies processed\n",
      "2020-12-26 19:16:55,348 : INFO : token count processed\n",
      "2020-12-26 19:16:55,349 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:16:55,350 : INFO : alphabet_target #8010\n",
      "2020-12-26 19:16:55,351 : INFO : vocab #8006\n",
      "2020-12-26 19:16:55,353 : INFO : diff #{'```'}\n",
      "2020-12-26 19:16:56,864 : INFO : alphabet #8006\n",
      "2020-12-26 19:16:57,612 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/HubRestApi.py')[[0.7515663541166074, 0.5709175662399294], [0.19465309381484985, 0.8053469], [6.09973560818326, 1.4244329425867892], [6.969615971743114, 7.157650486588366, 7.346795025161771, 6.780471433169709, 0.377179053418657, 0.1891445385734043]]\n",
      "2020-12-26 19:16:57,621 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:16:57,626 : INFO : built Dictionary(451 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 4170 corpus positions)\n",
      "2020-12-26 19:16:59,439 : INFO : token count processed\n",
      "2020-12-26 19:16:59,448 : INFO : frequencies processed\n",
      "2020-12-26 19:17:00,195 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:00,196 : INFO : entropies processed\n",
      "2020-12-26 19:17:00,197 : INFO : extropies processed\n",
      "2020-12-26 19:17:00,200 : INFO : token count processed\n",
      "2020-12-26 19:17:00,201 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:00,202 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:00,203 : INFO : vocab #8006\n",
      "2020-12-26 19:17:00,205 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:01,715 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:02,464 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/ipCentralScan.py')[[0.8165851445027837, 0.5504834183116196], [0.2359585165977478, 0.7640415], [5.677756974724429, 1.4194020789530977], [6.969615971743114, 6.807408309196005, 7.120474560687038, 6.656549720252082, 0.15085858894392423, 0.3130662514910325]]\n",
      "2020-12-26 19:17:02,468 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:02,470 : INFO : built Dictionary(273 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 680 corpus positions)\n",
      "2020-12-26 19:17:03,041 : INFO : token count processed\n",
      "2020-12-26 19:17:03,052 : INFO : frequencies processed\n",
      "2020-12-26 19:17:03,798 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:03,799 : INFO : entropies processed\n",
      "2020-12-26 19:17:03,800 : INFO : extropies processed\n",
      "2020-12-26 19:17:03,802 : INFO : token count processed\n",
      "2020-12-26 19:17:03,804 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:03,805 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:03,806 : INFO : vocab #8006\n",
      "2020-12-26 19:17:03,807 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:05,313 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:06,169 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/ipcReport.py')[[0.9277817311320742, 0.5187309246948606], [0.32102227210998535, 0.6789777], [4.534098237775659, 1.3959389587678739], [6.969615971743114, 6.206464900680334, 7.298476323060871, 5.877604549362577, 0.3288603513177577, 1.092011422380537]]\n",
      "2020-12-26 19:17:06,173 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:06,175 : INFO : built Dictionary(397 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1536 corpus positions)\n",
      "2020-12-26 19:17:07,679 : INFO : token count processed\n",
      "2020-12-26 19:17:07,691 : INFO : frequencies processed\n",
      "2020-12-26 19:17:08,444 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:08,445 : INFO : entropies processed\n",
      "2020-12-26 19:17:08,447 : INFO : extropies processed\n",
      "2020-12-26 19:17:08,451 : INFO : token count processed\n",
      "2020-12-26 19:17:08,453 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:08,456 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:08,457 : INFO : vocab #8006\n",
      "2020-12-26 19:17:08,460 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:09,979 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:10,731 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/rest_request.py')[[0.7905802216969895, 0.5584781892945675], [0.23945355415344238, 0.76054645], [5.524285438665805, 1.4151916735340484], [6.969615971743114, 7.072405114331329, 7.559245532063245, 6.482775554011197, 0.5896295603201311, 0.48684041773191566]]\n",
      "2020-12-26 19:17:10,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:10,749 : INFO : built Dictionary(649 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 5572 corpus positions)\n",
      "2020-12-26 19:17:15,404 : INFO : token count processed\n",
      "2020-12-26 19:17:15,413 : INFO : frequencies processed\n",
      "2020-12-26 19:17:16,157 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:16,158 : INFO : entropies processed\n",
      "2020-12-26 19:17:16,159 : INFO : extropies processed\n",
      "2020-12-26 19:17:16,163 : INFO : token count processed\n",
      "2020-12-26 19:17:16,164 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:16,165 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:16,166 : INFO : vocab #8006\n",
      "2020-12-26 19:17:16,168 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:17,682 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:18,432 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/run_ipcentral_automation.py')[[0.7638122890570497, 0.5669537547754638], [0.21733558177947998, 0.7826644], [5.959262888626653, 1.422801305565007], [6.969615971743114, 7.438474602856903, 7.7345096878438895, 6.6735808867561275, 0.7648937161007758, 0.29603508498698616]]\n",
      "2020-12-26 19:17:18,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:18,439 : INFO : built Dictionary(304 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1038 corpus positions)\n",
      "2020-12-26 19:17:19,224 : INFO : token count processed\n",
      "2020-12-26 19:17:19,236 : INFO : frequencies processed\n",
      "2020-12-26 19:17:19,984 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:19,985 : INFO : entropies processed\n",
      "2020-12-26 19:17:19,986 : INFO : extropies processed\n",
      "2020-12-26 19:17:19,988 : INFO : token count processed\n",
      "2020-12-26 19:17:19,989 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:19,991 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:19,992 : INFO : vocab #8006\n",
      "2020-12-26 19:17:19,993 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:21,506 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:22,257 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/tpsd_triage.py')[[0.8438445943879466, 0.542345056109213], [0.25411754846572876, 0.74588245], [5.063405840723041, 1.4059842566971241], [6.969615971743114, 6.517838464869326, 7.282008519081732, 6.205445917530708, 0.312392547338618, 0.7641700542124052]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:17:22,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:22,266 : INFO : built Dictionary(412 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2708 corpus positions)\n",
      "2020-12-26 19:17:23,930 : INFO : token count processed\n",
      "2020-12-26 19:17:23,940 : INFO : frequencies processed\n",
      "2020-12-26 19:17:24,691 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:24,692 : INFO : entropies processed\n",
      "2020-12-26 19:17:24,693 : INFO : extropies processed\n",
      "2020-12-26 19:17:24,696 : INFO : token count processed\n",
      "2020-12-26 19:17:24,697 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:24,698 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:24,699 : INFO : vocab #8006\n",
      "2020-12-26 19:17:24,701 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:26,209 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:26,958 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/unused/bd_image.py')[[0.8329428755454227, 0.5455707394604065], [0.2591692805290222, 0.7408307], [5.53153263285039, 1.4175353803154398], [6.969615971743114, 6.828798019994871, 7.257873248442689, 6.540540743295296, 0.288257276699575, 0.4290752284478181]]\n",
      "2020-12-26 19:17:26,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:26,966 : INFO : built Dictionary(306 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1175 corpus positions)\n",
      "2020-12-26 19:17:27,800 : INFO : token count processed\n",
      "2020-12-26 19:17:27,812 : INFO : frequencies processed\n",
      "2020-12-26 19:17:28,559 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:28,560 : INFO : entropies processed\n",
      "2020-12-26 19:17:28,561 : INFO : extropies processed\n",
      "2020-12-26 19:17:28,565 : INFO : token count processed\n",
      "2020-12-26 19:17:28,568 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:28,570 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:28,571 : INFO : vocab #8006\n",
      "2020-12-26 19:17:28,575 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:30,086 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:30,833 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/unused/ipc.py')[[0.8488906118785589, 0.5408648805804436], [0.2503967881202698, 0.7496032], [5.043074298225579, 1.4059615780226176], [6.969615971743114, 6.41691623234547, 7.172764154002442, 6.213768050086141, 0.20314818225932818, 0.7558479216569722]]\n",
      "2020-12-26 19:17:30,841 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:30,844 : INFO : built Dictionary(439 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 4156 corpus positions)\n",
      "2020-12-26 19:17:32,603 : INFO : token count processed\n",
      "2020-12-26 19:17:32,612 : INFO : frequencies processed\n",
      "2020-12-26 19:17:33,358 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:33,359 : INFO : entropies processed\n",
      "2020-12-26 19:17:33,360 : INFO : extropies processed\n",
      "2020-12-26 19:17:33,367 : INFO : token count processed\n",
      "2020-12-26 19:17:33,370 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:33,372 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:33,373 : INFO : vocab #8006\n",
      "2020-12-26 19:17:33,375 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:34,881 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:35,627 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/third_party/UploadBom.py')[[0.8224855490779175, 0.5487011957411392], [0.24055522680282593, 0.7594448], [5.608777308005055, 1.418574597509122], [6.969615971743114, 6.872469634872497, 7.194766874887352, 6.64731873172826, 0.2251509031442387, 0.32229724001485494]]\n",
      "2020-12-26 19:17:35,631 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:35,634 : INFO : built Dictionary(254 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 581 corpus positions)\n",
      "2020-12-26 19:17:36,089 : INFO : token count processed\n",
      "2020-12-26 19:17:36,100 : INFO : frequencies processed\n",
      "2020-12-26 19:17:36,851 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:36,852 : INFO : entropies processed\n",
      "2020-12-26 19:17:36,853 : INFO : extropies processed\n",
      "2020-12-26 19:17:36,857 : INFO : token count processed\n",
      "2020-12-26 19:17:36,860 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:36,862 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:36,863 : INFO : vocab #8006\n",
      "2020-12-26 19:17:36,867 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:38,371 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:39,227 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/webex_send_func.py')[[0.7926764383823921, 0.5578251482472444], [0.2243814468383789, 0.77561855], [4.943880053428424, 1.4109466862803726], [6.969615971743114, 6.198484194628611, 7.209414893017637, 5.958685273354087, 0.23979892127452374, 1.0109306983890267]]\n",
      "2020-12-26 19:17:39,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:39,236 : INFO : built Dictionary(370 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1813 corpus positions)\n",
      "2020-12-26 19:17:40,493 : INFO : token count processed\n",
      "2020-12-26 19:17:40,504 : INFO : frequencies processed\n",
      "2020-12-26 19:17:41,253 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:41,254 : INFO : entropies processed\n",
      "2020-12-26 19:17:41,255 : INFO : extropies processed\n",
      "2020-12-26 19:17:41,258 : INFO : token count processed\n",
      "2020-12-26 19:17:41,259 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:41,260 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:41,261 : INFO : vocab #8006\n",
      "2020-12-26 19:17:41,263 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:42,774 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:43,526 : INFO : Computed distances or similarities ('294', 'sacp-python-common/sacp_python_common/webexSend.py')[[0.894513389340368, 0.5278400277488565], [0.3315001130104065, 0.6684999], [5.207438056786576, 1.4093425914711077], [6.969615971743114, 6.830230257253655, 7.3986511112522315, 6.401195117744537, 0.42903513950911787, 0.5684208539985764]]\n",
      "2020-12-26 19:17:43,530 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:43,533 : INFO : built Dictionary(296 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 711 corpus positions)\n",
      "2020-12-26 19:17:44,174 : INFO : token count processed\n",
      "2020-12-26 19:17:44,186 : INFO : frequencies processed\n",
      "2020-12-26 19:17:44,935 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:44,936 : INFO : entropies processed\n",
      "2020-12-26 19:17:44,937 : INFO : extropies processed\n",
      "2020-12-26 19:17:44,941 : INFO : token count processed\n",
      "2020-12-26 19:17:44,944 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:44,946 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:44,947 : INFO : vocab #8006\n",
      "2020-12-26 19:17:44,949 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:46,466 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:47,213 : INFO : Computed distances or similarities ('294', 'sacp-python-common/setup.py')[[0.8358648044579594, 0.544702419029843], [0.2845262885093689, 0.7154737], [4.939629058852768, 1.409219892819281], [6.969615971743114, 6.56009527974789, 7.398398221166241, 6.131313030324764, 0.4287822494231275, 0.8383029414183509]]\n",
      "2020-12-26 19:17:47,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:47,222 : INFO : built Dictionary(338 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1759 corpus positions)\n",
      "2020-12-26 19:17:48,259 : INFO : token count processed\n",
      "2020-12-26 19:17:48,270 : INFO : frequencies processed\n",
      "2020-12-26 19:17:49,019 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:49,020 : INFO : entropies processed\n",
      "2020-12-26 19:17:49,021 : INFO : extropies processed\n",
      "2020-12-26 19:17:49,024 : INFO : token count processed\n",
      "2020-12-26 19:17:49,025 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:49,026 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:49,027 : INFO : vocab #8006\n",
      "2020-12-26 19:17:49,029 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:50,538 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:51,287 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/bandit/test_bandit.py')[[0.768758170754532, 0.5653684130111531], [0.2407326102256775, 0.7592674], [5.302275398440902, 1.4136949999765054], [6.969615971743114, 6.5612688259621, 7.097295749470268, 6.4335890482349445, 0.12767977772715433, 0.5360269235081683]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:17:51,291 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:51,294 : INFO : built Dictionary(268 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 768 corpus positions)\n",
      "2020-12-26 19:17:51,837 : INFO : token count processed\n",
      "2020-12-26 19:17:51,845 : INFO : frequencies processed\n",
      "2020-12-26 19:17:52,597 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:52,598 : INFO : entropies processed\n",
      "2020-12-26 19:17:52,598 : INFO : extropies processed\n",
      "2020-12-26 19:17:52,600 : INFO : token count processed\n",
      "2020-12-26 19:17:52,601 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:52,603 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:52,603 : INFO : vocab #8006\n",
      "2020-12-26 19:17:52,605 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:54,115 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:54,868 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/cave/test_cave_ca.py')[[0.7748343549121235, 0.5634328619075624], [0.21258479356765747, 0.7874152], [4.8493039518225824, 1.398108502391426], [6.969615971743114, 6.195832554153221, 7.126158233255779, 6.039290292640555, 0.1565422615126657, 0.930325679102558]]\n",
      "2020-12-26 19:17:54,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:54,874 : INFO : built Dictionary(257 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 765 corpus positions)\n",
      "2020-12-26 19:17:55,368 : INFO : token count processed\n",
      "2020-12-26 19:17:55,375 : INFO : frequencies processed\n",
      "2020-12-26 19:17:56,124 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:56,125 : INFO : entropies processed\n",
      "2020-12-26 19:17:56,125 : INFO : extropies processed\n",
      "2020-12-26 19:17:56,127 : INFO : token count processed\n",
      "2020-12-26 19:17:56,129 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:56,130 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:56,131 : INFO : vocab #8006\n",
      "2020-12-26 19:17:56,132 : INFO : diff #{'```'}\n",
      "2020-12-26 19:17:57,646 : INFO : alphabet #8006\n",
      "2020-12-26 19:17:58,396 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/cave/test_cave_ssl.py')[[0.7653370834017449, 0.5664640534673604], [0.21228420734405518, 0.7877158], [4.962752114105414, 1.4040656632787487], [6.969615971743114, 6.137714254194409, 7.076562423918573, 6.030767802018951, 0.1069464521754595, 0.9388481697241637]]\n",
      "2020-12-26 19:17:58,400 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:17:58,402 : INFO : built Dictionary(261 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 862 corpus positions)\n",
      "2020-12-26 19:17:58,885 : INFO : token count processed\n",
      "2020-12-26 19:17:58,895 : INFO : frequencies processed\n",
      "2020-12-26 19:17:59,646 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:17:59,647 : INFO : entropies processed\n",
      "2020-12-26 19:17:59,648 : INFO : extropies processed\n",
      "2020-12-26 19:17:59,652 : INFO : token count processed\n",
      "2020-12-26 19:17:59,655 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:17:59,657 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:17:59,658 : INFO : vocab #8006\n",
      "2020-12-26 19:17:59,662 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:01,170 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:02,024 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/cave/test_cave_zap.py')[[0.7738693617740597, 0.5637393719906706], [0.22759753465652466, 0.77240247], [4.856438499741975, 1.4025976672849172], [6.969615971743114, 6.132560039014329, 7.040422913415564, 6.061753097341879, 0.07080694167245039, 0.9078628744012347]]\n",
      "2020-12-26 19:18:02,044 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:02,053 : INFO : built Dictionary(457 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 12034 corpus positions)\n",
      "2020-12-26 19:18:03,844 : INFO : token count processed\n",
      "2020-12-26 19:18:03,852 : INFO : frequencies processed\n",
      "2020-12-26 19:18:04,602 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:04,603 : INFO : entropies processed\n",
      "2020-12-26 19:18:04,604 : INFO : extropies processed\n",
      "2020-12-26 19:18:04,610 : INFO : token count processed\n",
      "2020-12-26 19:18:04,611 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:04,613 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:04,613 : INFO : vocab #8006\n",
      "2020-12-26 19:18:04,615 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:06,136 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:06,884 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/csbcicdReport/test_csbcicd_func.py')[[0.5874168949623424, 0.6299542377137939], [0.1656818389892578, 0.83431816], [6.201006979789417, 1.425499227418988], [6.969615971743114, 6.7569795334181375, 6.904157604258822, 6.822437900902429, -0.06545836748429146, 0.14717807084068468]]\n",
      "2020-12-26 19:18:06,891 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:06,896 : INFO : built Dictionary(387 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3349 corpus positions)\n",
      "2020-12-26 19:18:08,191 : INFO : token count processed\n",
      "2020-12-26 19:18:08,201 : INFO : frequencies processed\n",
      "2020-12-26 19:18:08,947 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:08,948 : INFO : entropies processed\n",
      "2020-12-26 19:18:08,949 : INFO : extropies processed\n",
      "2020-12-26 19:18:08,952 : INFO : token count processed\n",
      "2020-12-26 19:18:08,953 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:08,954 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:08,955 : INFO : vocab #8006\n",
      "2020-12-26 19:18:08,957 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:10,470 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:11,217 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/csbcicdReport/test_csbcicdReport.py')[[0.7967168346145588, 0.5565707298637992], [0.28446245193481445, 0.71553755], [5.417871263329254, 1.416034847280363], [6.969615971743114, 6.51553992472357, 6.870029731466168, 6.615126165000515, -0.0995862402769454, 0.3544898067425981]]\n",
      "2020-12-26 19:18:11,223 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:11,225 : INFO : built Dictionary(346 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1850 corpus positions)\n",
      "2020-12-26 19:18:12,349 : INFO : token count processed\n",
      "2020-12-26 19:18:12,359 : INFO : frequencies processed\n",
      "2020-12-26 19:18:13,109 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:13,110 : INFO : entropies processed\n",
      "2020-12-26 19:18:13,111 : INFO : extropies processed\n",
      "2020-12-26 19:18:13,113 : INFO : token count processed\n",
      "2020-12-26 19:18:13,115 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:13,116 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:13,117 : INFO : vocab #8006\n",
      "2020-12-26 19:18:13,118 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:14,628 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:15,378 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/custom_scan/test_customScan.py')[[0.7257132926989909, 0.5794705321160355], [0.20319217443466187, 0.7968078], [5.647181810953204, 1.4182399473738225], [6.969615971743114, 6.655076556612047, 7.0976165084628935, 6.527076019892268, 0.12800053671977984, 0.44253995185084616]]\n",
      "2020-12-26 19:18:15,383 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:15,385 : INFO : built Dictionary(358 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1812 corpus positions)\n",
      "2020-12-26 19:18:16,642 : INFO : token count processed\n",
      "2020-12-26 19:18:16,653 : INFO : frequencies processed\n",
      "2020-12-26 19:18:17,401 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:17,402 : INFO : entropies processed\n",
      "2020-12-26 19:18:17,403 : INFO : extropies processed\n",
      "2020-12-26 19:18:17,405 : INFO : token count processed\n",
      "2020-12-26 19:18:17,406 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:17,407 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:17,408 : INFO : vocab #8006\n",
      "2020-12-26 19:18:17,410 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:18,920 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:19,671 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/gosec/test_gosec.py')[[0.8100172499146315, 0.5524809225145034], [0.24034124612808228, 0.75965875], [5.365570086777335, 1.413222960275042], [6.969615971743114, 6.781699187074322, 7.246362435536146, 6.504952723281289, 0.2767464637930326, 0.4646632484618243]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:18:19,676 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:19,679 : INFO : built Dictionary(328 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1567 corpus positions)\n",
      "2020-12-26 19:18:20,617 : INFO : token count processed\n",
      "2020-12-26 19:18:20,628 : INFO : frequencies processed\n",
      "2020-12-26 19:18:21,378 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:21,379 : INFO : entropies processed\n",
      "2020-12-26 19:18:21,380 : INFO : extropies processed\n",
      "2020-12-26 19:18:21,385 : INFO : token count processed\n",
      "2020-12-26 19:18:21,387 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:21,390 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:21,390 : INFO : vocab #8006\n",
      "2020-12-26 19:18:21,394 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:22,909 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:23,766 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/gosec/test_gosec_display.py')[[0.8319745708578145, 0.5458591052013098], [0.2289266586303711, 0.77107334], [4.970037645902448, 1.4052668249856544], [6.969615971743114, 6.622578715814259, 7.191608509406851, 6.400586178150522, 0.22199253766373772, 0.5690297935925921]]\n",
      "2020-12-26 19:18:23,771 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:23,775 : INFO : built Dictionary(338 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1507 corpus positions)\n",
      "2020-12-26 19:18:24,772 : INFO : token count processed\n",
      "2020-12-26 19:18:24,784 : INFO : frequencies processed\n",
      "2020-12-26 19:18:25,535 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:25,536 : INFO : entropies processed\n",
      "2020-12-26 19:18:25,538 : INFO : extropies processed\n",
      "2020-12-26 19:18:25,542 : INFO : token count processed\n",
      "2020-12-26 19:18:25,545 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:25,548 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:25,548 : INFO : vocab #8006\n",
      "2020-12-26 19:18:25,550 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:27,059 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:27,811 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/harden_check/test_HardenPostCheck.py')[[0.7745116898990231, 0.5635353126678495], [0.23005372285842896, 0.7699463], [5.328614438100973, 1.4140335438649285], [6.969615971743114, 6.734422462155908, 7.248836073382374, 6.455202360516648, 0.27922010163926014, 0.5144136112264661]]\n",
      "2020-12-26 19:18:27,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:27,820 : INFO : built Dictionary(354 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1690 corpus positions)\n",
      "2020-12-26 19:18:28,920 : INFO : token count processed\n",
      "2020-12-26 19:18:28,932 : INFO : frequencies processed\n",
      "2020-12-26 19:18:29,678 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:29,679 : INFO : entropies processed\n",
      "2020-12-26 19:18:29,680 : INFO : extropies processed\n",
      "2020-12-26 19:18:29,685 : INFO : token count processed\n",
      "2020-12-26 19:18:29,687 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:29,690 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:29,691 : INFO : vocab #8006\n",
      "2020-12-26 19:18:29,694 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:31,222 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:31,974 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/security_results_push/test_security_results_push.py')[[0.7897801280410254, 0.5587278483723773], [0.2149685025215149, 0.7850315], [5.322062753598057, 1.4129978722670233], [6.969615971743114, 6.765450962587388, 7.228822369421934, 6.506244564908567, 0.25920639767882037, 0.46337140683454603]]\n",
      "2020-12-26 19:18:31,992 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:32,001 : INFO : built Dictionary(463 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 10633 corpus positions)\n",
      "2020-12-26 19:18:33,945 : INFO : token count processed\n",
      "2020-12-26 19:18:33,951 : INFO : frequencies processed\n",
      "2020-12-26 19:18:34,701 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:34,702 : INFO : entropies processed\n",
      "2020-12-26 19:18:34,703 : INFO : extropies processed\n",
      "2020-12-26 19:18:34,711 : INFO : token count processed\n",
      "2020-12-26 19:18:34,713 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:34,714 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:34,714 : INFO : vocab #8006\n",
      "2020-12-26 19:18:34,716 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:36,237 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:36,991 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/security_results_push/test_security_results_push_func.py')[[0.5695156514164312, 0.6371392340672335], [0.17121905088424683, 0.82878095], [6.238558031111928, 1.4259809877133203], [6.969615971743114, 6.638430409424932, 6.779946238685751, 6.828100142482294, -0.18966973305736268, 0.14151582926081918]]\n",
      "2020-12-26 19:18:36,998 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:37,000 : INFO : built Dictionary(421 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 3232 corpus positions)\n",
      "2020-12-26 19:18:38,618 : INFO : token count processed\n",
      "2020-12-26 19:18:38,624 : INFO : frequencies processed\n",
      "2020-12-26 19:18:39,385 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:39,386 : INFO : entropies processed\n",
      "2020-12-26 19:18:39,387 : INFO : extropies processed\n",
      "2020-12-26 19:18:39,390 : INFO : token count processed\n",
      "2020-12-26 19:18:39,391 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:39,392 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:39,393 : INFO : vocab #8006\n",
      "2020-12-26 19:18:39,395 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:40,903 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:41,653 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/spotbugs/test_spotbugs.py')[[0.7136060778590397, 0.5835646902288003], [0.16549795866012573, 0.83450204], [5.787139114365295, 1.4207589167937513], [6.969615971743114, 6.921683529042006, 7.195073058541232, 6.696226442243888, 0.2254570867981185, 0.27338952949922657]]\n",
      "2020-12-26 19:18:41,657 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:41,660 : INFO : built Dictionary(297 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1006 corpus positions)\n",
      "2020-12-26 19:18:42,359 : INFO : token count processed\n",
      "2020-12-26 19:18:42,370 : INFO : frequencies processed\n",
      "2020-12-26 19:18:43,223 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:43,224 : INFO : entropies processed\n",
      "2020-12-26 19:18:43,225 : INFO : extropies processed\n",
      "2020-12-26 19:18:43,229 : INFO : token count processed\n",
      "2020-12-26 19:18:43,232 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:43,234 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:43,235 : INFO : vocab #8006\n",
      "2020-12-26 19:18:43,237 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:44,750 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:45,502 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/spotbugs/test_spotbugsdisplay.py')[[0.8259830364059275, 0.547650213645081], [0.2388262152671814, 0.7611738], [4.95696278547487, 1.4067682546093065], [6.969615971743114, 6.443188759664073, 7.195928474967369, 6.216876256439818, 0.22631250322425522, 0.7527397153032958]]\n",
      "2020-12-26 19:18:45,506 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:45,510 : INFO : built Dictionary(329 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1203 corpus positions)\n",
      "2020-12-26 19:18:46,494 : INFO : token count processed\n",
      "2020-12-26 19:18:46,500 : INFO : frequencies processed\n",
      "2020-12-26 19:18:47,250 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:47,251 : INFO : entropies processed\n",
      "2020-12-26 19:18:47,252 : INFO : extropies processed\n",
      "2020-12-26 19:18:47,254 : INFO : token count processed\n",
      "2020-12-26 19:18:47,256 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:47,257 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:47,258 : INFO : vocab #8006\n",
      "2020-12-26 19:18:47,259 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:48,772 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:49,520 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/test_auth_utility.py')[[0.7550906944973924, 0.5697711252958191], [0.19545024633407593, 0.80454975], [5.500569913900362, 1.4176994458425263], [6.969615971743114, 6.898279638545452, 7.387278030494868, 6.480617579793697, 0.41766205875175455, 0.4889983919494165]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:18:49,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:49,539 : INFO : built Dictionary(395 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 8860 corpus positions)\n",
      "2020-12-26 19:18:51,140 : INFO : token count processed\n",
      "2020-12-26 19:18:51,149 : INFO : frequencies processed\n",
      "2020-12-26 19:18:51,895 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:51,896 : INFO : entropies processed\n",
      "2020-12-26 19:18:51,897 : INFO : extropies processed\n",
      "2020-12-26 19:18:51,901 : INFO : token count processed\n",
      "2020-12-26 19:18:51,903 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:51,904 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:51,905 : INFO : vocab #8006\n",
      "2020-12-26 19:18:51,907 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:53,418 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:54,167 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_binary_scan_func.py')[[0.7994402526396716, 0.5557283708270166], [0.19440025091171265, 0.80559975], [5.488240869889424, 1.415828482077041], [6.969615971743114, 6.408340164694879, 6.571733122733927, 6.806223013704066, -0.3978828490091866, 0.16339295803904808]]\n",
      "2020-12-26 19:18:54,172 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:54,176 : INFO : built Dictionary(342 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1877 corpus positions)\n",
      "2020-12-26 19:18:55,279 : INFO : token count processed\n",
      "2020-12-26 19:18:55,289 : INFO : frequencies processed\n",
      "2020-12-26 19:18:56,036 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:18:56,037 : INFO : entropies processed\n",
      "2020-12-26 19:18:56,038 : INFO : extropies processed\n",
      "2020-12-26 19:18:56,040 : INFO : token count processed\n",
      "2020-12-26 19:18:56,041 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:18:56,043 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:18:56,043 : INFO : vocab #8006\n",
      "2020-12-26 19:18:56,045 : INFO : diff #{'```'}\n",
      "2020-12-26 19:18:57,557 : INFO : alphabet #8006\n",
      "2020-12-26 19:18:58,307 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_BinaryScan.py')[[0.7452403549914797, 0.5729869797818662], [0.21462035179138184, 0.78537965], [5.258737746910805, 1.4124234264186708], [6.969615971743114, 6.443827478732862, 7.023280649428449, 6.390162801047526, 0.05366467768533578, 0.5794531706955874]]\n",
      "2020-12-26 19:18:58,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:18:58,316 : INFO : built Dictionary(347 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1847 corpus positions)\n",
      "2020-12-26 19:18:59,298 : INFO : token count processed\n",
      "2020-12-26 19:18:59,309 : INFO : frequencies processed\n",
      "2020-12-26 19:19:00,059 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:00,059 : INFO : entropies processed\n",
      "2020-12-26 19:19:00,060 : INFO : extropies processed\n",
      "2020-12-26 19:19:00,063 : INFO : token count processed\n",
      "2020-12-26 19:19:00,064 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:00,065 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:00,066 : INFO : vocab #8006\n",
      "2020-12-26 19:19:00,068 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:01,575 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:02,326 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_blackduck.py')[[0.7323000392927173, 0.5772672039009427], [0.19248300790786743, 0.807517], [5.302157982309252, 1.4137817372809383], [6.969615971743114, 6.509540793861948, 7.04611428012383, 6.433042485481232, 0.07649830838071647, 0.5365734862618821]]\n",
      "2020-12-26 19:19:02,331 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:02,335 : INFO : built Dictionary(354 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1801 corpus positions)\n",
      "2020-12-26 19:19:03,385 : INFO : token count processed\n",
      "2020-12-26 19:19:03,397 : INFO : frequencies processed\n",
      "2020-12-26 19:19:04,145 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:04,146 : INFO : entropies processed\n",
      "2020-12-26 19:19:04,146 : INFO : extropies processed\n",
      "2020-12-26 19:19:04,149 : INFO : token count processed\n",
      "2020-12-26 19:19:04,150 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:04,151 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:04,152 : INFO : vocab #8006\n",
      "2020-12-26 19:19:04,154 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:05,662 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:06,411 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_bom.py')[[0.7827216730515195, 0.5609400587407907], [0.25389474630355835, 0.74610525], [5.2507029788260855, 1.4103878729358128], [6.969615971743114, 6.70060831439398, 7.250347271733195, 6.419877014403899, 0.28073129999008106, 0.5497389573392146]]\n",
      "2020-12-26 19:19:06,417 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:06,419 : INFO : built Dictionary(335 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1955 corpus positions)\n",
      "2020-12-26 19:19:07,319 : INFO : token count processed\n",
      "2020-12-26 19:19:07,330 : INFO : frequencies processed\n",
      "2020-12-26 19:19:08,080 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:08,081 : INFO : entropies processed\n",
      "2020-12-26 19:19:08,082 : INFO : extropies processed\n",
      "2020-12-26 19:19:08,087 : INFO : token count processed\n",
      "2020-12-26 19:19:08,089 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:08,092 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:08,093 : INFO : vocab #8006\n",
      "2020-12-26 19:19:08,096 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:09,614 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:10,363 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_bom_bd.py')[[0.8204884653709787, 0.5493031233220257], [0.2575429677963257, 0.74245703], [5.192878693802241, 1.4104518508707717], [6.969615971743114, 6.3789777505465235, 6.944303984239594, 6.404289738050043, -0.025311987503519262, 0.5653262336930709]]\n",
      "2020-12-26 19:19:10,366 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:10,369 : INFO : built Dictionary(287 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 668 corpus positions)\n",
      "2020-12-26 19:19:11,032 : INFO : token count processed\n",
      "2020-12-26 19:19:11,043 : INFO : frequencies processed\n",
      "2020-12-26 19:19:11,897 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:11,898 : INFO : entropies processed\n",
      "2020-12-26 19:19:11,899 : INFO : extropies processed\n",
      "2020-12-26 19:19:11,904 : INFO : token count processed\n",
      "2020-12-26 19:19:11,906 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:11,909 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:11,909 : INFO : vocab #8006\n",
      "2020-12-26 19:19:11,911 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:13,430 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:14,180 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_corona_lite.py')[[0.8721131609451748, 0.534155744888375], [0.2760584354400635, 0.72394156], [4.999904382062596, 1.4122716018846215], [6.969615971743114, 6.594537906629094, 7.417285002674619, 6.146868875697589, 0.4476690309315057, 0.822747096045525]]\n",
      "2020-12-26 19:19:14,185 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:14,187 : INFO : built Dictionary(336 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1795 corpus positions)\n",
      "2020-12-26 19:19:15,173 : INFO : token count processed\n",
      "2020-12-26 19:19:15,184 : INFO : frequencies processed\n",
      "2020-12-26 19:19:15,934 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:15,935 : INFO : entropies processed\n",
      "2020-12-26 19:19:15,936 : INFO : extropies processed\n",
      "2020-12-26 19:19:15,938 : INFO : token count processed\n",
      "2020-12-26 19:19:15,939 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:15,941 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:15,942 : INFO : vocab #8006\n",
      "2020-12-26 19:19:15,943 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:17,449 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:18,198 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_corona_lite_func.py')[[0.7588634672649263, 0.5685489627884667], [0.17929613590240479, 0.82070386], [5.48473815641031, 1.4153782185533446], [6.969615971743114, 6.507928811366327, 7.001140018096677, 6.476404765012763, 0.03152404635356376, 0.4932112067303507]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:19:18,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:18,208 : INFO : built Dictionary(363 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2075 corpus positions)\n",
      "2020-12-26 19:19:19,489 : INFO : token count processed\n",
      "2020-12-26 19:19:19,500 : INFO : frequencies processed\n",
      "2020-12-26 19:19:20,245 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:20,246 : INFO : entropies processed\n",
      "2020-12-26 19:19:20,247 : INFO : extropies processed\n",
      "2020-12-26 19:19:20,251 : INFO : token count processed\n",
      "2020-12-26 19:19:20,253 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:20,256 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:20,257 : INFO : vocab #8006\n",
      "2020-12-26 19:19:20,260 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:21,777 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:22,525 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_cve.py')[[0.7704154910074393, 0.5648391606825349], [0.2512865662574768, 0.74871343], [5.2473039160268335, 1.4114080482243865], [6.969615971743114, 6.54238466446361, 7.105142613186008, 6.406858023020716, 0.13552664144289395, 0.5627579487223979]]\n",
      "2020-12-26 19:19:22,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:22,534 : INFO : built Dictionary(345 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1986 corpus positions)\n",
      "2020-12-26 19:19:23,483 : INFO : token count processed\n",
      "2020-12-26 19:19:23,494 : INFO : frequencies processed\n",
      "2020-12-26 19:19:24,244 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:24,245 : INFO : entropies processed\n",
      "2020-12-26 19:19:24,246 : INFO : extropies processed\n",
      "2020-12-26 19:19:24,249 : INFO : token count processed\n",
      "2020-12-26 19:19:24,250 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:24,251 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:24,252 : INFO : vocab #8006\n",
      "2020-12-26 19:19:24,254 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:25,788 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:26,541 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_cve_bd.py')[[0.801474271166294, 0.5551009059666387], [0.24637138843536377, 0.7536286], [5.196444642038128, 1.4113550028686825], [6.969615971743114, 6.426532968077849, 6.9670409697794815, 6.429107970041481, -0.0025750019636321397, 0.5405080017016326]]\n",
      "2020-12-26 19:19:26,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:26,548 : INFO : built Dictionary(330 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2256 corpus positions)\n",
      "2020-12-26 19:19:27,479 : INFO : token count processed\n",
      "2020-12-26 19:19:27,490 : INFO : frequencies processed\n",
      "2020-12-26 19:19:28,240 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:28,241 : INFO : entropies processed\n",
      "2020-12-26 19:19:28,242 : INFO : extropies processed\n",
      "2020-12-26 19:19:28,247 : INFO : token count processed\n",
      "2020-12-26 19:19:28,249 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:28,252 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:28,252 : INFO : vocab #8006\n",
      "2020-12-26 19:19:28,254 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:29,786 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:30,536 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_ipCentralScan.py')[[0.7792429284901644, 0.5620367989033309], [0.23949295282363892, 0.76050705], [5.138320349529898, 1.4099378154960336], [6.969615971743114, 6.40953838450538, 6.93089027529617, 6.448264080952324, -0.038725696446944013, 0.5213518907907897]]\n",
      "2020-12-26 19:19:30,541 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:30,544 : INFO : built Dictionary(324 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1148 corpus positions)\n",
      "2020-12-26 19:19:31,377 : INFO : token count processed\n",
      "2020-12-26 19:19:31,389 : INFO : frequencies processed\n",
      "2020-12-26 19:19:32,138 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:32,139 : INFO : entropies processed\n",
      "2020-12-26 19:19:32,140 : INFO : extropies processed\n",
      "2020-12-26 19:19:32,144 : INFO : token count processed\n",
      "2020-12-26 19:19:32,147 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:32,149 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:32,150 : INFO : vocab #8006\n",
      "2020-12-26 19:19:32,154 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:33,680 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:34,429 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_ipcReport.py')[[0.8911472975034259, 0.5287795410331798], [0.33953070640563965, 0.6604693], [4.8720574300204476, 1.4022956037422203], [6.969615971743114, 6.513136741171774, 7.292119164766557, 6.19063354814833, 0.32250319302344366, 0.7789824235947833]]\n",
      "2020-12-26 19:19:34,435 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:34,438 : INFO : built Dictionary(407 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2664 corpus positions)\n",
      "2020-12-26 19:19:35,952 : INFO : token count processed\n",
      "2020-12-26 19:19:35,962 : INFO : frequencies processed\n",
      "2020-12-26 19:19:36,817 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:36,818 : INFO : entropies processed\n",
      "2020-12-26 19:19:36,818 : INFO : extropies processed\n",
      "2020-12-26 19:19:36,821 : INFO : token count processed\n",
      "2020-12-26 19:19:36,822 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:36,824 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:36,826 : INFO : vocab #8006\n",
      "2020-12-26 19:19:36,829 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:38,352 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:39,101 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_triage.py')[[0.7570437988084598, 0.5691377760065802], [0.24749284982681274, 0.75250715], [5.456077797437091, 1.4145234656641965], [6.969615971743114, 6.770302123271581, 7.243498278047635, 6.496419816967059, 0.2738823063045217, 0.4731961547760539]]\n",
      "2020-12-26 19:19:39,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:39,108 : INFO : built Dictionary(342 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 1917 corpus positions)\n",
      "2020-12-26 19:19:40,087 : INFO : token count processed\n",
      "2020-12-26 19:19:40,099 : INFO : frequencies processed\n",
      "2020-12-26 19:19:40,848 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:40,849 : INFO : entropies processed\n",
      "2020-12-26 19:19:40,850 : INFO : extropies processed\n",
      "2020-12-26 19:19:40,855 : INFO : token count processed\n",
      "2020-12-26 19:19:40,858 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:40,860 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:40,861 : INFO : vocab #8006\n",
      "2020-12-26 19:19:40,863 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:42,381 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:43,128 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/test_UploadBom.py')[[0.7874754939381989, 0.5594482292995142], [0.23126167058944702, 0.7687383], [5.154139383131056, 1.410067704814359], [6.969615971743114, 6.592422117733454, 7.133767875842787, 6.42827021363378, 0.16415190409967373, 0.5413457581093333]]\n",
      "2020-12-26 19:19:43,133 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:43,137 : INFO : built Dictionary(364 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2370 corpus positions)\n",
      "2020-12-26 19:19:44,275 : INFO : token count processed\n",
      "2020-12-26 19:19:44,282 : INFO : frequencies processed\n",
      "2020-12-26 19:19:45,029 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:45,029 : INFO : entropies processed\n",
      "2020-12-26 19:19:45,030 : INFO : extropies processed\n",
      "2020-12-26 19:19:45,032 : INFO : token count processed\n",
      "2020-12-26 19:19:45,033 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:45,035 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:45,035 : INFO : vocab #8006\n",
      "2020-12-26 19:19:45,037 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:46,545 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:47,300 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/unused/test_bd_image.py')[[0.7654881977429338, 0.5664155678176934], [0.22438079118728638, 0.7756192], [5.23103510652953, 1.412260511419719], [6.969615971743114, 6.446379772539096, 6.902597987798025, 6.513397756484185, -0.06701798394508884, 0.4562182152589287]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:19:47,306 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:47,310 : INFO : built Dictionary(359 unique tokens: ['\"', '\",', '#', '(', ')']...) from 2 documents (total 2641 corpus positions)\n",
      "2020-12-26 19:19:48,622 : INFO : token count processed\n",
      "2020-12-26 19:19:48,635 : INFO : frequencies processed\n",
      "2020-12-26 19:19:49,379 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:49,380 : INFO : entropies processed\n",
      "2020-12-26 19:19:49,381 : INFO : extropies processed\n",
      "2020-12-26 19:19:49,384 : INFO : token count processed\n",
      "2020-12-26 19:19:49,385 : INFO : alphabet_source #8007\n",
      "2020-12-26 19:19:49,386 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:49,387 : INFO : vocab #8006\n",
      "2020-12-26 19:19:49,388 : INFO : diff #{'```'}\n",
      "2020-12-26 19:19:50,896 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:51,644 : INFO : Computed distances or similarities ('294', 'sacp-python-common/test/python/third_party/unused/test_ipc.py')[[0.7979721865081925, 0.5561821297926087], [0.34167009592056274, 0.6583299], [5.349443768505646, 1.4135272521739783], [6.969615971743114, 6.3302275852634216, 6.846974168715417, 6.452869388291119, -0.12264180302769656, 0.5167465834519955]]\n",
      "2020-12-26 19:19:51,649 : INFO : Removed 0 and 1 OOV words from document 1 and 2 (respectively).\n",
      "2020-12-26 19:19:51,650 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:51,654 : INFO : built Dictionary(344 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1853 corpus positions)\n",
      "2020-12-26 19:19:52,423 : INFO : token count processed\n",
      "2020-12-26 19:19:52,435 : INFO : frequencies processed\n",
      "2020-12-26 19:19:53,183 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:53,184 : INFO : entropies processed\n",
      "2020-12-26 19:19:53,185 : INFO : extropies processed\n",
      "2020-12-26 19:19:53,190 : INFO : token count processed\n",
      "2020-12-26 19:19:53,193 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:19:53,195 : INFO : alphabet_target #8010\n",
      "2020-12-26 19:19:53,196 : INFO : vocab #8006\n",
      "2020-12-26 19:19:53,198 : INFO : diff #set()\n",
      "2020-12-26 19:19:54,709 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:55,461 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/auth_utility.py')[[1.0369682936753288, 0.49092565805022265], [0.5436919331550598, 0.45630807], [4.594312789884633, 1.4051289604991926], [6.5447135052193754, 6.895875762815869, 7.250760532069591, 6.189828735965654, 0.7060470268502153, 0.35488476925372137]]\n",
      "2020-12-26 19:19:55,468 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:55,472 : INFO : built Dictionary(408 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2866 corpus positions)\n",
      "2020-12-26 19:19:56,638 : INFO : token count processed\n",
      "2020-12-26 19:19:56,644 : INFO : frequencies processed\n",
      "2020-12-26 19:19:57,495 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:19:57,496 : INFO : entropies processed\n",
      "2020-12-26 19:19:57,497 : INFO : extropies processed\n",
      "2020-12-26 19:19:57,500 : INFO : token count processed\n",
      "2020-12-26 19:19:57,501 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:19:57,502 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:19:57,503 : INFO : vocab #8006\n",
      "2020-12-26 19:19:57,505 : INFO : diff #set()\n",
      "2020-12-26 19:19:59,012 : INFO : alphabet #8006\n",
      "2020-12-26 19:19:59,758 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/bandit/bandit.py')[[1.0799166573806893, 0.48078849527525513], [0.5699241459369659, 0.43007585], [4.652530185456991, 1.4071232886738698], [6.5447135052193754, 7.046810312550396, 7.394828950425492, 6.196694867344281, 0.8501154452061161, 0.34801863787509557]]\n",
      "2020-12-26 19:19:59,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:19:59,769 : INFO : built Dictionary(351 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2886 corpus positions)\n",
      "2020-12-26 19:20:00,594 : INFO : token count processed\n",
      "2020-12-26 19:20:00,607 : INFO : frequencies processed\n",
      "2020-12-26 19:20:01,355 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:01,356 : INFO : entropies processed\n",
      "2020-12-26 19:20:01,356 : INFO : extropies processed\n",
      "2020-12-26 19:20:01,359 : INFO : token count processed\n",
      "2020-12-26 19:20:01,360 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:01,361 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:01,362 : INFO : vocab #8006\n",
      "2020-12-26 19:20:01,364 : INFO : diff #set()\n",
      "2020-12-26 19:20:02,867 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:03,615 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/bandit/banditReport.py')[[1.098194292841092, 0.47660028597539206], [0.6089715361595154, 0.39102846], [4.533689055389995, 1.4032229312445001], [6.5447135052193754, 6.426571231608991, 6.707500462384408, 6.2637842744439585, 0.16278695716503222, 0.280929230775417]]\n",
      "2020-12-26 19:20:03,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:03,621 : INFO : built Dictionary(243 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1009 corpus positions)\n",
      "2020-12-26 19:20:04,056 : INFO : token count processed\n",
      "2020-12-26 19:20:04,070 : INFO : frequencies processed\n",
      "2020-12-26 19:20:04,817 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:04,818 : INFO : entropies processed\n",
      "2020-12-26 19:20:04,819 : INFO : extropies processed\n",
      "2020-12-26 19:20:04,823 : INFO : token count processed\n",
      "2020-12-26 19:20:04,826 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:04,829 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:04,829 : INFO : vocab #8006\n",
      "2020-12-26 19:20:04,831 : INFO : diff #set()\n",
      "2020-12-26 19:20:06,351 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:07,099 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/cave/caveCa.py')[[1.0841103751004195, 0.47982103632674283], [0.5917401611804962, 0.40825984], [4.083274571476652, 1.3909988597366896], [6.5447135052193754, 6.098070142413432, 6.736050471732675, 5.906733175900133, 0.19133696651329934, 0.6379803293192428]]\n",
      "2020-12-26 19:20:07,103 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:07,104 : INFO : built Dictionary(221 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 685 corpus positions)\n",
      "2020-12-26 19:20:07,436 : INFO : token count processed\n",
      "2020-12-26 19:20:07,448 : INFO : frequencies processed\n",
      "2020-12-26 19:20:08,197 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:08,198 : INFO : entropies processed\n",
      "2020-12-26 19:20:08,198 : INFO : extropies processed\n",
      "2020-12-26 19:20:08,200 : INFO : token count processed\n",
      "2020-12-26 19:20:08,202 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:08,203 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:08,204 : INFO : vocab #8006\n",
      "2020-12-26 19:20:08,206 : INFO : diff #set()\n",
      "2020-12-26 19:20:09,717 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:10,467 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/cave/caveSsl.py')[[1.0891904723388555, 0.47865429851424546], [0.5790420472621918, 0.42095795], [3.797902689682947, 1.3817425704661987], [6.5447135052193754, 5.941919007331087, 6.760967611965115, 5.725664900585348, 0.21625410674573953, 0.8190486046340277]]\n",
      "2020-12-26 19:20:10,474 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:10,477 : INFO : built Dictionary(307 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2725 corpus positions)\n",
      "2020-12-26 19:20:11,135 : INFO : token count processed\n",
      "2020-12-26 19:20:11,141 : INFO : frequencies processed\n",
      "2020-12-26 19:20:11,890 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:11,891 : INFO : entropies processed\n",
      "2020-12-26 19:20:11,892 : INFO : extropies processed\n",
      "2020-12-26 19:20:11,895 : INFO : token count processed\n",
      "2020-12-26 19:20:11,896 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:11,898 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:11,898 : INFO : vocab #8006\n",
      "2020-12-26 19:20:11,900 : INFO : diff #set()\n",
      "2020-12-26 19:20:13,515 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:14,264 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/cave/caveZap.py')[[1.0816374784481162, 0.48039104327882826], [0.6015342175960541, 0.39846578], [4.311132754418151, 1.3954655757273817], [6.5447135052193754, 6.3389906976029495, 6.653714558619719, 6.229989644202607, 0.10900105340034383, 0.31472386101676975]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:20:14,269 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:14,273 : INFO : built Dictionary(288 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1845 corpus positions)\n",
      "2020-12-26 19:20:14,899 : INFO : token count processed\n",
      "2020-12-26 19:20:14,910 : INFO : frequencies processed\n",
      "2020-12-26 19:20:15,656 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:15,656 : INFO : entropies processed\n",
      "2020-12-26 19:20:15,657 : INFO : extropies processed\n",
      "2020-12-26 19:20:15,659 : INFO : token count processed\n",
      "2020-12-26 19:20:15,660 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:15,662 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:15,662 : INFO : vocab #8006\n",
      "2020-12-26 19:20:15,664 : INFO : diff #set()\n",
      "2020-12-26 19:20:17,176 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:17,924 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/csbcicd_report/aggregator.py')[[1.0676217476201284, 0.4836474568673012], [0.5646955966949463, 0.4353044], [4.175188482808195, 1.3956295295329844], [6.5447135052193754, 6.424670910428789, 6.82834836256159, 6.141036053086575, 0.2836348573422143, 0.4036774521328006]]\n",
      "2020-12-26 19:20:17,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:17,941 : INFO : built Dictionary(460 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 7748 corpus positions)\n",
      "2020-12-26 19:20:19,353 : INFO : token count processed\n",
      "2020-12-26 19:20:19,362 : INFO : frequencies processed\n",
      "2020-12-26 19:20:20,111 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:20,112 : INFO : entropies processed\n",
      "2020-12-26 19:20:20,113 : INFO : extropies processed\n",
      "2020-12-26 19:20:20,122 : INFO : token count processed\n",
      "2020-12-26 19:20:20,125 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:20,126 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:20,127 : INFO : vocab #8006\n",
      "2020-12-26 19:20:20,129 : INFO : diff #set()\n",
      "2020-12-26 19:20:21,634 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:22,381 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicd_func.py')[[1.0477798780968794, 0.488333736792725], [0.5482818484306335, 0.45171815], [4.949750815434249, 1.413708031292092], [6.5447135052193754, 6.856857092706523, 7.010481532172713, 6.391089065753185, 0.46576802695333797, 0.1536244394661903]]\n",
      "2020-12-26 19:20:22,388 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:22,392 : INFO : built Dictionary(377 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3353 corpus positions)\n",
      "2020-12-26 19:20:23,464 : INFO : token count processed\n",
      "2020-12-26 19:20:23,471 : INFO : frequencies processed\n",
      "2020-12-26 19:20:24,219 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:24,220 : INFO : entropies processed\n",
      "2020-12-26 19:20:24,221 : INFO : extropies processed\n",
      "2020-12-26 19:20:24,224 : INFO : token count processed\n",
      "2020-12-26 19:20:24,225 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:24,227 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:24,227 : INFO : vocab #8006\n",
      "2020-12-26 19:20:24,229 : INFO : diff #set()\n",
      "2020-12-26 19:20:25,734 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:26,480 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicdReport.py')[[1.0766964768808724, 0.4815340186361591], [0.5659644901752472, 0.4340355], [4.4308523481841515, 1.4019373207660082], [6.5447135052193754, 6.553499792717194, 6.85535305931808, 6.242860238618489, 0.3106395540987048, 0.3018532666008866]]\n",
      "2020-12-26 19:20:26,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:26,487 : INFO : built Dictionary(283 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 979 corpus positions)\n",
      "2020-12-26 19:20:27,052 : INFO : token count processed\n",
      "2020-12-26 19:20:27,063 : INFO : frequencies processed\n",
      "2020-12-26 19:20:27,807 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:27,808 : INFO : entropies processed\n",
      "2020-12-26 19:20:27,809 : INFO : extropies processed\n",
      "2020-12-26 19:20:27,812 : INFO : token count processed\n",
      "2020-12-26 19:20:27,815 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:27,817 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:27,818 : INFO : vocab #8006\n",
      "2020-12-26 19:20:27,821 : INFO : diff #set()\n",
      "2020-12-26 19:20:29,344 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:30,089 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/ctsm2csdl.py')[[1.0867150782470347, 0.4792221086742996], [0.6166754066944122, 0.3833246], [4.154845348584491, 1.3905600439210388], [6.5447135052193754, 6.637223258470346, 7.19729786603787, 5.984638897651852, 0.6525843608184942, 0.5600746075675236]]\n",
      "2020-12-26 19:20:30,097 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:30,102 : INFO : built Dictionary(464 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3415 corpus positions)\n",
      "2020-12-26 19:20:31,508 : INFO : token count processed\n",
      "2020-12-26 19:20:31,516 : INFO : frequencies processed\n",
      "2020-12-26 19:20:32,265 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:32,266 : INFO : entropies processed\n",
      "2020-12-26 19:20:32,267 : INFO : extropies processed\n",
      "2020-12-26 19:20:32,270 : INFO : token count processed\n",
      "2020-12-26 19:20:32,272 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:32,277 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:32,278 : INFO : vocab #8006\n",
      "2020-12-26 19:20:32,281 : INFO : diff #set()\n",
      "2020-12-26 19:20:33,797 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:34,545 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/custom_scan/customScan.py')[[1.0314442005664985, 0.492260629024974], [0.5343486666679382, 0.46565133], [5.0898063976262735, 1.416467970989945], [6.5447135052193754, 7.250907518628656, 7.534858386455254, 6.260762637392777, 0.9901448812358788, 0.28395086782659806]]\n",
      "2020-12-26 19:20:34,548 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:34,550 : INFO : built Dictionary(157 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 289 corpus positions)\n",
      "2020-12-26 19:20:34,702 : INFO : token count processed\n",
      "2020-12-26 19:20:34,713 : INFO : frequencies processed\n",
      "2020-12-26 19:20:35,462 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:35,463 : INFO : entropies processed\n",
      "2020-12-26 19:20:35,464 : INFO : extropies processed\n",
      "2020-12-26 19:20:35,466 : INFO : token count processed\n",
      "2020-12-26 19:20:35,467 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:35,468 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:20:35,469 : INFO : vocab #8006\n",
      "2020-12-26 19:20:35,471 : INFO : diff #set()\n",
      "2020-12-26 19:20:36,980 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:37,729 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/fireException.py')[[1.1231957591392423, 0.47098812989594835], [0.6448111236095428, 0.35518888], [2.939829017466402, 1.328231371910075], [6.5447135052193754, 5.304981337622145, 6.881155063691978, 4.968539779149543, 0.33644155847260215, 1.5761737260698325]]\n",
      "2020-12-26 19:20:37,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:37,736 : INFO : built Dictionary(245 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 745 corpus positions)\n",
      "2020-12-26 19:20:38,183 : INFO : token count processed\n",
      "2020-12-26 19:20:38,194 : INFO : frequencies processed\n",
      "2020-12-26 19:20:38,943 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:38,944 : INFO : entropies processed\n",
      "2020-12-26 19:20:38,945 : INFO : extropies processed\n",
      "2020-12-26 19:20:38,948 : INFO : token count processed\n",
      "2020-12-26 19:20:38,950 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:38,951 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:38,952 : INFO : vocab #8006\n",
      "2020-12-26 19:20:38,954 : INFO : diff #set()\n",
      "2020-12-26 19:20:40,561 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:41,310 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/gosec/gosec_display.py')[[1.1059503211482664, 0.47484500938025526], [0.6105620861053467, 0.3894379], [3.7567958110719153, 1.3779508091531052], [6.5447135052193754, 6.525221949271511, 7.23592711497784, 5.834008339513047, 0.6912136097584645, 0.7107051657063286]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:20:41,318 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:41,320 : INFO : built Dictionary(423 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3293 corpus positions)\n",
      "2020-12-26 19:20:42,570 : INFO : token count processed\n",
      "2020-12-26 19:20:42,580 : INFO : frequencies processed\n",
      "2020-12-26 19:20:43,329 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:43,330 : INFO : entropies processed\n",
      "2020-12-26 19:20:43,331 : INFO : extropies processed\n",
      "2020-12-26 19:20:43,334 : INFO : token count processed\n",
      "2020-12-26 19:20:43,335 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:43,337 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:43,337 : INFO : vocab #8006\n",
      "2020-12-26 19:20:43,339 : INFO : diff #set()\n",
      "2020-12-26 19:20:44,844 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:45,592 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/gosec/gosec_report.py')[[1.0871467313755885, 0.47912299838206585], [0.5879237353801727, 0.41207626], [4.545372163788727, 1.4044892255469719], [6.5447135052193754, 6.900194567319838, 7.17502284644412, 6.269885226095093, 0.6303093412247449, 0.2748282791242822]]\n",
      "2020-12-26 19:20:45,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:45,602 : INFO : built Dictionary(348 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3750 corpus positions)\n",
      "2020-12-26 19:20:46,421 : INFO : token count processed\n",
      "2020-12-26 19:20:46,432 : INFO : frequencies processed\n",
      "2020-12-26 19:20:47,180 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:47,180 : INFO : entropies processed\n",
      "2020-12-26 19:20:47,181 : INFO : extropies processed\n",
      "2020-12-26 19:20:47,184 : INFO : token count processed\n",
      "2020-12-26 19:20:47,185 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:47,187 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:47,187 : INFO : vocab #8006\n",
      "2020-12-26 19:20:47,189 : INFO : diff #set()\n",
      "2020-12-26 19:20:48,697 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:49,449 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/harden_check/harden_func.py')[[1.0870949417465163, 0.4791348874446426], [0.611455887556076, 0.3885441], [4.508604607874869, 1.4005771588709819], [6.5447135052193754, 6.350617617253523, 6.648589909049971, 6.246741213422927, 0.10387640383059527, 0.297972291796448]]\n",
      "2020-12-26 19:20:49,454 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:49,458 : INFO : built Dictionary(362 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1938 corpus positions)\n",
      "2020-12-26 19:20:50,399 : INFO : token count processed\n",
      "2020-12-26 19:20:50,410 : INFO : frequencies processed\n",
      "2020-12-26 19:20:51,157 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:51,158 : INFO : entropies processed\n",
      "2020-12-26 19:20:51,159 : INFO : extropies processed\n",
      "2020-12-26 19:20:51,164 : INFO : token count processed\n",
      "2020-12-26 19:20:51,166 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:51,169 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:51,170 : INFO : vocab #8006\n",
      "2020-12-26 19:20:51,173 : INFO : diff #set()\n",
      "2020-12-26 19:20:52,688 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:53,440 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/harden_check/hardenPostCheck.py')[[1.0635950848408204, 0.48459119104615284], [0.558100014925003, 0.44189999], [4.507712257147028, 1.4034132076965609], [6.5447135052193754, 6.941677454537802, 7.317313496704115, 6.169077463053062, 0.7725999914847392, 0.3756360421663123]]\n",
      "2020-12-26 19:20:53,445 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:53,448 : INFO : built Dictionary(299 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1737 corpus positions)\n",
      "2020-12-26 19:20:54,094 : INFO : token count processed\n",
      "2020-12-26 19:20:54,105 : INFO : frequencies processed\n",
      "2020-12-26 19:20:54,850 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:54,851 : INFO : entropies processed\n",
      "2020-12-26 19:20:54,852 : INFO : extropies processed\n",
      "2020-12-26 19:20:54,857 : INFO : token count processed\n",
      "2020-12-26 19:20:54,859 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:54,862 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:20:54,863 : INFO : vocab #8006\n",
      "2020-12-26 19:20:54,866 : INFO : diff #set()\n",
      "2020-12-26 19:20:56,376 : INFO : alphabet #8006\n",
      "2020-12-26 19:20:57,125 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/harden_check/hardenReport.py')[[1.077319766063197, 0.4813895368141303], [0.5864999294281006, 0.41350007], [4.174192197570899, 1.390967192011047], [6.5447135052193754, 6.494384552966903, 6.91325282461671, 6.125845233569568, 0.36853931939733453, 0.41886827164980733]]\n",
      "2020-12-26 19:20:57,133 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:20:57,138 : INFO : built Dictionary(462 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3868 corpus positions)\n",
      "2020-12-26 19:20:58,746 : INFO : token count processed\n",
      "2020-12-26 19:20:58,755 : INFO : frequencies processed\n",
      "2020-12-26 19:20:59,502 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:20:59,503 : INFO : entropies processed\n",
      "2020-12-26 19:20:59,504 : INFO : extropies processed\n",
      "2020-12-26 19:20:59,507 : INFO : token count processed\n",
      "2020-12-26 19:20:59,509 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:20:59,510 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:20:59,511 : INFO : vocab #8006\n",
      "2020-12-26 19:20:59,513 : INFO : diff #set()\n",
      "2020-12-26 19:21:01,020 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:01,770 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/psb_mapping.py')[[1.1336087815900822, 0.46868948451493775], [0.6782631874084473, 0.3217368], [4.236468023103722, 1.3929957526455712], [6.5447135052193754, 6.562992713112968, 6.907863324394452, 6.199842893937891, 0.36314981917507616, 0.34487061128148344]]\n",
      "2020-12-26 19:21:01,779 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:01,784 : INFO : built Dictionary(478 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 4307 corpus positions)\n",
      "2020-12-26 19:21:03,376 : INFO : token count processed\n",
      "2020-12-26 19:21:03,384 : INFO : frequencies processed\n",
      "2020-12-26 19:21:04,131 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:04,132 : INFO : entropies processed\n",
      "2020-12-26 19:21:04,133 : INFO : extropies processed\n",
      "2020-12-26 19:21:04,136 : INFO : token count processed\n",
      "2020-12-26 19:21:04,138 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:04,139 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:04,140 : INFO : vocab #8006\n",
      "2020-12-26 19:21:04,142 : INFO : diff #set()\n",
      "2020-12-26 19:21:05,750 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:06,501 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push.py')[[1.0710580898391189, 0.4828449790501437], [0.5490343570709229, 0.45096564], [4.812414310268052, 1.4120894685569043], [6.5447135052193754, 6.963414455813236, 7.234453426308759, 6.2736745347238525, 0.6897399210893838, 0.27103897049552295]]\n",
      "2020-12-26 19:21:06,513 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:06,517 : INFO : built Dictionary(529 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 6896 corpus positions)\n",
      "2020-12-26 19:21:08,300 : INFO : token count processed\n",
      "2020-12-26 19:21:08,309 : INFO : frequencies processed\n",
      "2020-12-26 19:21:09,058 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:09,059 : INFO : entropies processed\n",
      "2020-12-26 19:21:09,060 : INFO : extropies processed\n",
      "2020-12-26 19:21:09,070 : INFO : token count processed\n",
      "2020-12-26 19:21:09,072 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:09,074 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:09,074 : INFO : vocab #8006\n",
      "2020-12-26 19:21:09,076 : INFO : diff #set()\n",
      "2020-12-26 19:21:10,592 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:11,342 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push_func.py')[[1.0404999001197848, 0.4900759857627518], [0.5371541082859039, 0.4628459], [5.198798698528802, 1.4182795734447933], [6.5447135052193754, 6.923627972311028, 7.079596933023337, 6.388744544507066, 0.5348834278039618, 0.15596896071230937]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:21:11,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:11,360 : INFO : built Dictionary(586 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 8132 corpus positions)\n",
      "2020-12-26 19:21:13,580 : INFO : token count processed\n",
      "2020-12-26 19:21:13,586 : INFO : frequencies processed\n",
      "2020-12-26 19:21:14,335 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:14,336 : INFO : entropies processed\n",
      "2020-12-26 19:21:14,337 : INFO : extropies processed\n",
      "2020-12-26 19:21:14,346 : INFO : token count processed\n",
      "2020-12-26 19:21:14,348 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:14,351 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:14,352 : INFO : vocab #8006\n",
      "2020-12-26 19:21:14,355 : INFO : diff #set()\n",
      "2020-12-26 19:21:15,872 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:16,621 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/spotbugs/spotbugs.py')[[1.062957212175344, 0.4847410281212384], [0.5520928204059601, 0.44790718], [5.102063065018275, 1.4162224656538775], [6.5447135052193754, 7.229383614478795, 7.412158610961205, 6.361938508736966, 0.8674451057418295, 0.1827749964824097]]\n",
      "2020-12-26 19:21:16,624 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:16,627 : INFO : built Dictionary(222 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 541 corpus positions)\n",
      "2020-12-26 19:21:16,996 : INFO : token count processed\n",
      "2020-12-26 19:21:17,008 : INFO : frequencies processed\n",
      "2020-12-26 19:21:17,758 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:17,758 : INFO : entropies processed\n",
      "2020-12-26 19:21:17,759 : INFO : extropies processed\n",
      "2020-12-26 19:21:17,763 : INFO : token count processed\n",
      "2020-12-26 19:21:17,765 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:17,767 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:17,768 : INFO : vocab #8006\n",
      "2020-12-26 19:21:17,770 : INFO : diff #set()\n",
      "2020-12-26 19:21:19,281 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:20,030 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/spotbugs/spotbugsdisplay.py')[[1.0782825065060975, 0.4811665386536641], [0.5862549841403961, 0.41374502], [3.6550455468258036, 1.377925043862341], [6.5447135052193754, 6.400449261283311, 7.206932118457177, 5.73823064804551, 0.6622186132378012, 0.806482857173866]]\n",
      "2020-12-26 19:21:20,033 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:20,035 : INFO : built Dictionary(129 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 206 corpus positions)\n",
      "2020-12-26 19:21:20,103 : INFO : token count processed\n",
      "2020-12-26 19:21:20,109 : INFO : frequencies processed\n",
      "2020-12-26 19:21:20,875 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:20,876 : INFO : entropies processed\n",
      "2020-12-26 19:21:20,877 : INFO : extropies processed\n",
      "2020-12-26 19:21:20,878 : INFO : token count processed\n",
      "2020-12-26 19:21:20,880 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:20,881 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:21:20,882 : INFO : vocab #8006\n",
      "2020-12-26 19:21:20,884 : INFO : diff #set()\n",
      "2020-12-26 19:21:22,396 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:23,148 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/template/__init__.py')[[1.1790879870812268, 0.45890758240535634], [0.6605985462665558, 0.33940145], [2.1556390622295662, 1.2407663947533205], [6.5447135052193754, 4.271370634378849, 6.6982775629942, 4.117806576604025, 0.1535640577748243, 2.4269069286153506]]\n",
      "2020-12-26 19:21:23,173 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:23,178 : INFO : built Dictionary(703 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 14687 corpus positions)\n",
      "2020-12-26 19:21:26,210 : INFO : token count processed\n",
      "2020-12-26 19:21:26,216 : INFO : frequencies processed\n",
      "2020-12-26 19:21:26,966 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:26,967 : INFO : entropies processed\n",
      "2020-12-26 19:21:26,971 : INFO : extropies processed\n",
      "2020-12-26 19:21:26,978 : INFO : token count processed\n",
      "2020-12-26 19:21:26,979 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:26,981 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:26,981 : INFO : vocab #8006\n",
      "2020-12-26 19:21:26,983 : INFO : diff #set()\n",
      "2020-12-26 19:21:28,616 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:29,367 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/binary_scan_func.py')[[1.0044150843389534, 0.49889866016938067], [0.5182417035102844, 0.4817583], [5.491876405913103, 1.4231080981525202], [6.5447135052193754, 7.369295554021139, 7.555814142980618, 6.3581949162598965, 1.0111006377612428, 0.18651858895947893]]\n",
      "2020-12-26 19:21:29,377 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:29,380 : INFO : built Dictionary(514 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 5012 corpus positions)\n",
      "2020-12-26 19:21:31,156 : INFO : token count processed\n",
      "2020-12-26 19:21:31,166 : INFO : frequencies processed\n",
      "2020-12-26 19:21:31,916 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:31,917 : INFO : entropies processed\n",
      "2020-12-26 19:21:31,918 : INFO : extropies processed\n",
      "2020-12-26 19:21:31,921 : INFO : token count processed\n",
      "2020-12-26 19:21:31,923 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:31,924 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:31,925 : INFO : vocab #8006\n",
      "2020-12-26 19:21:31,927 : INFO : diff #set()\n",
      "2020-12-26 19:21:33,441 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:34,193 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/binaryScan.py')[[1.0065203326065557, 0.4983752139211853], [0.5071088373661041, 0.49289116], [5.206793015578223, 1.4185538654617165], [6.5447135052193754, 7.271825719524831, 7.503910611639739, 6.312628613104467, 0.9591971064203637, 0.23208489211490857]]\n",
      "2020-12-26 19:21:34,202 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:34,207 : INFO : built Dictionary(489 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 4304 corpus positions)\n",
      "2020-12-26 19:21:35,808 : INFO : token count processed\n",
      "2020-12-26 19:21:35,818 : INFO : frequencies processed\n",
      "2020-12-26 19:21:36,566 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:36,567 : INFO : entropies processed\n",
      "2020-12-26 19:21:36,568 : INFO : extropies processed\n",
      "2020-12-26 19:21:36,571 : INFO : token count processed\n",
      "2020-12-26 19:21:36,572 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:36,573 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:36,574 : INFO : vocab #8006\n",
      "2020-12-26 19:21:36,576 : INFO : diff #set()\n",
      "2020-12-26 19:21:38,084 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:38,832 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/blackduck.py')[[1.0640864234326757, 0.4844758381468115], [0.5444464385509491, 0.45555356], [4.899453123948885, 1.4115851265840074], [6.5447135052193754, 7.141932166468383, 7.408438721054157, 6.278206950633601, 0.8637252158347817, 0.2665065545857743]]\n",
      "2020-12-26 19:21:38,836 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:38,839 : INFO : built Dictionary(249 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 810 corpus positions)\n",
      "2020-12-26 19:21:39,301 : INFO : token count processed\n",
      "2020-12-26 19:21:39,307 : INFO : frequencies processed\n",
      "2020-12-26 19:21:40,059 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:40,060 : INFO : entropies processed\n",
      "2020-12-26 19:21:40,061 : INFO : extropies processed\n",
      "2020-12-26 19:21:40,063 : INFO : token count processed\n",
      "2020-12-26 19:21:40,064 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:40,065 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:40,065 : INFO : vocab #8006\n",
      "2020-12-26 19:21:40,067 : INFO : diff #set()\n",
      "2020-12-26 19:21:41,569 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:42,320 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/bom.py')[[1.0108882600861442, 0.49729267401320504], [0.5364832580089569, 0.46351674], [4.310298681647991, 1.3971918647526549], [6.5447135052193754, 6.521729764375934, 7.138610031316501, 5.927833238278808, 0.5938965260971258, 0.6168802669405675]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:21:42,324 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:42,325 : INFO : built Dictionary(247 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 971 corpus positions)\n",
      "2020-12-26 19:21:42,800 : INFO : token count processed\n",
      "2020-12-26 19:21:42,808 : INFO : frequencies processed\n",
      "2020-12-26 19:21:43,558 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:43,559 : INFO : entropies processed\n",
      "2020-12-26 19:21:43,560 : INFO : extropies processed\n",
      "2020-12-26 19:21:43,562 : INFO : token count processed\n",
      "2020-12-26 19:21:43,563 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:43,565 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:43,565 : INFO : vocab #8006\n",
      "2020-12-26 19:21:43,567 : INFO : diff #set()\n",
      "2020-12-26 19:21:45,182 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:45,934 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/bom_bd.py')[[1.049881132606414, 0.4878331646130646], [0.5463708341121674, 0.45362917], [3.993743542157264, 1.3861331567546125], [6.5447135052193754, 6.387061504963217, 6.982787113763617, 5.948987896418975, 0.4380736085442418, 0.5957256088004002]]\n",
      "2020-12-26 19:21:45,940 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:45,944 : INFO : built Dictionary(436 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2237 corpus positions)\n",
      "2020-12-26 19:21:47,286 : INFO : token count processed\n",
      "2020-12-26 19:21:47,297 : INFO : frequencies processed\n",
      "2020-12-26 19:21:48,044 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:48,045 : INFO : entropies processed\n",
      "2020-12-26 19:21:48,046 : INFO : extropies processed\n",
      "2020-12-26 19:21:48,049 : INFO : token count processed\n",
      "2020-12-26 19:21:48,050 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:48,051 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:48,052 : INFO : vocab #8006\n",
      "2020-12-26 19:21:48,054 : INFO : diff #set()\n",
      "2020-12-26 19:21:49,561 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:50,310 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/corona_lite/corona_lite.py')[[0.9917120074076503, 0.5020806202306168], [0.4945625066757202, 0.5054375], [5.181665191450268, 1.4183278690888574], [6.5447135052193754, 7.267710126411932, 7.579312987854072, 6.233110643777236, 1.0345994826346967, 0.31160286144214044]]\n",
      "2020-12-26 19:21:50,315 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:50,319 : INFO : built Dictionary(380 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2092 corpus positions)\n",
      "2020-12-26 19:21:51,294 : INFO : token count processed\n",
      "2020-12-26 19:21:51,304 : INFO : frequencies processed\n",
      "2020-12-26 19:21:52,052 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:52,053 : INFO : entropies processed\n",
      "2020-12-26 19:21:52,054 : INFO : extropies processed\n",
      "2020-12-26 19:21:52,056 : INFO : token count processed\n",
      "2020-12-26 19:21:52,057 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:52,058 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:52,059 : INFO : vocab #8006\n",
      "2020-12-26 19:21:52,061 : INFO : diff #set()\n",
      "2020-12-26 19:21:53,568 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:54,315 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/corona_lite/corona_lite_func.py')[[0.981094432217736, 0.5047714958648135], [0.5048016607761383, 0.49519834], [5.0042844539045745, 1.415057832251683], [6.5447135052193754, 7.097365282615124, 7.397435887507948, 6.244642900326552, 0.8527223822885723, 0.30007060489282367]]\n",
      "2020-12-26 19:21:54,319 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:54,321 : INFO : built Dictionary(229 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 754 corpus positions)\n",
      "2020-12-26 19:21:54,714 : INFO : token count processed\n",
      "2020-12-26 19:21:54,726 : INFO : frequencies processed\n",
      "2020-12-26 19:21:55,474 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:55,475 : INFO : entropies processed\n",
      "2020-12-26 19:21:55,476 : INFO : extropies processed\n",
      "2020-12-26 19:21:55,478 : INFO : token count processed\n",
      "2020-12-26 19:21:55,479 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:55,481 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:55,481 : INFO : vocab #8006\n",
      "2020-12-26 19:21:55,483 : INFO : diff #set()\n",
      "2020-12-26 19:21:56,988 : INFO : alphabet #8006\n",
      "2020-12-26 19:21:57,739 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/cve.py')[[1.0450904167142796, 0.48897593564916225], [0.5530133247375488, 0.44698668], [4.078954102332804, 1.387530771140209], [6.5447135052193754, 6.249195780135539, 6.96428731688038, 5.829621968474534, 0.4195738116610048, 0.7150915367448416]]\n",
      "2020-12-26 19:21:57,743 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:21:57,745 : INFO : built Dictionary(229 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 904 corpus positions)\n",
      "2020-12-26 19:21:58,136 : INFO : token count processed\n",
      "2020-12-26 19:21:58,147 : INFO : frequencies processed\n",
      "2020-12-26 19:21:58,900 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:21:58,901 : INFO : entropies processed\n",
      "2020-12-26 19:21:58,902 : INFO : extropies processed\n",
      "2020-12-26 19:21:58,904 : INFO : token count processed\n",
      "2020-12-26 19:21:58,905 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:21:58,907 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:21:58,907 : INFO : vocab #8006\n",
      "2020-12-26 19:21:58,909 : INFO : diff #set()\n",
      "2020-12-26 19:22:00,418 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:01,166 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/cve_bd.py')[[1.078191755281197, 0.48118755040710454], [0.5572801530361176, 0.44271985], [3.80433446092203, 1.3763494813285666], [6.5447135052193754, 6.199441725113713, 6.868354526608291, 5.8758007037247975, 0.3236410213889158, 0.668912801494578]]\n",
      "2020-12-26 19:22:01,182 : INFO : Removed 0 and 1 OOV words from document 1 and 2 (respectively).\n",
      "2020-12-26 19:22:01,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:01,191 : INFO : built Dictionary(578 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 8510 corpus positions)\n",
      "2020-12-26 19:22:03,284 : INFO : token count processed\n",
      "2020-12-26 19:22:03,293 : INFO : frequencies processed\n",
      "2020-12-26 19:22:04,040 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:04,041 : INFO : entropies processed\n",
      "2020-12-26 19:22:04,041 : INFO : extropies processed\n",
      "2020-12-26 19:22:04,046 : INFO : token count processed\n",
      "2020-12-26 19:22:04,047 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:04,048 : INFO : alphabet_target #8010\n",
      "2020-12-26 19:22:04,049 : INFO : vocab #8006\n",
      "2020-12-26 19:22:04,051 : INFO : diff #set()\n",
      "2020-12-26 19:22:05,556 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:06,304 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/HubRestApi.py')[[1.0415688566891188, 0.48981938410920606], [0.5686385333538055, 0.43136147], [5.211387271685215, 1.4183202376178745], [6.5447135052193754, 7.157650486588366, 7.336751042256256, 6.365612949551486, 0.7920375370368804, 0.17910055566788952]]\n",
      "2020-12-26 19:22:06,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:06,315 : INFO : built Dictionary(415 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3953 corpus positions)\n",
      "2020-12-26 19:22:07,473 : INFO : token count processed\n",
      "2020-12-26 19:22:07,483 : INFO : frequencies processed\n",
      "2020-12-26 19:22:08,233 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:08,234 : INFO : entropies processed\n",
      "2020-12-26 19:22:08,235 : INFO : extropies processed\n",
      "2020-12-26 19:22:08,238 : INFO : token count processed\n",
      "2020-12-26 19:22:08,239 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:08,241 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:08,242 : INFO : vocab #8006\n",
      "2020-12-26 19:22:08,243 : INFO : diff #set()\n",
      "2020-12-26 19:22:09,751 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:10,502 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/ipCentralScan.py')[[1.055894752225778, 0.48640622236005404], [0.5388873219490051, 0.46111268], [4.862553953187008, 1.4123792564172941], [6.5447135052193754, 6.807408309196005, 7.060951244670569, 6.291170569744811, 0.5162377394511939, 0.25354293547456397]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:22:10,505 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:10,506 : INFO : built Dictionary(205 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 463 corpus positions)\n",
      "2020-12-26 19:22:10,823 : INFO : token count processed\n",
      "2020-12-26 19:22:10,834 : INFO : frequencies processed\n",
      "2020-12-26 19:22:11,588 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:11,589 : INFO : entropies processed\n",
      "2020-12-26 19:22:11,589 : INFO : extropies processed\n",
      "2020-12-26 19:22:11,591 : INFO : token count processed\n",
      "2020-12-26 19:22:11,593 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:11,594 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:11,595 : INFO : vocab #8006\n",
      "2020-12-26 19:22:11,597 : INFO : diff #set()\n",
      "2020-12-26 19:22:13,214 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:13,962 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/ipcReport.py')[[1.0812068436493645, 0.48049044382658057], [0.5814121961593628, 0.4185878], [3.6820058147602137, 1.375790051461238], [6.5447135052193754, 6.206464900680334, 7.108491918038599, 5.642686487861111, 0.5637784128192234, 0.9020270173582645]]\n",
      "2020-12-26 19:22:13,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:13,970 : INFO : built Dictionary(354 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1319 corpus positions)\n",
      "2020-12-26 19:22:14,952 : INFO : token count processed\n",
      "2020-12-26 19:22:14,962 : INFO : frequencies processed\n",
      "2020-12-26 19:22:15,711 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:15,712 : INFO : entropies processed\n",
      "2020-12-26 19:22:15,713 : INFO : extropies processed\n",
      "2020-12-26 19:22:15,718 : INFO : token count processed\n",
      "2020-12-26 19:22:15,720 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:15,723 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:15,724 : INFO : vocab #8006\n",
      "2020-12-26 19:22:15,726 : INFO : diff #set()\n",
      "2020-12-26 19:22:17,240 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:17,985 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/rest_request.py')[[1.0195629631150183, 0.4951566345114479], [0.5268087983131409, 0.4731912], [4.8693606909445775, 1.410322677571233], [6.5447135052193754, 7.072405114331329, 7.519685220176521, 6.097433399374184, 0.974971714957146, 0.4472801058451923]]\n",
      "2020-12-26 19:22:17,996 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:18,003 : INFO : built Dictionary(610 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 5355 corpus positions)\n",
      "2020-12-26 19:22:20,352 : INFO : token count processed\n",
      "2020-12-26 19:22:20,362 : INFO : frequencies processed\n",
      "2020-12-26 19:22:21,113 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:21,114 : INFO : entropies processed\n",
      "2020-12-26 19:22:21,115 : INFO : extropies processed\n",
      "2020-12-26 19:22:21,118 : INFO : token count processed\n",
      "2020-12-26 19:22:21,120 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:21,121 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:21,122 : INFO : vocab #8006\n",
      "2020-12-26 19:22:21,124 : INFO : diff #set()\n",
      "2020-12-26 19:22:22,633 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:23,384 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/run_ipcentral_automation.py')[[1.0072372386736497, 0.49819721392812744], [0.5168207585811615, 0.48317924], [5.5960489906217035, 1.4234903195355357], [6.5447135052193754, 7.438474602856903, 7.714184954208788, 6.269003153867491, 1.1694714489894125, 0.2757103513518846]]\n",
      "2020-12-26 19:22:23,388 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:23,389 : INFO : built Dictionary(251 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 821 corpus positions)\n",
      "2020-12-26 19:22:23,870 : INFO : token count processed\n",
      "2020-12-26 19:22:23,876 : INFO : frequencies processed\n",
      "2020-12-26 19:22:24,625 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:24,626 : INFO : entropies processed\n",
      "2020-12-26 19:22:24,627 : INFO : extropies processed\n",
      "2020-12-26 19:22:24,629 : INFO : token count processed\n",
      "2020-12-26 19:22:24,630 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:24,631 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:24,632 : INFO : vocab #8006\n",
      "2020-12-26 19:22:24,634 : INFO : diff #set()\n",
      "2020-12-26 19:22:26,146 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:26,896 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/tpsd_triage.py')[[1.0400783989851898, 0.4901772404910697], [0.5404369533061981, 0.45956305], [4.160383163865372, 1.3914854486772614], [6.5447135052193754, 6.517838464869326, 7.146652134554327, 5.915899835534375, 0.6019386293349518, 0.6288136696850009]]\n",
      "2020-12-26 19:22:26,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:26,906 : INFO : built Dictionary(377 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2491 corpus positions)\n",
      "2020-12-26 19:22:27,945 : INFO : token count processed\n",
      "2020-12-26 19:22:27,958 : INFO : frequencies processed\n",
      "2020-12-26 19:22:28,704 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:28,705 : INFO : entropies processed\n",
      "2020-12-26 19:22:28,706 : INFO : extropies processed\n",
      "2020-12-26 19:22:28,709 : INFO : token count processed\n",
      "2020-12-26 19:22:28,710 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:28,711 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:28,712 : INFO : vocab #8006\n",
      "2020-12-26 19:22:28,714 : INFO : diff #set()\n",
      "2020-12-26 19:22:30,227 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:30,977 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/unused/bd_image.py')[[1.081575974671552, 0.48040523726634], [0.5638102889060974, 0.4361897], [4.365533250556853, 1.39873053303273], [6.5447135052193754, 6.828798019994871, 7.200025332907675, 6.173486192306571, 0.6553118276882994, 0.3712273129128043]]\n",
      "2020-12-26 19:22:30,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:30,983 : INFO : built Dictionary(254 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 958 corpus positions)\n",
      "2020-12-26 19:22:31,447 : INFO : token count processed\n",
      "2020-12-26 19:22:31,458 : INFO : frequencies processed\n",
      "2020-12-26 19:22:32,205 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:32,206 : INFO : entropies processed\n",
      "2020-12-26 19:22:32,207 : INFO : extropies processed\n",
      "2020-12-26 19:22:32,211 : INFO : token count processed\n",
      "2020-12-26 19:22:32,213 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:32,215 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:32,216 : INFO : vocab #8006\n",
      "2020-12-26 19:22:32,219 : INFO : diff #set()\n",
      "2020-12-26 19:22:33,728 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:34,480 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/unused/ipc.py')[[1.0607951687390542, 0.4852495848055939], [0.5588025748729706, 0.44119743], [4.237224022722453, 1.3944961808684724], [6.5447135052193754, 6.41691623234547, 7.034794932461688, 5.926834805103157, 0.49008142724231263, 0.6178787001162185]]\n",
      "2020-12-26 19:22:34,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:34,492 : INFO : built Dictionary(393 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3939 corpus positions)\n",
      "2020-12-26 19:22:35,575 : INFO : token count processed\n",
      "2020-12-26 19:22:35,584 : INFO : frequencies processed\n",
      "2020-12-26 19:22:36,336 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:36,337 : INFO : entropies processed\n",
      "2020-12-26 19:22:36,338 : INFO : extropies processed\n",
      "2020-12-26 19:22:36,341 : INFO : token count processed\n",
      "2020-12-26 19:22:36,342 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:36,344 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:36,344 : INFO : vocab #8006\n",
      "2020-12-26 19:22:36,346 : INFO : diff #set()\n",
      "2020-12-26 19:22:37,956 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:38,706 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/third_party/UploadBom.py')[[0.9977165449131309, 0.5005715162876043], [0.5065991282463074, 0.49340087], [5.028975811929268, 1.415280476173507], [6.5447135052193754, 6.872469634872497, 7.114326283987571, 6.302856856104301, 0.5696127787681959, 0.24185664911507399]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:22:38,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:38,711 : INFO : built Dictionary(199 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 364 corpus positions)\n",
      "2020-12-26 19:22:38,966 : INFO : token count processed\n",
      "2020-12-26 19:22:38,976 : INFO : frequencies processed\n",
      "2020-12-26 19:22:39,726 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:39,726 : INFO : entropies processed\n",
      "2020-12-26 19:22:39,727 : INFO : extropies processed\n",
      "2020-12-26 19:22:39,731 : INFO : token count processed\n",
      "2020-12-26 19:22:39,733 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:39,735 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:39,736 : INFO : vocab #8006\n",
      "2020-12-26 19:22:39,739 : INFO : diff #set()\n",
      "2020-12-26 19:22:41,254 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:42,005 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/webex_send_func.py')[[1.0813830572707703, 0.4804497646441198], [0.5865059196949005, 0.41349408], [2.97965869499932, 1.3376197888824308], [6.5447135052193754, 6.198484194628611, 7.22038134262643, 5.522816357221556, 0.6756678374070546, 1.0218971479978194]]\n",
      "2020-12-26 19:22:42,009 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:42,013 : INFO : built Dictionary(320 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1596 corpus positions)\n",
      "2020-12-26 19:22:42,695 : INFO : token count processed\n",
      "2020-12-26 19:22:42,706 : INFO : frequencies processed\n",
      "2020-12-26 19:22:43,456 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:43,457 : INFO : entropies processed\n",
      "2020-12-26 19:22:43,458 : INFO : extropies processed\n",
      "2020-12-26 19:22:43,462 : INFO : token count processed\n",
      "2020-12-26 19:22:43,465 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:43,467 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:43,468 : INFO : vocab #8006\n",
      "2020-12-26 19:22:43,471 : INFO : diff #set()\n",
      "2020-12-26 19:22:44,994 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:45,744 : INFO : Computed distances or similarities ('293', 'sacp-python-common/sacp_python_common/webexSend.py')[[1.0435720359975031, 0.4893392463710645], [0.550794243812561, 0.44920576], [4.564183254461326, 1.4046191175626221], [6.5447135052193754, 6.830230257253655, 7.262774414187967, 6.112169348285064, 0.7180609089685914, 0.4325441569343118]]\n",
      "2020-12-26 19:22:45,747 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:45,750 : INFO : built Dictionary(236 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 494 corpus positions)\n",
      "2020-12-26 19:22:46,151 : INFO : token count processed\n",
      "2020-12-26 19:22:46,163 : INFO : frequencies processed\n",
      "2020-12-26 19:22:46,910 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:46,911 : INFO : entropies processed\n",
      "2020-12-26 19:22:46,912 : INFO : extropies processed\n",
      "2020-12-26 19:22:46,916 : INFO : token count processed\n",
      "2020-12-26 19:22:46,918 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:46,920 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:46,921 : INFO : vocab #8006\n",
      "2020-12-26 19:22:46,923 : INFO : diff #set()\n",
      "2020-12-26 19:22:48,432 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:49,181 : INFO : Computed distances or similarities ('293', 'sacp-python-common/setup.py')[[1.0766457808520467, 0.48154577406537796], [0.5838980078697205, 0.416102], [3.8980685120588383, 1.3864458182143853], [6.5447135052193754, 6.56009527974789, 7.369103823842328, 5.735704961124937, 0.8243903186229522, 0.8090085440944375]]\n",
      "2020-12-26 19:22:49,186 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:49,189 : INFO : built Dictionary(297 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1542 corpus positions)\n",
      "2020-12-26 19:22:49,844 : INFO : token count processed\n",
      "2020-12-26 19:22:49,856 : INFO : frequencies processed\n",
      "2020-12-26 19:22:50,603 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:50,604 : INFO : entropies processed\n",
      "2020-12-26 19:22:50,605 : INFO : extropies processed\n",
      "2020-12-26 19:22:50,607 : INFO : token count processed\n",
      "2020-12-26 19:22:50,608 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:50,610 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:50,610 : INFO : vocab #8006\n",
      "2020-12-26 19:22:50,612 : INFO : diff #set()\n",
      "2020-12-26 19:22:52,118 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:52,869 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/bandit/test_bandit.py')[[1.0823379922322858, 0.48022943620597863], [0.5830645263195038, 0.41693547], [4.2645152829941075, 1.3940789246705656], [6.5447135052193754, 6.5612688259621, 7.039689577126396, 6.06629275405508, 0.4949760719070202, 0.47842075116429594]]\n",
      "2020-12-26 19:22:52,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:52,873 : INFO : built Dictionary(216 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 551 corpus positions)\n",
      "2020-12-26 19:22:53,203 : INFO : token count processed\n",
      "2020-12-26 19:22:53,214 : INFO : frequencies processed\n",
      "2020-12-26 19:22:53,965 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:53,966 : INFO : entropies processed\n",
      "2020-12-26 19:22:53,967 : INFO : extropies processed\n",
      "2020-12-26 19:22:53,969 : INFO : token count processed\n",
      "2020-12-26 19:22:53,970 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:53,971 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:53,972 : INFO : vocab #8006\n",
      "2020-12-26 19:22:53,973 : INFO : diff #set()\n",
      "2020-12-26 19:22:55,586 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:56,337 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/cave/test_cave_ca.py')[[1.093627440157617, 0.4776398994487367], [0.5695452094078064, 0.4304548], [3.4852281360342516, 1.359257882223477], [6.5447135052193754, 6.195832554153221, 7.077221139799157, 5.663324919573441, 0.5325076345797815, 0.8813885856459356]]\n",
      "2020-12-26 19:22:56,341 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:56,343 : INFO : built Dictionary(205 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 548 corpus positions)\n",
      "2020-12-26 19:22:56,650 : INFO : token count processed\n",
      "2020-12-26 19:22:56,661 : INFO : frequencies processed\n",
      "2020-12-26 19:22:57,411 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:22:57,412 : INFO : entropies processed\n",
      "2020-12-26 19:22:57,413 : INFO : extropies processed\n",
      "2020-12-26 19:22:57,415 : INFO : token count processed\n",
      "2020-12-26 19:22:57,416 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:22:57,417 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:22:57,418 : INFO : vocab #8006\n",
      "2020-12-26 19:22:57,420 : INFO : diff #set()\n",
      "2020-12-26 19:22:58,928 : INFO : alphabet #8006\n",
      "2020-12-26 19:22:59,680 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/cave/test_cave_ssl.py')[[1.0809690815794655, 0.4805453424810114], [0.5600035190582275, 0.43999648], [3.6062389286533896, 1.367006267577962], [6.5447135052193754, 6.137714254194409, 7.019164916227764, 5.66326284318602, 0.4744514110083884, 0.8814506620333544]]\n",
      "2020-12-26 19:22:59,684 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:22:59,686 : INFO : built Dictionary(207 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 645 corpus positions)\n",
      "2020-12-26 19:22:59,984 : INFO : token count processed\n",
      "2020-12-26 19:22:59,995 : INFO : frequencies processed\n",
      "2020-12-26 19:23:00,742 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:00,743 : INFO : entropies processed\n",
      "2020-12-26 19:23:00,744 : INFO : extropies processed\n",
      "2020-12-26 19:23:00,749 : INFO : token count processed\n",
      "2020-12-26 19:23:00,752 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:00,754 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:00,755 : INFO : vocab #8006\n",
      "2020-12-26 19:23:00,758 : INFO : diff #set()\n",
      "2020-12-26 19:23:02,263 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:03,014 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/cave/test_cave_zap.py')[[1.0863088175626732, 0.47931542616411327], [0.5868608951568604, 0.4131391], [3.7232314287976207, 1.379629248505052], [6.5447135052193754, 6.132560039014329, 6.952564135874484, 5.724709408359221, 0.4078506306551084, 0.8200040968601545]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:23:03,034 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:03,039 : INFO : built Dictionary(462 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 11817 corpus positions)\n",
      "2020-12-26 19:23:04,517 : INFO : token count processed\n",
      "2020-12-26 19:23:04,525 : INFO : frequencies processed\n",
      "2020-12-26 19:23:05,274 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:05,275 : INFO : entropies processed\n",
      "2020-12-26 19:23:05,276 : INFO : extropies processed\n",
      "2020-12-26 19:23:05,281 : INFO : token count processed\n",
      "2020-12-26 19:23:05,282 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:05,284 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:05,285 : INFO : vocab #8006\n",
      "2020-12-26 19:23:05,286 : INFO : diff #set()\n",
      "2020-12-26 19:23:06,800 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:07,550 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/csbcicdReport/test_csbcicd_func.py')[[1.0761708169776605, 0.48165593689238334], [0.625573992729187, 0.374426], [4.781274975135268, 1.410443369344312], [6.5447135052193754, 6.7569795334181375, 6.9145929435298115, 6.3871000951077015, 0.369879438310436, 0.15761341011167396]]\n",
      "2020-12-26 19:23:07,557 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:07,561 : INFO : built Dictionary(342 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3132 corpus positions)\n",
      "2020-12-26 19:23:08,338 : INFO : token count processed\n",
      "2020-12-26 19:23:08,348 : INFO : frequencies processed\n",
      "2020-12-26 19:23:09,096 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:09,097 : INFO : entropies processed\n",
      "2020-12-26 19:23:09,098 : INFO : extropies processed\n",
      "2020-12-26 19:23:09,104 : INFO : token count processed\n",
      "2020-12-26 19:23:09,106 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:09,109 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:09,110 : INFO : vocab #8006\n",
      "2020-12-26 19:23:09,111 : INFO : diff #set()\n",
      "2020-12-26 19:23:10,624 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:11,476 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/csbcicdReport/test_csbcicdReport.py')[[1.0600560306767073, 0.48542368999133984], [0.6109787821769714, 0.38902122], [4.731196627493952, 1.4095543165815134], [6.5447135052193754, 6.51553992472357, 6.787458498241601, 6.272794931701346, 0.2427449930222254, 0.2719185735180307]]\n",
      "2020-12-26 19:23:11,481 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:11,483 : INFO : built Dictionary(311 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1633 corpus positions)\n",
      "2020-12-26 19:23:12,179 : INFO : token count processed\n",
      "2020-12-26 19:23:12,190 : INFO : frequencies processed\n",
      "2020-12-26 19:23:12,941 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:12,941 : INFO : entropies processed\n",
      "2020-12-26 19:23:12,942 : INFO : extropies processed\n",
      "2020-12-26 19:23:12,945 : INFO : token count processed\n",
      "2020-12-26 19:23:12,946 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:12,947 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:12,948 : INFO : vocab #8006\n",
      "2020-12-26 19:23:12,950 : INFO : diff #set()\n",
      "2020-12-26 19:23:14,456 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:15,204 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/custom_scan/test_customScan.py')[[1.0421389900306508, 0.489682634180052], [0.5447699129581451, 0.4552301], [4.777445918178311, 1.4093290000302299], [6.5447135052193754, 6.655076556612047, 7.051962010749968, 6.147828051081454, 0.5072485055305922, 0.3968854541379203]]\n",
      "2020-12-26 19:23:15,209 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:15,212 : INFO : built Dictionary(312 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1595 corpus positions)\n",
      "2020-12-26 19:23:15,952 : INFO : token count processed\n",
      "2020-12-26 19:23:15,963 : INFO : frequencies processed\n",
      "2020-12-26 19:23:16,709 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:16,709 : INFO : entropies processed\n",
      "2020-12-26 19:23:16,710 : INFO : extropies processed\n",
      "2020-12-26 19:23:16,714 : INFO : token count processed\n",
      "2020-12-26 19:23:16,716 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:16,718 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:16,719 : INFO : vocab #8006\n",
      "2020-12-26 19:23:16,721 : INFO : diff #set()\n",
      "2020-12-26 19:23:18,241 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:18,991 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/gosec/test_gosec.py')[[1.0614022194509294, 0.485106686392507], [0.5325663685798645, 0.46743363], [4.73412735148665, 1.4065542468349286], [6.5447135052193754, 6.781699187074322, 7.17458670974674, 6.151825982546957, 0.6298732045273647, 0.3928875226724182]]\n",
      "2020-12-26 19:23:18,995 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:18,997 : INFO : built Dictionary(274 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1350 corpus positions)\n",
      "2020-12-26 19:23:19,532 : INFO : token count processed\n",
      "2020-12-26 19:23:19,542 : INFO : frequencies processed\n",
      "2020-12-26 19:23:20,295 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:20,296 : INFO : entropies processed\n",
      "2020-12-26 19:23:20,297 : INFO : extropies processed\n",
      "2020-12-26 19:23:20,299 : INFO : token count processed\n",
      "2020-12-26 19:23:20,300 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:20,302 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:20,303 : INFO : vocab #8006\n",
      "2020-12-26 19:23:20,304 : INFO : diff #set()\n",
      "2020-12-26 19:23:21,813 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:22,565 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/gosec/test_gosec_display.py')[[1.0584204981668484, 0.4858093868043786], [0.5218282043933868, 0.4781718], [4.248104685120989, 1.3948242048948936], [6.5447135052193754, 6.622578715814259, 7.077008892195848, 6.090283328837786, 0.5322953869764726, 0.4544301763815888]]\n",
      "2020-12-26 19:23:22,570 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:22,571 : INFO : built Dictionary(291 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1290 corpus positions)\n",
      "2020-12-26 19:23:23,238 : INFO : token count processed\n",
      "2020-12-26 19:23:23,249 : INFO : frequencies processed\n",
      "2020-12-26 19:23:23,998 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:23,999 : INFO : entropies processed\n",
      "2020-12-26 19:23:24,000 : INFO : extropies processed\n",
      "2020-12-26 19:23:24,005 : INFO : token count processed\n",
      "2020-12-26 19:23:24,008 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:24,010 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:24,011 : INFO : vocab #8006\n",
      "2020-12-26 19:23:24,014 : INFO : diff #set()\n",
      "2020-12-26 19:23:25,534 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:26,284 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/harden_check/test_HardenPostCheck.py')[[1.0377473905752446, 0.49073796125323743], [0.5307227373123169, 0.46927726], [4.630280869184503, 1.4059032010957646], [6.5447135052193754, 6.734422462155908, 7.1764399344465355, 6.102696032928747, 0.63172642922716, 0.4420174722906278]]\n",
      "2020-12-26 19:23:26,289 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:26,292 : INFO : built Dictionary(312 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1473 corpus positions)\n",
      "2020-12-26 19:23:26,944 : INFO : token count processed\n",
      "2020-12-26 19:23:26,954 : INFO : frequencies processed\n",
      "2020-12-26 19:23:27,704 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:27,705 : INFO : entropies processed\n",
      "2020-12-26 19:23:27,706 : INFO : extropies processed\n",
      "2020-12-26 19:23:27,711 : INFO : token count processed\n",
      "2020-12-26 19:23:27,713 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:27,716 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:27,717 : INFO : vocab #8006\n",
      "2020-12-26 19:23:27,720 : INFO : diff #set()\n",
      "2020-12-26 19:23:29,224 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:29,975 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/security_results_push/test_security_results_push.py')[[1.0792546416512288, 0.48094157395068043], [0.5411437451839447, 0.45885625], [4.4200427723692055, 1.399454066609486], [6.5447135052193754, 6.765450962587388, 7.17720956300097, 6.1329549048057945, 0.6324960577815943, 0.4117586004135818]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:23:29,992 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:30,001 : INFO : built Dictionary(473 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 10416 corpus positions)\n",
      "2020-12-26 19:23:31,431 : INFO : token count processed\n",
      "2020-12-26 19:23:31,439 : INFO : frequencies processed\n",
      "2020-12-26 19:23:32,188 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:32,189 : INFO : entropies processed\n",
      "2020-12-26 19:23:32,189 : INFO : extropies processed\n",
      "2020-12-26 19:23:32,194 : INFO : token count processed\n",
      "2020-12-26 19:23:32,196 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:32,197 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:32,198 : INFO : vocab #8006\n",
      "2020-12-26 19:23:32,200 : INFO : diff #set()\n",
      "2020-12-26 19:23:33,712 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:34,459 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/security_results_push/test_security_results_push_func.py')[[1.0680305295846506, 0.4835518555912436], [0.640739232301712, 0.35926077], [4.641048248004573, 1.407197084101744], [6.5447135052193754, 6.638430409424932, 6.792848042665835, 6.3902958719784735, 0.2481345374464592, 0.15441763324090285]]\n",
      "2020-12-26 19:23:34,466 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:34,468 : INFO : built Dictionary(395 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 3015 corpus positions)\n",
      "2020-12-26 19:23:35,609 : INFO : token count processed\n",
      "2020-12-26 19:23:35,620 : INFO : frequencies processed\n",
      "2020-12-26 19:23:36,372 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:36,373 : INFO : entropies processed\n",
      "2020-12-26 19:23:36,374 : INFO : extropies processed\n",
      "2020-12-26 19:23:36,377 : INFO : token count processed\n",
      "2020-12-26 19:23:36,378 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:36,380 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:36,381 : INFO : vocab #8006\n",
      "2020-12-26 19:23:36,383 : INFO : diff #set()\n",
      "2020-12-26 19:23:37,891 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:38,747 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/spotbugs/test_spotbugs.py')[[1.0474707273431416, 0.4884074710546067], [0.5187272727489471, 0.48127273], [4.776864454101657, 1.409200255751286], [6.5447135052193754, 6.921683529042006, 7.179784756965964, 6.286612277295416, 0.6350712517465888, 0.25810122792395873]]\n",
      "2020-12-26 19:23:38,751 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:38,752 : INFO : built Dictionary(238 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 789 corpus positions)\n",
      "2020-12-26 19:23:39,158 : INFO : token count processed\n",
      "2020-12-26 19:23:39,169 : INFO : frequencies processed\n",
      "2020-12-26 19:23:39,921 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:39,922 : INFO : entropies processed\n",
      "2020-12-26 19:23:39,922 : INFO : extropies processed\n",
      "2020-12-26 19:23:39,924 : INFO : token count processed\n",
      "2020-12-26 19:23:39,926 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:39,927 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:39,928 : INFO : vocab #8006\n",
      "2020-12-26 19:23:39,930 : INFO : diff #set()\n",
      "2020-12-26 19:23:41,439 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:42,189 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/spotbugs/test_spotbugsdisplay.py')[[1.04137026122942, 0.489867036368869], [0.5155570209026337, 0.48444298], [4.265311532225103, 1.4012147853799235], [6.5447135052193754, 6.443188759664073, 7.0699852446174445, 5.917917020266004, 0.525271739398069, 0.6267964849533714]]\n",
      "2020-12-26 19:23:42,193 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:42,196 : INFO : built Dictionary(284 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 986 corpus positions)\n",
      "2020-12-26 19:23:42,804 : INFO : token count processed\n",
      "2020-12-26 19:23:42,816 : INFO : frequencies processed\n",
      "2020-12-26 19:23:43,564 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:43,565 : INFO : entropies processed\n",
      "2020-12-26 19:23:43,566 : INFO : extropies processed\n",
      "2020-12-26 19:23:43,568 : INFO : token count processed\n",
      "2020-12-26 19:23:43,569 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:43,571 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:43,574 : INFO : vocab #8006\n",
      "2020-12-26 19:23:43,577 : INFO : diff #set()\n",
      "2020-12-26 19:23:45,077 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:45,829 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/test_auth_utility.py')[[1.0195772622192103, 0.495153128680579], [0.5107156336307526, 0.48928437], [4.652515020931583, 1.4068664221406968], [6.5447135052193754, 6.898279638545452, 7.343057147779275, 6.099935995985552, 0.7983436425598995, 0.4447775092338233]]\n",
      "2020-12-26 19:23:45,843 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:45,850 : INFO : built Dictionary(352 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 8643 corpus positions)\n",
      "2020-12-26 19:23:46,730 : INFO : token count processed\n",
      "2020-12-26 19:23:46,737 : INFO : frequencies processed\n",
      "2020-12-26 19:23:47,486 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:47,486 : INFO : entropies processed\n",
      "2020-12-26 19:23:47,487 : INFO : extropies processed\n",
      "2020-12-26 19:23:47,492 : INFO : token count processed\n",
      "2020-12-26 19:23:47,493 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:47,494 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:47,495 : INFO : vocab #8006\n",
      "2020-12-26 19:23:47,497 : INFO : diff #set()\n",
      "2020-12-26 19:23:49,031 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:49,781 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_binary_scan_func.py')[[1.0363792986309492, 0.49106765162673593], [0.5375179648399353, 0.46248204], [4.841482109456131, 1.4109701448936234], [6.5447135052193754, 6.408340164694879, 6.5177054107759105, 6.435348259138344, -0.02700809444346497, 0.10936524608103149]]\n",
      "2020-12-26 19:23:49,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:49,789 : INFO : built Dictionary(287 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1660 corpus positions)\n",
      "2020-12-26 19:23:50,442 : INFO : token count processed\n",
      "2020-12-26 19:23:50,453 : INFO : frequencies processed\n",
      "2020-12-26 19:23:51,200 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:51,201 : INFO : entropies processed\n",
      "2020-12-26 19:23:51,202 : INFO : extropies processed\n",
      "2020-12-26 19:23:51,206 : INFO : token count processed\n",
      "2020-12-26 19:23:51,209 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:51,211 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:51,212 : INFO : vocab #8006\n",
      "2020-12-26 19:23:51,214 : INFO : diff #set()\n",
      "2020-12-26 19:23:52,734 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:53,484 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_BinaryScan.py')[[0.9996529399058859, 0.5000867800824803], [0.5426112115383148, 0.4573888], [4.750505744366038, 1.4100965535390153], [6.5447135052193754, 6.443827478732862, 6.908726206084097, 6.07981477786814, 0.3640127008647216, 0.46489872735123505]]\n",
      "2020-12-26 19:23:53,489 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:53,492 : INFO : built Dictionary(300 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1630 corpus positions)\n",
      "2020-12-26 19:23:54,162 : INFO : token count processed\n",
      "2020-12-26 19:23:54,173 : INFO : frequencies processed\n",
      "2020-12-26 19:23:54,922 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:54,923 : INFO : entropies processed\n",
      "2020-12-26 19:23:54,924 : INFO : extropies processed\n",
      "2020-12-26 19:23:54,926 : INFO : token count processed\n",
      "2020-12-26 19:23:54,928 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:54,929 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:54,930 : INFO : vocab #8006\n",
      "2020-12-26 19:23:54,932 : INFO : diff #set()\n",
      "2020-12-26 19:23:56,447 : INFO : alphabet #8006\n",
      "2020-12-26 19:23:57,196 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_blackduck.py')[[1.0520821835877663, 0.4873099177010766], [0.5697866678237915, 0.43021333], [4.532795450559985, 1.4037943275733675], [6.5447135052193754, 6.509540793861948, 6.982378742258286, 6.071875556823038, 0.43766523703891025, 0.47283794839633764]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:23:57,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:23:57,204 : INFO : built Dictionary(303 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1584 corpus positions)\n",
      "2020-12-26 19:23:57,817 : INFO : token count processed\n",
      "2020-12-26 19:23:57,827 : INFO : frequencies processed\n",
      "2020-12-26 19:23:58,579 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:23:58,579 : INFO : entropies processed\n",
      "2020-12-26 19:23:58,580 : INFO : extropies processed\n",
      "2020-12-26 19:23:58,585 : INFO : token count processed\n",
      "2020-12-26 19:23:58,587 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:23:58,590 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:23:58,591 : INFO : vocab #8006\n",
      "2020-12-26 19:23:58,594 : INFO : diff #set()\n",
      "2020-12-26 19:24:00,106 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:00,964 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_bom.py')[[0.9865349425951312, 0.5033890814392821], [0.5068639814853668, 0.49313602], [4.8117890986551455, 1.410570318075495], [6.5447135052193754, 6.70060831439398, 7.144908191094134, 6.100413628519221, 0.6001946858747589, 0.44429987670015425]]\n",
      "2020-12-26 19:24:00,969 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:00,972 : INFO : built Dictionary(278 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1738 corpus positions)\n",
      "2020-12-26 19:24:01,534 : INFO : token count processed\n",
      "2020-12-26 19:24:01,544 : INFO : frequencies processed\n",
      "2020-12-26 19:24:02,292 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:02,293 : INFO : entropies processed\n",
      "2020-12-26 19:24:02,294 : INFO : extropies processed\n",
      "2020-12-26 19:24:02,296 : INFO : token count processed\n",
      "2020-12-26 19:24:02,297 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:02,299 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:02,300 : INFO : vocab #8006\n",
      "2020-12-26 19:24:02,301 : INFO : diff #set()\n",
      "2020-12-26 19:24:03,814 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:04,562 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_bom_bd.py')[[1.0322598902532456, 0.49206305000458733], [0.531193882226944, 0.46880612], [4.829737420890341, 1.4120803029909117], [6.5447135052193754, 6.3789777505465235, 6.789005534247138, 6.134685721518761, 0.24429202902776215, 0.4100277837006141]]\n",
      "2020-12-26 19:24:04,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:04,568 : INFO : built Dictionary(219 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 451 corpus positions)\n",
      "2020-12-26 19:24:04,916 : INFO : token count processed\n",
      "2020-12-26 19:24:04,927 : INFO : frequencies processed\n",
      "2020-12-26 19:24:05,676 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:05,677 : INFO : entropies processed\n",
      "2020-12-26 19:24:05,678 : INFO : extropies processed\n",
      "2020-12-26 19:24:05,681 : INFO : token count processed\n",
      "2020-12-26 19:24:05,683 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:05,686 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:05,687 : INFO : vocab #8006\n",
      "2020-12-26 19:24:05,690 : INFO : diff #set()\n",
      "2020-12-26 19:24:07,211 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:07,958 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_corona_lite.py')[[0.9901980012681039, 0.5024625687307621], [0.48636066913604736, 0.51363933], [4.362507470762515, 1.401497123736923], [6.5447135052193754, 6.594537906629094, 7.29206841693323, 5.84718299491524, 0.7473549117138543, 0.6975305103041354]]\n",
      "2020-12-26 19:24:07,962 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:07,966 : INFO : built Dictionary(301 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1578 corpus positions)\n",
      "2020-12-26 19:24:08,619 : INFO : token count processed\n",
      "2020-12-26 19:24:08,630 : INFO : frequencies processed\n",
      "2020-12-26 19:24:09,380 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:09,381 : INFO : entropies processed\n",
      "2020-12-26 19:24:09,381 : INFO : extropies processed\n",
      "2020-12-26 19:24:09,384 : INFO : token count processed\n",
      "2020-12-26 19:24:09,385 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:09,386 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:09,387 : INFO : vocab #8006\n",
      "2020-12-26 19:24:09,389 : INFO : diff #set()\n",
      "2020-12-26 19:24:10,894 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:11,642 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_corona_lite_func.py')[[1.0434203596260407, 0.4893755684136408], [0.5558356642723083, 0.44416434], [4.46046345839295, 1.4030752499981791], [6.5447135052193754, 6.507928811366327, 6.9058382490485375, 6.146804067537165, 0.36112474382916204, 0.39790943768221076]]\n",
      "2020-12-26 19:24:11,648 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:11,649 : INFO : built Dictionary(310 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1858 corpus positions)\n",
      "2020-12-26 19:24:12,337 : INFO : token count processed\n",
      "2020-12-26 19:24:12,348 : INFO : frequencies processed\n",
      "2020-12-26 19:24:13,095 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:13,096 : INFO : entropies processed\n",
      "2020-12-26 19:24:13,097 : INFO : extropies processed\n",
      "2020-12-26 19:24:13,102 : INFO : token count processed\n",
      "2020-12-26 19:24:13,105 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:13,107 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:13,108 : INFO : vocab #8006\n",
      "2020-12-26 19:24:13,110 : INFO : diff #set()\n",
      "2020-12-26 19:24:14,630 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:15,380 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_cve.py')[[1.0182702139613242, 0.49547379388673013], [0.5575038194656372, 0.44249618], [4.802165310947833, 1.4100839607316267], [6.5447135052193754, 6.54238466446361, 7.0007579418103845, 6.086340227872601, 0.456044436591009, 0.4583732773467748]]\n",
      "2020-12-26 19:24:15,384 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:15,388 : INFO : built Dictionary(290 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1769 corpus positions)\n",
      "2020-12-26 19:24:15,964 : INFO : token count processed\n",
      "2020-12-26 19:24:15,975 : INFO : frequencies processed\n",
      "2020-12-26 19:24:16,725 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:16,726 : INFO : entropies processed\n",
      "2020-12-26 19:24:16,727 : INFO : extropies processed\n",
      "2020-12-26 19:24:16,729 : INFO : token count processed\n",
      "2020-12-26 19:24:16,730 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:16,732 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:16,732 : INFO : vocab #8006\n",
      "2020-12-26 19:24:16,734 : INFO : diff #set()\n",
      "2020-12-26 19:24:18,238 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:19,093 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_cve_bd.py')[[1.0345901585297093, 0.4914994775766768], [0.5357057452201843, 0.46429425], [4.787233041173864, 1.4112320071342668], [6.5447135052193754, 6.426532968077849, 6.831225540292158, 6.140020933005067, 0.2865120350727821, 0.40469257221430865]]\n",
      "2020-12-26 19:24:19,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:19,101 : INFO : built Dictionary(278 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2039 corpus positions)\n",
      "2020-12-26 19:24:19,668 : INFO : token count processed\n",
      "2020-12-26 19:24:19,679 : INFO : frequencies processed\n",
      "2020-12-26 19:24:20,428 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:20,429 : INFO : entropies processed\n",
      "2020-12-26 19:24:20,430 : INFO : extropies processed\n",
      "2020-12-26 19:24:20,435 : INFO : token count processed\n",
      "2020-12-26 19:24:20,437 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:20,439 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:20,440 : INFO : vocab #8006\n",
      "2020-12-26 19:24:20,443 : INFO : diff #set()\n",
      "2020-12-26 19:24:21,950 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:22,717 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_ipCentralScan.py')[[1.0696893203225084, 0.4831643040242269], [0.5677950084209442, 0.432205], [4.45838324469907, 1.4007494817980974], [6.5447135052193754, 6.40953838450538, 6.837521562556493, 6.116730327168263, 0.29280805733711723, 0.42798317805111274]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:24:22,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:22,722 : INFO : built Dictionary(261 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 931 corpus positions)\n",
      "2020-12-26 19:24:23,221 : INFO : token count processed\n",
      "2020-12-26 19:24:23,229 : INFO : frequencies processed\n",
      "2020-12-26 19:24:23,980 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:23,981 : INFO : entropies processed\n",
      "2020-12-26 19:24:23,982 : INFO : extropies processed\n",
      "2020-12-26 19:24:23,984 : INFO : token count processed\n",
      "2020-12-26 19:24:23,985 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:23,987 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:23,987 : INFO : vocab #8006\n",
      "2020-12-26 19:24:23,989 : INFO : diff #set()\n",
      "2020-12-26 19:24:25,498 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:26,248 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_ipcReport.py')[[1.0433699819464632, 0.48938763358333426], [0.5451566874980927, 0.4548433], [4.506328385912462, 1.4049393357921975], [6.5447135052193754, 6.513136741171774, 7.127688111601691, 5.930162134789459, 0.5829746063823151, 0.6145513704299166]]\n",
      "2020-12-26 19:24:26,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:26,256 : INFO : built Dictionary(365 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2447 corpus positions)\n",
      "2020-12-26 19:24:27,203 : INFO : token count processed\n",
      "2020-12-26 19:24:27,214 : INFO : frequencies processed\n",
      "2020-12-26 19:24:27,962 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:27,963 : INFO : entropies processed\n",
      "2020-12-26 19:24:27,964 : INFO : extropies processed\n",
      "2020-12-26 19:24:27,966 : INFO : token count processed\n",
      "2020-12-26 19:24:27,968 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:27,969 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:27,970 : INFO : vocab #8006\n",
      "2020-12-26 19:24:27,971 : INFO : diff #set()\n",
      "2020-12-26 19:24:29,484 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:30,265 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_triage.py')[[1.0477914545343352, 0.48833097617716087], [0.6151888370513916, 0.38481116], [4.7577316415581, 1.4093146409173087], [6.5447135052193754, 6.770302123271581, 7.187924400326941, 6.127091228164017, 0.6432108951075657, 0.4176222770553597]]\n",
      "2020-12-26 19:24:30,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:30,273 : INFO : built Dictionary(285 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 1700 corpus positions)\n",
      "2020-12-26 19:24:30,882 : INFO : token count processed\n",
      "2020-12-26 19:24:30,893 : INFO : frequencies processed\n",
      "2020-12-26 19:24:31,641 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:31,642 : INFO : entropies processed\n",
      "2020-12-26 19:24:31,643 : INFO : extropies processed\n",
      "2020-12-26 19:24:31,648 : INFO : token count processed\n",
      "2020-12-26 19:24:31,650 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:31,651 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:31,652 : INFO : vocab #8006\n",
      "2020-12-26 19:24:31,654 : INFO : diff #set()\n",
      "2020-12-26 19:24:33,160 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:33,910 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/test_UploadBom.py')[[1.005685147449151, 0.4985827417986363], [0.5337779521942139, 0.46622205], [4.8409710592793544, 1.4119455774291512], [6.5447135052193754, 6.592422117733454, 7.014175122183697, 6.122960500769133, 0.4694616169643213, 0.42175300445024266]]\n",
      "2020-12-26 19:24:33,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:33,918 : INFO : built Dictionary(312 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2153 corpus positions)\n",
      "2020-12-26 19:24:34,559 : INFO : token count processed\n",
      "2020-12-26 19:24:34,570 : INFO : frequencies processed\n",
      "2020-12-26 19:24:35,425 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:35,426 : INFO : entropies processed\n",
      "2020-12-26 19:24:35,427 : INFO : extropies processed\n",
      "2020-12-26 19:24:35,429 : INFO : token count processed\n",
      "2020-12-26 19:24:35,431 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:35,432 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:35,433 : INFO : vocab #8006\n",
      "2020-12-26 19:24:35,434 : INFO : diff #set()\n",
      "2020-12-26 19:24:36,968 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:37,716 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/unused/test_bd_image.py')[[1.0558009075039447, 0.48642842619140214], [0.5660040974617004, 0.4339959], [4.684828905920194, 1.4076957806948671], [6.5447135052193754, 6.446379772539096, 6.807180246351638, 6.183913031406833, 0.262466741132263, 0.3608004738125423]]\n",
      "2020-12-26 19:24:37,722 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:37,724 : INFO : built Dictionary(311 unique tokens: [\"'\", '(', ')', ',', '.']...) from 2 documents (total 2424 corpus positions)\n",
      "2020-12-26 19:24:38,418 : INFO : token count processed\n",
      "2020-12-26 19:24:38,428 : INFO : frequencies processed\n",
      "2020-12-26 19:24:39,178 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:39,179 : INFO : entropies processed\n",
      "2020-12-26 19:24:39,180 : INFO : extropies processed\n",
      "2020-12-26 19:24:39,183 : INFO : token count processed\n",
      "2020-12-26 19:24:39,184 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:39,185 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:39,186 : INFO : vocab #8006\n",
      "2020-12-26 19:24:39,188 : INFO : diff #set()\n",
      "2020-12-26 19:24:40,701 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:41,450 : INFO : Computed distances or similarities ('293', 'sacp-python-common/test/python/third_party/unused/test_ipc.py')[[1.0312696061224076, 0.4923029404791569], [0.6151138842105865, 0.38488612], [4.758969969293428, 1.4095877080245816], [6.5447135052193754, 6.3302275852634216, 6.736739547030441, 6.138201543452355, 0.19202604181106597, 0.40651196176701987]]\n",
      "2020-12-26 19:24:41,455 : INFO : Removed 0 and 1 OOV words from document 1 and 2 (respectively).\n",
      "2020-12-26 19:24:41,456 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:41,459 : INFO : built Dictionary(330 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 1836 corpus positions)\n",
      "2020-12-26 19:24:42,114 : INFO : token count processed\n",
      "2020-12-26 19:24:42,120 : INFO : frequencies processed\n",
      "2020-12-26 19:24:42,867 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:42,868 : INFO : entropies processed\n",
      "2020-12-26 19:24:42,869 : INFO : extropies processed\n",
      "2020-12-26 19:24:42,871 : INFO : token count processed\n",
      "2020-12-26 19:24:42,873 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:42,874 : INFO : alphabet_target #8010\n",
      "2020-12-26 19:24:42,875 : INFO : vocab #8006\n",
      "2020-12-26 19:24:42,876 : INFO : diff #set()\n",
      "2020-12-26 19:24:44,380 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:45,130 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/auth_utility.py')[[1.0721167709672987, 0.48259828500552276], [0.641757071018219, 0.35824293], [4.631305423879506, 1.4040178889153034], [6.351505805342684, 6.895875762815869, 7.237702940406166, 6.009678627752386, 0.8861971350634823, 0.34182717759029657]]\n",
      "2020-12-26 19:24:45,137 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:45,139 : INFO : built Dictionary(390 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 2849 corpus positions)\n",
      "2020-12-26 19:24:46,096 : INFO : token count processed\n",
      "2020-12-26 19:24:46,102 : INFO : frequencies processed\n",
      "2020-12-26 19:24:46,851 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:46,852 : INFO : entropies processed\n",
      "2020-12-26 19:24:46,853 : INFO : extropies processed\n",
      "2020-12-26 19:24:46,857 : INFO : token count processed\n",
      "2020-12-26 19:24:46,859 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:46,861 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:46,862 : INFO : vocab #8006\n",
      "2020-12-26 19:24:46,865 : INFO : diff #set()\n",
      "2020-12-26 19:24:48,383 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:49,129 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/bandit/bandit.py')[[1.0754647552501881, 0.4818197936006167], [0.6399089395999908, 0.36009106], [4.8437064692952125, 1.4106211936968875], [6.351505805342684, 7.046810312550396, 7.3716277843633256, 6.026688333529754, 1.020121979020642, 0.3248174718129295]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:24:49,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:49,140 : INFO : built Dictionary(332 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 2869 corpus positions)\n",
      "2020-12-26 19:24:49,821 : INFO : token count processed\n",
      "2020-12-26 19:24:49,832 : INFO : frequencies processed\n",
      "2020-12-26 19:24:50,584 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:50,585 : INFO : entropies processed\n",
      "2020-12-26 19:24:50,586 : INFO : extropies processed\n",
      "2020-12-26 19:24:50,589 : INFO : token count processed\n",
      "2020-12-26 19:24:50,590 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:50,592 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:50,592 : INFO : vocab #8006\n",
      "2020-12-26 19:24:50,594 : INFO : diff #set()\n",
      "2020-12-26 19:24:52,105 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:52,856 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/bandit/banditReport.py')[[1.0846822865434544, 0.4796894022916404], [0.6552718579769135, 0.34472814], [4.822156249394178, 1.4098263125458195], [6.351505805342684, 6.426571231608991, 6.676928495466182, 6.101148541485493, 0.32542269012349845, 0.25035726385719137]]\n",
      "2020-12-26 19:24:52,861 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:52,862 : INFO : built Dictionary(229 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 992 corpus positions)\n",
      "2020-12-26 19:24:53,187 : INFO : token count processed\n",
      "2020-12-26 19:24:53,198 : INFO : frequencies processed\n",
      "2020-12-26 19:24:53,948 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:53,949 : INFO : entropies processed\n",
      "2020-12-26 19:24:53,950 : INFO : extropies processed\n",
      "2020-12-26 19:24:53,952 : INFO : token count processed\n",
      "2020-12-26 19:24:53,953 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:53,955 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:53,955 : INFO : vocab #8006\n",
      "2020-12-26 19:24:53,957 : INFO : diff #set()\n",
      "2020-12-26 19:24:55,468 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:56,215 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/cave/caveCa.py')[[1.0817598172674867, 0.48036281212911386], [0.6439716219902039, 0.35602838], [4.0472990984266435, 1.3823684768321582], [6.351505805342684, 6.098070142413432, 6.677410523194947, 5.7721654245611695, 0.3259047178522634, 0.579340380781515]]\n",
      "2020-12-26 19:24:56,219 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:56,220 : INFO : built Dictionary(200 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 668 corpus positions)\n",
      "2020-12-26 19:24:56,478 : INFO : token count processed\n",
      "2020-12-26 19:24:56,490 : INFO : frequencies processed\n",
      "2020-12-26 19:24:57,247 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:24:57,248 : INFO : entropies processed\n",
      "2020-12-26 19:24:57,249 : INFO : extropies processed\n",
      "2020-12-26 19:24:57,251 : INFO : token count processed\n",
      "2020-12-26 19:24:57,252 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:24:57,254 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:24:57,255 : INFO : vocab #8006\n",
      "2020-12-26 19:24:57,256 : INFO : diff #set()\n",
      "2020-12-26 19:24:58,763 : INFO : alphabet #8006\n",
      "2020-12-26 19:24:59,521 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/cave/caveSsl.py')[[1.0765856397427294, 0.4815597203705459], [0.6416923999786377, 0.3583076], [4.2603326005698765, 1.3901126731137545], [6.351505805342684, 5.941919007331087, 6.660114068478972, 5.633310744194798, 0.3086082631362883, 0.7181950611478847]]\n",
      "2020-12-26 19:24:59,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:24:59,529 : INFO : built Dictionary(291 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 2708 corpus positions)\n",
      "2020-12-26 19:25:00,059 : INFO : token count processed\n",
      "2020-12-26 19:25:00,070 : INFO : frequencies processed\n",
      "2020-12-26 19:25:00,925 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:00,926 : INFO : entropies processed\n",
      "2020-12-26 19:25:00,927 : INFO : extropies processed\n",
      "2020-12-26 19:25:00,929 : INFO : token count processed\n",
      "2020-12-26 19:25:00,931 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:00,933 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:00,934 : INFO : vocab #8006\n",
      "2020-12-26 19:25:00,937 : INFO : diff #set()\n",
      "2020-12-26 19:25:02,453 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:03,201 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/cave/caveZap.py')[[1.0825745827633901, 0.48017487982259416], [0.6532078981399536, 0.3467921], [4.3919313347092155, 1.3957740636502451], [6.351505805342684, 6.3389906976029495, 6.618369524552448, 6.072126978393185, 0.2668637192097645, 0.27937882694949856]]\n",
      "2020-12-26 19:25:03,206 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:03,208 : INFO : built Dictionary(277 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 1828 corpus positions)\n",
      "2020-12-26 19:25:03,676 : INFO : token count processed\n",
      "2020-12-26 19:25:03,686 : INFO : frequencies processed\n",
      "2020-12-26 19:25:04,437 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:04,437 : INFO : entropies processed\n",
      "2020-12-26 19:25:04,438 : INFO : extropies processed\n",
      "2020-12-26 19:25:04,441 : INFO : token count processed\n",
      "2020-12-26 19:25:04,442 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:04,443 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:04,444 : INFO : vocab #8006\n",
      "2020-12-26 19:25:04,446 : INFO : diff #set()\n",
      "2020-12-26 19:25:05,954 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:06,702 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/csbcicd_report/aggregator.py')[[1.0720726705517856, 0.48260855625961396], [0.6241506040096283, 0.3758494], [3.9056390622295662, 1.380975751553854], [6.351505805342684, 6.424670910428789, 6.795675649338133, 5.980501066433341, 0.4441698439954491, 0.3710047389093436]]\n",
      "2020-12-26 19:25:06,716 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:06,719 : INFO : built Dictionary(438 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 7731 corpus positions)\n",
      "2020-12-26 19:25:07,886 : INFO : token count processed\n",
      "2020-12-26 19:25:07,892 : INFO : frequencies processed\n",
      "2020-12-26 19:25:08,640 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:08,641 : INFO : entropies processed\n",
      "2020-12-26 19:25:08,641 : INFO : extropies processed\n",
      "2020-12-26 19:25:08,645 : INFO : token count processed\n",
      "2020-12-26 19:25:08,647 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:08,648 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:08,649 : INFO : vocab #8006\n",
      "2020-12-26 19:25:08,651 : INFO : diff #set()\n",
      "2020-12-26 19:25:10,160 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:10,911 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicd_func.py')[[1.0684823343486332, 0.48344623659302405], [0.612342119216919, 0.38765788], [5.178943724967402, 1.4147875249293436], [6.351505805342684, 6.856857092706523, 6.998292530642214, 6.210070367406992, 0.6467867252995303, 0.1414354379356908]]\n",
      "2020-12-26 19:25:10,918 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:10,922 : INFO : built Dictionary(354 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 3336 corpus positions)\n",
      "2020-12-26 19:25:11,764 : INFO : token count processed\n",
      "2020-12-26 19:25:11,771 : INFO : frequencies processed\n",
      "2020-12-26 19:25:12,517 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:12,518 : INFO : entropies processed\n",
      "2020-12-26 19:25:12,519 : INFO : extropies processed\n",
      "2020-12-26 19:25:12,522 : INFO : token count processed\n",
      "2020-12-26 19:25:12,523 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:12,525 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:12,526 : INFO : vocab #8006\n",
      "2020-12-26 19:25:12,527 : INFO : diff #set()\n",
      "2020-12-26 19:25:14,031 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:14,781 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/csbcicd_report/csbcicdReport.py')[[1.0776010693970255, 0.48132435756313235], [0.6203479766845703, 0.37965202], [4.911602217974672, 1.412709855548799], [6.351505805342684, 6.553499792717194, 6.827468806156796, 6.07753679190308, 0.47596300081411247, 0.27396901343960245]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:25:14,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:14,786 : INFO : built Dictionary(269 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 962 corpus positions)\n",
      "2020-12-26 19:25:15,255 : INFO : token count processed\n",
      "2020-12-26 19:25:15,266 : INFO : frequencies processed\n",
      "2020-12-26 19:25:16,019 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:16,020 : INFO : entropies processed\n",
      "2020-12-26 19:25:16,021 : INFO : extropies processed\n",
      "2020-12-26 19:25:16,023 : INFO : token count processed\n",
      "2020-12-26 19:25:16,024 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:16,026 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:16,027 : INFO : vocab #8006\n",
      "2020-12-26 19:25:16,029 : INFO : diff #set()\n",
      "2020-12-26 19:25:17,537 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:18,285 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/ctsm2csdl.py')[[1.096098713068304, 0.47707676826736056], [0.6930161118507385, 0.3069839], [4.179229296672174, 1.3882971653431904], [6.351505805342684, 6.637223258470346, 7.156813114441267, 5.831915949371762, 0.8053073090985832, 0.5195898559709207]]\n",
      "2020-12-26 19:25:18,293 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:18,298 : INFO : built Dictionary(440 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 3398 corpus positions)\n",
      "2020-12-26 19:25:19,500 : INFO : token count processed\n",
      "2020-12-26 19:25:19,511 : INFO : frequencies processed\n",
      "2020-12-26 19:25:20,262 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:20,263 : INFO : entropies processed\n",
      "2020-12-26 19:25:20,264 : INFO : extropies processed\n",
      "2020-12-26 19:25:20,270 : INFO : token count processed\n",
      "2020-12-26 19:25:20,273 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:20,275 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:20,276 : INFO : vocab #8006\n",
      "2020-12-26 19:25:20,278 : INFO : diff #set()\n",
      "2020-12-26 19:25:21,788 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:22,535 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/custom_scan/customScan.py')[[1.0196607934990807, 0.49513264961067593], [0.5977436006069183, 0.4022564], [5.413843736505229, 1.4215853288328397], [6.351505805342684, 7.250907518628656, 7.501790854570819, 6.1006224694005216, 1.1502850492281356, 0.25088333594216294]]\n",
      "2020-12-26 19:25:22,538 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:22,540 : INFO : built Dictionary(148 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 272 corpus positions)\n",
      "2020-12-26 19:25:22,664 : INFO : token count processed\n",
      "2020-12-26 19:25:22,673 : INFO : frequencies processed\n",
      "2020-12-26 19:25:23,533 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:23,534 : INFO : entropies processed\n",
      "2020-12-26 19:25:23,534 : INFO : extropies processed\n",
      "2020-12-26 19:25:23,536 : INFO : token count processed\n",
      "2020-12-26 19:25:23,538 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:23,539 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:25:23,540 : INFO : vocab #8006\n",
      "2020-12-26 19:25:23,541 : INFO : diff #set()\n",
      "2020-12-26 19:25:25,053 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:25,802 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/fireException.py')[[1.1577135510617327, 0.4634535476258822], [0.7279835343360901, 0.27201647], [1.836591668108979, 1.1861517395221295], [6.351505805342684, 5.304981337622145, 6.826842671154745, 4.829644471810083, 0.4753368658120616, 1.5218613335326001]]\n",
      "2020-12-26 19:25:25,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:25,807 : INFO : built Dictionary(229 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 728 corpus positions)\n",
      "2020-12-26 19:25:26,193 : INFO : token count processed\n",
      "2020-12-26 19:25:26,204 : INFO : frequencies processed\n",
      "2020-12-26 19:25:26,954 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:26,954 : INFO : entropies processed\n",
      "2020-12-26 19:25:26,955 : INFO : extropies processed\n",
      "2020-12-26 19:25:26,959 : INFO : token count processed\n",
      "2020-12-26 19:25:26,962 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:26,964 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:26,965 : INFO : vocab #8006\n",
      "2020-12-26 19:25:26,968 : INFO : diff #set()\n",
      "2020-12-26 19:25:28,487 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:29,236 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/gosec/gosec_display.py')[[1.1061645184056221, 0.4747967175693404], [0.6774884462356567, 0.32251155], [3.873140679513133, 1.3726471941360994], [6.351505805342684, 6.525221949271511, 7.179592376476632, 5.697135378137562, 0.828086571133948, 0.6543704272051203]]\n",
      "2020-12-26 19:25:29,243 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:29,246 : INFO : built Dictionary(400 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 3276 corpus positions)\n",
      "2020-12-26 19:25:30,286 : INFO : token count processed\n",
      "2020-12-26 19:25:30,296 : INFO : frequencies processed\n",
      "2020-12-26 19:25:31,044 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:31,045 : INFO : entropies processed\n",
      "2020-12-26 19:25:31,046 : INFO : extropies processed\n",
      "2020-12-26 19:25:31,049 : INFO : token count processed\n",
      "2020-12-26 19:25:31,050 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:31,052 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:31,052 : INFO : vocab #8006\n",
      "2020-12-26 19:25:31,054 : INFO : diff #set()\n",
      "2020-12-26 19:25:32,600 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:33,351 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/gosec/gosec_report.py')[[1.0689789846849025, 0.483330187209367], [0.6429618000984192, 0.3570382], [4.967720100474499, 1.4135788159697056], [6.351505805342684, 6.900194567319838, 7.144164790202202, 6.10753558246032, 0.7926589848595187, 0.24397022288236414]]\n",
      "2020-12-26 19:25:33,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:33,361 : INFO : built Dictionary(332 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 3733 corpus positions)\n",
      "2020-12-26 19:25:33,979 : INFO : token count processed\n",
      "2020-12-26 19:25:33,990 : INFO : frequencies processed\n",
      "2020-12-26 19:25:34,737 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:34,738 : INFO : entropies processed\n",
      "2020-12-26 19:25:34,739 : INFO : extropies processed\n",
      "2020-12-26 19:25:34,742 : INFO : token count processed\n",
      "2020-12-26 19:25:34,743 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:34,744 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:34,745 : INFO : vocab #8006\n",
      "2020-12-26 19:25:34,747 : INFO : diff #set()\n",
      "2020-12-26 19:25:36,252 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:37,031 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/harden_check/harden_func.py')[[1.0623005572455817, 0.4848953739970883], [0.6600334346294403, 0.33996657], [4.664653803789036, 1.4062929863221059], [6.351505805342684, 6.350617617253523, 6.6176448430856665, 6.084478579510539, 0.26613903774298286, 0.2670272258321438]]\n",
      "2020-12-26 19:25:37,036 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:37,038 : INFO : built Dictionary(342 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 1921 corpus positions)\n",
      "2020-12-26 19:25:37,754 : INFO : token count processed\n",
      "2020-12-26 19:25:37,764 : INFO : frequencies processed\n",
      "2020-12-26 19:25:38,512 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:38,513 : INFO : entropies processed\n",
      "2020-12-26 19:25:38,514 : INFO : extropies processed\n",
      "2020-12-26 19:25:38,518 : INFO : token count processed\n",
      "2020-12-26 19:25:38,521 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:38,523 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:38,524 : INFO : vocab #8006\n",
      "2020-12-26 19:25:38,527 : INFO : diff #set()\n",
      "2020-12-26 19:25:40,050 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:40,798 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/harden_check/hardenPostCheck.py')[[1.0438743327606494, 0.4892668712412009], [0.6220099627971649, 0.37799004], [4.838562939644917, 1.4114161289993064], [6.351505805342684, 6.941677454537802, 7.277447586476486, 6.015735673404, 0.925941781133802, 0.3357701319386832]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:25:40,803 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:40,805 : INFO : built Dictionary(283 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 1720 corpus positions)\n",
      "2020-12-26 19:25:41,337 : INFO : token count processed\n",
      "2020-12-26 19:25:41,347 : INFO : frequencies processed\n",
      "2020-12-26 19:25:42,204 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:42,205 : INFO : entropies processed\n",
      "2020-12-26 19:25:42,206 : INFO : extropies processed\n",
      "2020-12-26 19:25:42,208 : INFO : token count processed\n",
      "2020-12-26 19:25:42,210 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:42,211 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:42,212 : INFO : vocab #8006\n",
      "2020-12-26 19:25:42,214 : INFO : diff #set()\n",
      "2020-12-26 19:25:43,742 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:44,492 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/harden_check/hardenReport.py')[[1.0839318948609018, 0.4798621310351162], [0.6410656869411469, 0.3589343], [4.303783770917412, 1.3940836146310764], [6.351505805342684, 6.494384552966903, 6.8749300556907, 5.970960302618885, 0.5234242503480164, 0.3805455027237974]]\n",
      "2020-12-26 19:25:44,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:44,505 : INFO : built Dictionary(445 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 3851 corpus positions)\n",
      "2020-12-26 19:25:45,725 : INFO : token count processed\n",
      "2020-12-26 19:25:45,731 : INFO : frequencies processed\n",
      "2020-12-26 19:25:46,480 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:46,481 : INFO : entropies processed\n",
      "2020-12-26 19:25:46,482 : INFO : extropies processed\n",
      "2020-12-26 19:25:46,485 : INFO : token count processed\n",
      "2020-12-26 19:25:46,486 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:46,488 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:25:46,488 : INFO : vocab #8006\n",
      "2020-12-26 19:25:46,490 : INFO : diff #set()\n",
      "2020-12-26 19:25:48,003 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:48,753 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/psb_mapping.py')[[1.1137216964978502, 0.47309917935595025], [0.6993041634559631, 0.30069584], [4.418722908066561, 1.3971765893626007], [6.351505805342684, 6.562992713112968, 6.883340650252144, 6.031157868203508, 0.5318348449094605, 0.320347937139176]]\n",
      "2020-12-26 19:25:48,762 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:48,765 : INFO : built Dictionary(455 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 4290 corpus positions)\n",
      "2020-12-26 19:25:50,036 : INFO : token count processed\n",
      "2020-12-26 19:25:50,046 : INFO : frequencies processed\n",
      "2020-12-26 19:25:50,797 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:50,798 : INFO : entropies processed\n",
      "2020-12-26 19:25:50,799 : INFO : extropies processed\n",
      "2020-12-26 19:25:50,802 : INFO : token count processed\n",
      "2020-12-26 19:25:50,803 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:50,805 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:50,806 : INFO : vocab #8006\n",
      "2020-12-26 19:25:50,807 : INFO : diff #set()\n",
      "2020-12-26 19:25:52,319 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:53,068 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push.py')[[1.060572898526356, 0.4853019277867637], [0.6082843542098999, 0.39171565], [5.1834551205210575, 1.4185730004244632], [6.351505805342684, 6.963414455813236, 7.210341454743389, 6.10457880641253, 0.8588356494007057, 0.24692699893015302]]\n",
      "2020-12-26 19:25:53,080 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:53,084 : INFO : built Dictionary(509 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 6879 corpus positions)\n",
      "2020-12-26 19:25:54,637 : INFO : token count processed\n",
      "2020-12-26 19:25:54,646 : INFO : frequencies processed\n",
      "2020-12-26 19:25:55,396 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:25:55,397 : INFO : entropies processed\n",
      "2020-12-26 19:25:55,398 : INFO : extropies processed\n",
      "2020-12-26 19:25:55,402 : INFO : token count processed\n",
      "2020-12-26 19:25:55,403 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:25:55,405 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:25:55,405 : INFO : vocab #8006\n",
      "2020-12-26 19:25:55,407 : INFO : diff #set()\n",
      "2020-12-26 19:25:56,916 : INFO : alphabet #8006\n",
      "2020-12-26 19:25:57,667 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/security_results_push/security_results_push_func.py')[[1.0496826071811003, 0.4878804145073397], [0.595980167388916, 0.40401983], [5.3240520391118995, 1.4177990790821098], [6.351505805342684, 6.923627972311028, 7.065136545642034, 6.209997232011677, 0.71363074029935, 0.14150857333100575]]\n",
      "2020-12-26 19:25:57,681 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:25:57,684 : INFO : built Dictionary(564 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 8115 corpus positions)\n",
      "2020-12-26 19:25:59,410 : INFO : token count processed\n",
      "2020-12-26 19:25:59,419 : INFO : frequencies processed\n",
      "2020-12-26 19:26:00,165 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:26:00,166 : INFO : entropies processed\n",
      "2020-12-26 19:26:00,167 : INFO : extropies processed\n",
      "2020-12-26 19:26:00,171 : INFO : token count processed\n",
      "2020-12-26 19:26:00,173 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:26:00,174 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:26:00,175 : INFO : vocab #8006\n",
      "2020-12-26 19:26:00,177 : INFO : diff #set()\n",
      "2020-12-26 19:26:01,792 : INFO : alphabet #8006\n",
      "2020-12-26 19:26:02,541 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/spotbugs/spotbugs.py')[[1.0336943392507267, 0.49171597751923213], [0.6197981834411621, 0.38020182], [5.2965145745152205, 1.4172080978916086], [6.351505805342684, 7.229383614478795, 7.393780117259782, 6.187109302561696, 1.0422743119170983, 0.1643965027809866]]\n",
      "2020-12-26 19:26:02,545 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:26:02,546 : INFO : built Dictionary(207 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 524 corpus positions)\n",
      "2020-12-26 19:26:02,832 : INFO : token count processed\n",
      "2020-12-26 19:26:02,844 : INFO : frequencies processed\n",
      "2020-12-26 19:26:03,592 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:26:03,593 : INFO : entropies processed\n",
      "2020-12-26 19:26:03,594 : INFO : extropies processed\n",
      "2020-12-26 19:26:03,596 : INFO : token count processed\n",
      "2020-12-26 19:26:03,597 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:26:03,598 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:26:03,599 : INFO : vocab #8006\n",
      "2020-12-26 19:26:03,601 : INFO : diff #set()\n",
      "2020-12-26 19:26:05,108 : INFO : alphabet #8006\n",
      "2020-12-26 19:26:05,856 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/spotbugs/spotbugsdisplay.py')[[1.092249296566035, 0.4779545160518295], [0.6605196595191956, 0.33948034], [3.5726236638951625, 1.3529011002066118], [6.351505805342684, 6.400449261283311, 7.152526607044642, 5.599428459581352, 0.8010208017019584, 0.7520773457613315]]\n",
      "2020-12-26 19:26:05,859 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:26:05,860 : INFO : built Dictionary(116 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 189 corpus positions)\n",
      "2020-12-26 19:26:05,920 : INFO : token count processed\n",
      "2020-12-26 19:26:05,928 : INFO : frequencies processed\n",
      "2020-12-26 19:26:06,680 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:26:06,681 : INFO : entropies processed\n",
      "2020-12-26 19:26:06,681 : INFO : extropies processed\n",
      "2020-12-26 19:26:06,685 : INFO : token count processed\n",
      "2020-12-26 19:26:06,687 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:26:06,689 : INFO : alphabet_target #8008\n",
      "2020-12-26 19:26:06,690 : INFO : vocab #8006\n",
      "2020-12-26 19:26:06,693 : INFO : diff #set()\n",
      "2020-12-26 19:26:08,212 : INFO : alphabet #8006\n",
      "2020-12-26 19:26:08,962 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/template/__init__.py')[[1.1960363981577915, 0.45536585861640494], [0.7308225631713867, 0.26917744], [1.9219280948873623, 1.2148067842293933], [6.351505805342684, 4.271370634378849, 6.569849590808993, 4.05302684891254, 0.21834378546630973, 2.298478956430144]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-26 19:26:08,986 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:26:08,998 : INFO : built Dictionary(670 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 14670 corpus positions)\n",
      "2020-12-26 19:26:11,342 : INFO : token count processed\n",
      "2020-12-26 19:26:11,348 : INFO : frequencies processed\n",
      "2020-12-26 19:26:12,094 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:26:12,095 : INFO : entropies processed\n",
      "2020-12-26 19:26:12,096 : INFO : extropies processed\n",
      "2020-12-26 19:26:12,102 : INFO : token count processed\n",
      "2020-12-26 19:26:12,103 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:26:12,105 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:26:12,106 : INFO : vocab #8006\n",
      "2020-12-26 19:26:12,107 : INFO : diff #set()\n",
      "2020-12-26 19:26:13,614 : INFO : alphabet #8006\n",
      "2020-12-26 19:26:14,364 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/third_party/binary_scan_func.py')[[0.9874115731459899, 0.5031670407438764], [0.580678790807724, 0.4193212], [5.900416411804888, 1.4268112924998482], [6.351505805342684, 7.369295554021139, 7.544759627739126, 6.1760417316246965, 1.193253822396442, 0.17546407371798622]]\n",
      "2020-12-26 19:26:14,374 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:26:14,377 : INFO : built Dictionary(487 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 4995 corpus positions)\n",
      "2020-12-26 19:26:15,869 : INFO : token count processed\n",
      "2020-12-26 19:26:15,879 : INFO : frequencies processed\n",
      "2020-12-26 19:26:16,628 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:26:16,629 : INFO : entropies processed\n",
      "2020-12-26 19:26:16,630 : INFO : extropies processed\n",
      "2020-12-26 19:26:16,633 : INFO : token count processed\n",
      "2020-12-26 19:26:16,634 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:26:16,636 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:26:16,637 : INFO : vocab #8006\n",
      "2020-12-26 19:26:16,638 : INFO : diff #set()\n",
      "2020-12-26 19:26:18,158 : INFO : alphabet #8006\n",
      "2020-12-26 19:26:18,907 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/third_party/binaryScan.py')[[0.9741046904511915, 0.5065587477893307], [0.572166234254837, 0.42783377], [5.560964974431592, 1.4219908277735653], [6.351505805342684, 7.271825719524831, 7.477754050580581, 6.145577474286933, 1.126248245237897, 0.20592833105575004]]\n",
      "2020-12-26 19:26:18,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:26:18,921 : INFO : built Dictionary(470 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 4287 corpus positions)\n",
      "2020-12-26 19:26:20,237 : INFO : token count processed\n",
      "2020-12-26 19:26:20,247 : INFO : frequencies processed\n",
      "2020-12-26 19:26:20,998 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:26:20,999 : INFO : entropies processed\n",
      "2020-12-26 19:26:21,000 : INFO : extropies processed\n",
      "2020-12-26 19:26:21,003 : INFO : token count processed\n",
      "2020-12-26 19:26:21,004 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:26:21,006 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:26:21,007 : INFO : vocab #8006\n",
      "2020-12-26 19:26:21,008 : INFO : diff #set()\n",
      "2020-12-26 19:26:22,519 : INFO : alphabet #8006\n",
      "2020-12-26 19:26:23,271 : INFO : Computed distances or similarities ('287', 'sacp-python-common/sacp_python_common/third_party/blackduck.py')[[1.0703758851888527, 0.48300408015464463], [0.617607444524765, 0.38239256], [5.064964725016599, 1.4132622884104922], [6.351505805342684, 7.141932166468383, 7.388022205098271, 6.105415766712794, 1.0365163997555875, 0.24609003862988832]]\n",
      "2020-12-26 19:26:23,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-12-26 19:26:23,276 : INFO : built Dictionary(234 unique tokens: [',', '.', '/', '1', '3']...) from 2 documents (total 793 corpus positions)\n",
      "2020-12-26 19:26:23,644 : INFO : token count processed\n",
      "2020-12-26 19:26:23,655 : INFO : frequencies processed\n",
      "2020-12-26 19:26:24,406 : INFO : scalar_distribution processed\n",
      "2020-12-26 19:26:24,407 : INFO : entropies processed\n",
      "2020-12-26 19:26:24,407 : INFO : extropies processed\n",
      "2020-12-26 19:26:24,409 : INFO : token count processed\n",
      "2020-12-26 19:26:24,411 : INFO : alphabet_source #8006\n",
      "2020-12-26 19:26:24,412 : INFO : alphabet_target #8009\n",
      "2020-12-26 19:26:24,413 : INFO : vocab #8006\n",
      "2020-12-26 19:26:24,415 : INFO : diff #set()\n"
     ]
    }
   ],
   "source": [
    "#[step 2]NonGroundTruth Computation\n",
    "metric_list = [DistanceMetric.WMD,DistanceMetric.SCM,EntropyMetric.MSI_I,EntropyMetric.MI]\n",
    "#metric_list = [EntropyMetric.MSI_I,EntropyMetric.MI]\n",
    "word2vec.ComputeDistanceArtifacts( sampling=False, samples = 100, metric_list = metric_list )\n",
    "word2vec.df_nonground_link.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.df_nonground_link.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[step 3]Saving Non-GroundTruth Links\n",
    "word2vec.SaveLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Non-GroundTruth Links (change the timestamp with the assigned in the previous step)\n",
    "df_nonglinks = ds.mining.ir.LoadLinks(timestamp=1608758550.978155, params=parameters, logging=logging)\n",
    "df_nonglinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[step 4]GroundTruthMatching Testing\n",
    "#TODO change the path for a param\n",
    "path_to_ground_truth =  parameters['path_mappings']\n",
    "word2vec.MatchWithGroundTruth(path_to_ground_truth, semeru_format=True)\n",
    "word2vec.df_ground_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[step 4.1]GroundTruthMatching Testing For CISCO Mappings\n",
    "word2vec.MatchWithGroundTruth(from_mappings=True)\n",
    "word2vec.df_ground_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[optional]GroundTruth Direct Processing\n",
    "ground_links = word2vec.ground_truth_processing(path_to_ground_truth)\n",
    "ground_links # A tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[step 5]Saving GroundTruth Links\n",
    "word2vec.SaveLinks(grtruth = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Non-GroundTruth Links (change the timestamp with the assigned in the previous step)\n",
    "df_glinks = ds.mining.ir.LoadLinks(timestamp=1608759050.647883, params=parameters,grtruth = True, logging=logging)\n",
    "df_glinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nbdev_build_docs #<-------- [Activate when stable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
