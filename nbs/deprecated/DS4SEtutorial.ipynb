{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS4SEtutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu8SN9RmzoeQ"
      },
      "source": [
        "# DS4SE Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HkdzOKD0HyT"
      },
      "source": [
        "This quick tutorial uses [DS4SE API](https://pypi.org/project/ds4se/) to:\n",
        "1. Calculate traceability value between one pair of artifacts.\n",
        "2. For source and target artifact class in Libest dataset, calculate:\n",
        "  \n",
        "  >1) the number of documents in each class\n",
        "\n",
        "  >2) the vocab size of each class\n",
        "\n",
        "  >3) the average number of token in each documents of each class\n",
        "\n",
        "  >4) the top three most frequent tokens in source and target artifact classes\n",
        "\n",
        "  >5) the top three most frequent tokens in source artifact class\n",
        "\n",
        "  >6) the number of shared vocabulary between source and target artifact class\n",
        "\n",
        "  >7) the cross entropy value of source and target artifact class\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nztAxDWrA_PW"
      },
      "source": [
        "This is a quick introduction on how to use the DS4SE API, to follow this tutorial in Google Colab, click the right arrow button in each cell in sequence or click Runtime-> Run all to run all the cells at once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX6mQDUm0ZMo"
      },
      "source": [
        "Download and install dependent libraries of DS4SE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuX5a8RE0gUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c36169-9fbf-4f63-e65d-5016896f7e2a"
      },
      "source": [
        "!pip install --upgrade gensim\n",
        "!pip install nbdev\n",
        "!pip install sentencepiece\n",
        "!pip install dit"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.6/dist-packages (3.8.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: nbdev in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from nbdev) (5.3.5)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from nbdev) (5.0.8)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from nbdev) (4.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from nbdev) (3.13)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from nbdev) (19.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nbdev) (20.4)\n",
            "Requirement already satisfied: nbconvert<6 in /usr/local/lib/python3.6/dist-packages (from nbdev) (5.6.1)\n",
            "Requirement already satisfied: fastcore>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from nbdev) (1.3.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->nbdev) (2.8.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->nbdev) (5.1.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from jupyter-client->nbdev) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->nbdev) (4.6.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->nbdev) (19.0.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev) (2.6.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->nbdev) (5.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->nbdev) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->nbdev) (1.15.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (3.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (1.4.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (2.11.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert<6->nbdev) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->jupyter-client->nbdev) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (50.3.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (4.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert<6->nbdev) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert<6->nbdev) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->nbdev) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->nbdev) (0.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n",
            "Requirement already satisfied: dit in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
            "Requirement already satisfied: boltons in /usr/local/lib/python3.6/dist-packages (from dit) (20.2.1)\n",
            "Requirement already satisfied: debtcollector in /usr/local/lib/python3.6/dist-packages (from dit) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from dit) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from dit) (1.4.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (from dit) (1.0.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from dit) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from dit) (2.5)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from dit) (0.5.5)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from debtcollector->dit) (5.5.1)\n",
            "Requirement already satisfied: wrapt>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from debtcollector->dit) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from prettytable->dit) (50.3.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prettytable->dit) (0.2.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->dit) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX8MNChm0V1Y"
      },
      "source": [
        "Download and install DS4SE. Import TensorFlow into your program:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCbsOumw0KsV",
        "outputId": "49221fe2-e13b-4106-cc39-d9f07b564869"
      },
      "source": [
        "pip install ds4se"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ds4se in /usr/local/lib/python3.6/dist-packages (0.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvXnbVgj04J4"
      },
      "source": [
        "import ds4se.facade as facade"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFE_rPVe2wyM"
      },
      "source": [
        "Import other libraries needed for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZCODLyX23V4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQke9-cc03Me"
      },
      "source": [
        "Load and prapare [Libest dataset](https://github.com/WM-SEMERU/ds4se/tree/master/nbs/test_data). Convert the column name in which actual file content is stored into \"contents\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbwfiCXO1-hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af83fd0e-ddd6-4e36-d651-ae21cc42297f"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/WM-SEMERU/ds4se/SE_Proj2_Facade/nbs/test_data/%5Blibest-pre-req%5D.csv\n",
        "!wget https://raw.githubusercontent.com/WM-SEMERU/ds4se/SE_Proj2_Facade/nbs/test_data/%5Blibest-pre-tc%5D.csv"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-21 04:17:44--  https://raw.githubusercontent.com/WM-SEMERU/ds4se/SE_Proj2_Facade/nbs/test_data/%5Blibest-pre-req%5D.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60790 (59K) [text/plain]\n",
            "Saving to: ‘[libest-pre-req].csv.1’\n",
            "\n",
            "\r[libest-pre-req].cs   0%[                    ]       0  --.-KB/s               \r[libest-pre-req].cs 100%[===================>]  59.37K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-11-21 04:17:44 (4.28 MB/s) - ‘[libest-pre-req].csv.1’ saved [60790/60790]\n",
            "\n",
            "--2020-11-21 04:17:44--  https://raw.githubusercontent.com/WM-SEMERU/ds4se/SE_Proj2_Facade/nbs/test_data/%5Blibest-pre-tc%5D.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 343900 (336K) [text/plain]\n",
            "Saving to: ‘[libest-pre-tc].csv.1’\n",
            "\n",
            "[libest-pre-tc].csv 100%[===================>] 335.84K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-11-21 04:17:45 (8.32 MB/s) - ‘[libest-pre-tc].csv.1’ saved [343900/343900]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhNDeEMe2dJw"
      },
      "source": [
        "source_file = pd.read_csv(\"[libest-pre-req].csv\",names=['ids', 'text'], header=None, sep=' ')\n",
        "target_file = pd.read_csv(\"[libest-pre-tc].csv\",names=['ids', 'text'], header=None, sep=' ')\n",
        "source_file = source_file.rename(columns={\"text\":\"contents\"})\n",
        "target_file = target_file.rename(columns={\"text\":\"contents\"})"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-LarMKf302u"
      },
      "source": [
        "Create a pandas dataframe to store the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RJ4hNGA4R1q"
      },
      "source": [
        "d = {'source': [], 'target': [], 'distance':[],'similarity/traceability':[]}\n",
        "output_df = pd.DataFrame(data=d)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-Oo4UlG4mxW"
      },
      "source": [
        "Retrive one element from source artifact and one element from target artifact to calculate traceability. Store id information for reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHLKchLc5k2t"
      },
      "source": [
        "source_id = source_file[\"ids\"][1].split('/')[-1]\n",
        "target_id = target_file[\"ids\"][1].split('/')[-1]\n",
        "source_string = source_file[\"contents\"][1]\n",
        "target_string = target_file[\"contents\"][1]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTyIwRxs5rU5"
      },
      "source": [
        "Call TraceLinkValue method to calcuate the distance and traceability values of this pair. In this example we used word2vec technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgVMeJNC4m_U",
        "outputId": "b9b50888-25c8-4c80-8e83-60b31271d0a2"
      },
      "source": [
        "TLV = facade.TraceLinkValue(source_string, target_string, \"word2vec\")\n",
        "distance = TLV[0]\n",
        "traceability = TLV[1]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-21 04:17:45,247 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2020-11-21 04:17:45,256 : INFO : built Dictionary(1815 unique tokens: ['@return', 'Converts', 'The', 'a', 'and']...) from 153 documents (total 5769 corpus positions)\n",
            "2020-11-21 04:17:45,257 : INFO : loading Word2Vec object from /usr/local/lib/python3.6/dist-packages/ds4se/model/word2vec_libest.model\n",
            "2020-11-21 04:17:45,327 : INFO : loading wv recursively from /usr/local/lib/python3.6/dist-packages/ds4se/model/word2vec_libest.model.wv.* with mmap=None\n",
            "2020-11-21 04:17:45,330 : INFO : setting ignored attribute vectors_norm to None\n",
            "2020-11-21 04:17:45,332 : INFO : loading vocabulary recursively from /usr/local/lib/python3.6/dist-packages/ds4se/model/word2vec_libest.model.vocabulary.* with mmap=None\n",
            "2020-11-21 04:17:45,332 : INFO : loading trainables recursively from /usr/local/lib/python3.6/dist-packages/ds4se/model/word2vec_libest.model.trainables.* with mmap=None\n",
            "2020-11-21 04:17:45,333 : INFO : setting ignored attribute cum_table to None\n",
            "2020-11-21 04:17:45,334 : INFO : loaded /usr/local/lib/python3.6/dist-packages/ds4se/model/word2vec_libest.model\n",
            "2020-11-21 04:17:45,366 : INFO : precomputing L2-norms of word weight vectors\n",
            "2020-11-21 04:17:45,370 : INFO : constructing a sparse term similarity matrix using <gensim.models.keyedvectors.WordEmbeddingSimilarityIndex object at 0x7f3cc1334518>\n",
            "2020-11-21 04:17:45,374 : INFO : iterating over columns in dictionary order\n",
            "2020-11-21 04:17:45,379 : INFO : PROGRESS: at 0.06% columns (1 / 1815, 0.055096% density, 0.055096% projected density)\n",
            "2020-11-21 04:17:45,624 : INFO : PROGRESS: at 55.15% columns (1001 / 1815, 0.140033% density, 0.209102% projected density)\n",
            "2020-11-21 04:17:45,746 : INFO : constructed a sparse term similarity matrix with 0.173668% density\n",
            "2020-11-21 04:17:45,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2020-11-21 04:17:45,768 : INFO : built Dictionary(502 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2134 corpus positions)\n",
            "2020-11-21 04:17:49,106 : INFO : Computed distances or similarities ('source', 'target')[[0.4005029238604272, 0.7140292126228072]]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9cgdPwy6Vm8"
      },
      "source": [
        "Display the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNMssRvy5iw5",
        "outputId": "93562c5c-0474-4f03-d68a-6ea086f9a895"
      },
      "source": [
        "print(\"The traceability value between artifacts {} and {} is {}\".format(source_id,target_id,format(traceability,'.2f')))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The traceability value between artifacts RQ46-pre.txt and us3496.c is 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m998Sfi962DP"
      },
      "source": [
        "Call **NumDoc** method to count the number of documents in each artifacts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed7i00gM69Du"
      },
      "source": [
        "num_docs = facade.NumDoc(source_file, target_file)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLHGhG4k7Bts"
      },
      "source": [
        "Display the number of documents result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtTt1X8e7Fdm",
        "outputId": "f0c77424-d4be-4d9a-96f6-71c0604426c7"
      },
      "source": [
        "print(\"Source artifacts contains {} documents, Target artifacts contains {} documents.\".format(num_docs[0],num_docs[1]))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source artifacts contains 52 documents, Target artifacts contains 21 documents.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4PxltUd8Sgz"
      },
      "source": [
        "Call **VocabSize** method to count the vocabulary size of each artifacts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4qGzeoX8Sgz"
      },
      "source": [
        "vocab_size = facade.VocabSize(source_file,target_file)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nex61OxM8Sgz"
      },
      "source": [
        "Display the vocabulary size of each artifacts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxocesHg8Sgz",
        "outputId": "09d435c5-4fcb-4169-f65d-debb3322733c"
      },
      "source": [
        "print(\"Source artifacts's vocab size is {}. Target artifacts's vocab size is {}.\".format(vocab_size[0],vocab_size[1]))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source artifacts's vocab size is 2349. Target artifacts's vocab size is 3168.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42wuvP6_IF2v"
      },
      "source": [
        "Computes the average number of token in each class and also the difference between them using **AverageToken** method:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edJEEtldAWtT"
      },
      "source": [
        "token = facade.AverageToken(source_file, target_file)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dnF8sAu-IBL"
      },
      "source": [
        "Display the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR-gK8Y5-Ied",
        "outputId": "8e88771d-1aec-45f4-a9bf-3ed580ac9f68"
      },
      "source": [
        "print(\"On average, each document in source artifact class contains {} tokens and each document in target artifact class contains {} tokens \".format(token[0],token[1]))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On average, each document in source artifact class contains 365.21153846153845 tokens and each document in target artifact class contains 4970.476190476191 tokens \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghxkE0X2G45Y"
      },
      "source": [
        "To find out the most frequent token in both source and target artifacts, use **VocabShared** method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJBiqZDVGxqi"
      },
      "source": [
        "vocab_shared = facade.VocabShared(source_file, target_file)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1hhXMe4-JWi"
      },
      "source": [
        "Display the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyelaXi6-Jfo",
        "outputId": "d3f44dd6-7fa7-4cd1-ed23-71b808d98f34"
      },
      "source": [
        "print(\"the top three most frequent token used in two artifact classes and their corresponding count and frenquency is:\")\n",
        "vocab_shared"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the top three most frequent token used in two artifact classes and their corresponding count and frenquency is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': [2903, 0.02353065144969239],\n",
              " '8': [2241, 0.01816472266578045],\n",
              " '▁': [53876, 0.43669906217830773]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArklHjhx-lPs"
      },
      "source": [
        "Use **Vocab** method for the most frequent token in just source artifacts class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGopkMgwHDaj"
      },
      "source": [
        "vocab = facade.Vocab(source_file)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWQ5LLlC-KV5"
      },
      "source": [
        "Display the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIn2AtXZ-Kea",
        "outputId": "a76b160e-b286-48c1-dc3a-d438e3cdcab9"
      },
      "source": [
        "print(\"the top three most frequent token used in source artifact classes and their corresponding count and frenquency is:\")\n",
        "vocab"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the top three most frequent token used in source artifact classes and their corresponding count and frenquency is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client': [291, 0.01532304775946501],\n",
              " 'est': [281, 0.014796482544363119],\n",
              " '▁': [8912, 0.4692749196988047]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-PHjVCmHS5J"
      },
      "source": [
        "sharedvocabsize = facade.SharedVocabSize(source_file, target_file)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K85Nj-W-K_s"
      },
      "source": [
        "Display the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5dG4yQC-LKk",
        "outputId": "dd3a702c-4cca-41dc-8c05-f8816436b056"
      },
      "source": [
        "print(\"the number of shared token between source and target artifact classes is {}\".format(sharedvocabsize))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of shared token between source and target artifact classes is 5042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4paqRmalHac8"
      },
      "source": [
        "Use **CrossEntropy** methods to calcualte cross entropy of source and target class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NthD6LdHs8D"
      },
      "source": [
        "entropy = facade.CrossEntropy(source_file, target_file)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks8tkaIa9ov2"
      },
      "source": [
        "Display the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcWh09eH9sLB",
        "outputId": "5617bb7c-ad40-4f8a-ffd7-e4c4583ab7d3"
      },
      "source": [
        "print(\"The cross entropy value of source and target artifacts is {}\".format(format(entropy,\".2f\")))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cross entropy value of source and target artifacts is 6.16\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}