{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp codexplainer.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "formed-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple, List, Optional, Dict, Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statistical-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#Logging configuration\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-bradley",
   "metadata": {},
   "source": [
    "## Module codexplainer.utils\n",
    "\n",
    "> Module providing utilities for handling-organizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "funny-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_tabulardata_distances_data(data: List,\n",
    "                                   div_nm: Optional[str]='JS-Divergence',\n",
    "                                   dist_nm: Optional[str]='JS-Distance') -> Tuple:\n",
    "    \"\"\"\n",
    "    Get the tabular data for error distances (JS distance & divergence)\n",
    "    \n",
    "    :param err_data: List containing data of multiple experiments\n",
    "    :pram div_nm: Optional[str] indicating the name of the divergence metrics in the data\n",
    "    :pram dist_nm: Optional[str] indicating the name of the distance metrics in the data\n",
    "    \n",
    "    :return: Tuple[pd.DataFrame, pd.Dataframe] containing distance and divergence tabular data\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    divs = []\n",
    "    \n",
    "    for experiment in data:\n",
    "        record_dist = { }\n",
    "        record_div = { }\n",
    "        \n",
    "        for dimension, measures in experiment.items():\n",
    "            record_dist[dimension] = measures[dist_nm]\n",
    "            record_div[dimension] = measures[div_nm]\n",
    "            \n",
    "        dists.append(record_dist)\n",
    "        divs.append(record_div)\n",
    "    \n",
    "    \n",
    "    dist_df = pd.DataFrame(dists)\n",
    "    div_df = pd.DataFrame(divs)\n",
    "    \n",
    "    return dist_df, div_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comfortable-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_data_stats_dataframe(stats_data: List,\n",
    "                             measures: Optional[List[str]]=['mean']) -> Dict:\n",
    "    \"\"\"\n",
    "    Get a set of dataframes for the stats data gathered accross all experiments\n",
    "    Available for metrics & error analysis\n",
    "    \n",
    "    :param stats_data: List containing experimets data with metrics stats.\n",
    "    :param measures: List[str] containing all the measures to consider\n",
    "                     - ['mean'] considered by default\n",
    "    \n",
    "    :return: Dictionary containing pd.DataFrames for all the specified measures\n",
    "    \"\"\"\n",
    "    data = { }\n",
    "    \n",
    "    for measure in measures:\n",
    "        data[measure] = []\n",
    "    \n",
    "    for experiment in stats_data:\n",
    "        for m in range(len(measures)):\n",
    "            record = { }\n",
    "            measure = measures[m]\n",
    "            \n",
    "            record  = { metric: stats[measure]  for metric, stats in experiment.items() }\n",
    "                \n",
    "            data[measure].append(record)\n",
    "            \n",
    "    data_df = { measure: pd.DataFrame(m_data)  for measure, m_data in data.items() }\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "joint-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def clean_dict_dataset_nans(data: Dict, measures: Optional[List[str]]=['mean']):\n",
    "    \"\"\"\n",
    "    Replace Nan values by mean\n",
    "    :param data: Dict containing all \"raw\" dataframes for corresponding measures\n",
    "    \n",
    "    :return: Dictionary containing dataframes for each measure\n",
    "    \"\"\"\n",
    "    clean_dict = { }\n",
    "    for measure in measures:\n",
    "        clean_dict[measure] = data[measure].fillna(data[measure].mean())\n",
    "    \n",
    "    return clean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dense-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def clean_dataset_nans(data: pd.DataFrame):\n",
    "    clean_df = data.fillna(data.mean())\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "endless-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def integrate_missing_error_dims(df: pd.DataFrame, dimensions: Set):\n",
    "    \"\"\"\n",
    "    Integrate dimensions in order to standarize dimensions for comparisons\n",
    "    \n",
    "    :return: pd.DataFrame with the integrated dimensions\n",
    "    \"\"\"\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    present_dims = list(df.columns)\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        if dim not in present_dims:\n",
    "            result_df[dim] = np.zeros(len(df))\n",
    "        \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "native-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0.1_mgmnt.prep.ipynb.\n",
      "Converted 0.2_mgmnt.prep.files_mgmnt.ipynb.\n",
      "Converted 0.3_mgmnt.prep.bpe_tokenization.ipynb.\n",
      "Converted 0.4_mgmnt.prep.tokenization_counting.ipynb.\n",
      "Converted 0.5_mgmnt.prep.token_mgmnt.ipynb.\n",
      "Converted 1.1_exp.info.ipynb.\n",
      "Converted 1.2_exp.desc.metrics.java.ipynb.\n",
      "Converted 1.4_exp.metrics_python.ipynb.\n",
      "Converted 1.5_exp.metrics_java.ipynb.\n",
      "Converted 2.0_repr.codebert.ipynb.\n",
      "Converted 2.0_repr.i.ipynb.\n",
      "Converted 2.1_repr.codeberta.ipynb.\n",
      "Converted 2.1_repr.roberta.train.ipynb.\n",
      "Converted 2.2_repr.roberta.eval.ipynb.\n",
      "Converted 2.3_repr.word2vec.train.ipynb.\n",
      "Converted 2.6_repr.word2vec.eval.ipynb.\n",
      "Converted 2.7_repr.distmetrics.ipynb.\n",
      "Converted 2.8_repr.sentence_transformers.ipynb.\n",
      "Converted 3.1_traceability.unsupervised.eda.ipynb.\n",
      "Converted 3.2_traceability.unsupervised.approach.d2v.ipynb.\n",
      "Converted 3.2_traceability.unsupervised.approach.w2v.ipynb.\n",
      "Converted 4.0_infoxplainer.ir.ipynb.\n",
      "Converted 4.1_infoxplainer.ir.unsupervised.d2v.ipynb.\n",
      "Converted 4.2_infoxplainer.ir.unsupervised.w2v.ipynb.\n",
      "Converted 4.3_infoxplainer.ir.eval.x2v.ipynb.\n",
      "Converted 4.4_infoxplainer.causality.eval.traceability.ipynb.\n",
      "Converted 4.5_infoxplainer.description.eval.traceability.ipynb.\n",
      "Converted 4.6_infoxplainer.prediction.eval.traceability.ipynb.\n",
      "Converted 5.0_utils.clusterization.ipynb.\n",
      "Converted 5.1_utils.visualization.ipynb.\n",
      "Converted 5.2_utils.distances.ipynb.\n",
      "Converted 5.3_utils.plotting.ipynb.\n",
      "Converted 5.3_utils.statistics.ipynb.\n",
      "Converted 8.1_codexplainer.error_checker.ipynb.\n",
      "Converted 8.2_codexplainer.metrics.ipynb.\n",
      "Converted 8.4_codexplainer.metrics_example.ipynb.\n",
      "Converted 8.5_codexplainer.d2v_vectorization.ipynb.\n",
      "Converted 8.6_codexplainer.prototypes_criticisms.ipynb.\n",
      "Converted 8.7_codexplainer.mutual_info.ipynb.\n",
      "Converted 8.8_codexplainer.utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
