{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mgmnt.prep.tokenization_counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from ds4se.mgmnt.prep.bpe_tokenization import CustomTokenizer, HFTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization_counting\n",
    "\n",
    "> Module to obtain the vocabulary (based on BPE tokenization) from a collection of code snippets.\n",
    "\n",
    "> @Alvaro 16 May 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"bpe32k_path\": \"/tf/main/dvc-ds4se/models/bpe/sentencepiece/deprecated/java_bpe_32k.model\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method leverages Tokenization from <i>ds4se.mgmnt.prep.bpe_tokenization.CustomTokenizer</i> to perform a counting of tokens given certain code dataset. Such counting severs as input for computing <i>Mutual information</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_tokens_frequency_hf_tkzr(df: pd.DataFrame,\n",
    "                                  tokenizer: CustomTokenizer,\n",
    "                                  include_pad_token:Optional[bool]=False) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Function to get the frequencies of a code dataset given a tokenizer.\n",
    "    \n",
    "    :param df: DataFrame containing the code snippets\n",
    "    :param tokenizer: CustomTokenizer instance (HF or SP) with the corresponding implementation for tokenization\n",
    "    \n",
    "    :return: Dictionary containing the frequency of tokens for the given set of code snippets.\n",
    "    \"\"\"    \n",
    "    freqs = { }\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        tokens = tokenizer.tokenize_txt(row.code)\n",
    "        \n",
    "        for tok in tokens:\n",
    "            if tok == \"<pad>\" and not include_pad_token: # Special padding token is ignored by default\n",
    "                continue\n",
    "            freqs[tok] = freqs[tok]+1 if tok in freqs.keys() else 1\n",
    "                \n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example with CodeNetSearch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df = pd.read_csv('/tf/main/dvc-ds4se/code/searchnet/clean_java.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples = java_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "\n",
    "hf_tokenizer = HFTokenizer('tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = get_tokens_frequency_hf_tkzr(java_samples, hf_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 5,\n",
      " '\"': 2,\n",
      " '&': 2,\n",
      " '(': 60,\n",
      " ')': 60,\n",
      " ',': 20,\n",
      " '.': 43,\n",
      " '0': 2,\n",
      " ':': 3,\n",
      " ';': 29,\n",
      " '<': 7,\n",
      " '=': 12,\n",
      " '>': 9,\n",
      " '?': 1,\n",
      " '@': 5,\n",
      " 'APPLICATION': 1,\n",
      " 'ARRAY': 2,\n",
      " 'ATTRIBUTE': 1,\n",
      " 'All': 2,\n",
      " 'Attributes': 1,\n",
      " 'Begin': 2,\n",
      " 'Bot': 1,\n",
      " 'Builder': 2,\n",
      " 'Cas': 2,\n",
      " 'Char': 3,\n",
      " 'Character': 1,\n",
      " 'Commerce': 2,\n",
      " 'Consum': 1,\n",
      " 'Containers': 1,\n",
      " 'DI': 1,\n",
      " 'DOT': 2,\n",
      " 'Discount': 7,\n",
      " 'E': 2,\n",
      " 'EN': 1,\n",
      " 'ENTITY': 1,\n",
      " 'En': 7,\n",
      " 'FOUND': 1,\n",
      " 'From': 1,\n",
      " 'G': 1,\n",
      " 'H': 1,\n",
      " 'Helper': 1,\n",
      " 'IAtomContainer': 2,\n",
      " 'ID': 2,\n",
      " 'INDEX': 1,\n",
      " 'IT': 1,\n",
      " 'Id': 3,\n",
      " 'Ident': 1,\n",
      " 'Index': 1,\n",
      " 'Initial': 1,\n",
      " 'JC': 1,\n",
      " 'JSON': 1,\n",
      " 'LET': 1,\n",
      " 'Links': 3,\n",
      " 'List': 1,\n",
      " 'Look': 2,\n",
      " 'MP': 2,\n",
      " 'MediaType': 1,\n",
      " 'Menu': 2,\n",
      " 'NOT': 1,\n",
      " 'Name': 4,\n",
      " 'Names': 2,\n",
      " 'New': 1,\n",
      " 'Next': 1,\n",
      " 'Object': 2,\n",
      " 'Override': 1,\n",
      " 'PH': 1,\n",
      " 'PUT': 1,\n",
      " 'Param': 1,\n",
      " 'Path': 1,\n",
      " 'Persistence': 1,\n",
      " 'Pre': 2,\n",
      " 'Prop': 2,\n",
      " 'Property': 1,\n",
      " 'R': 1,\n",
      " 'RE': 1,\n",
      " 'Release': 2,\n",
      " 'Resources': 1,\n",
      " 'Response': 1,\n",
      " 'Service': 2,\n",
      " 'Set': 3,\n",
      " 'Status': 1,\n",
      " 'String': 3,\n",
      " 'Style': 1,\n",
      " 'T': 5,\n",
      " 'TER': 1,\n",
      " 'TYPE': 1,\n",
      " 'Th': 1,\n",
      " 'Token': 4,\n",
      " 'Tokens': 1,\n",
      " 'Type': 5,\n",
      " 'Usage': 7,\n",
      " 'Util': 1,\n",
      " 'Valid': 1,\n",
      " 'Value': 3,\n",
      " 'Version': 2,\n",
      " 'View': 1,\n",
      " 'Wh': 3,\n",
      " 'Y': 1,\n",
      " '[': 4,\n",
      " ']': 4,\n",
      " '_': 5,\n",
      " 'a': 3,\n",
      " 'able': 1,\n",
      " 'ableType': 1,\n",
      " 'add': 2,\n",
      " 'ak': 1,\n",
      " 'as': 2,\n",
      " 'at': 1,\n",
      " 'atom': 1,\n",
      " 'b': 1,\n",
      " 'build': 2,\n",
      " 'cache': 4,\n",
      " 'ced': 1,\n",
      " 'char': 1,\n",
      " 'class': 1,\n",
      " 'commerce': 2,\n",
      " 'cycle': 1,\n",
      " 'd': 4,\n",
      " 'dArray': 2,\n",
      " 'data': 1,\n",
      " 'do': 1,\n",
      " 'e': 1,\n",
      " 'eme': 1,\n",
      " 'end': 3,\n",
      " 'equals': 1,\n",
      " 'es': 1,\n",
      " 'finally': 1,\n",
      " 'for': 5,\n",
      " 'get': 5,\n",
      " 'getID': 1,\n",
      " 'getInstance': 1,\n",
      " 'getResource': 2,\n",
      " 'head': 2,\n",
      " 'i': 1,\n",
      " 'ic': 6,\n",
      " 'id': 1,\n",
      " 'ident': 2,\n",
      " 'ier': 1,\n",
      " 'if': 8,\n",
      " 'ile': 1,\n",
      " 'index': 2,\n",
      " 'ing': 1,\n",
      " 'int': 3,\n",
      " 'isPresent': 1,\n",
      " 'ive': 1,\n",
      " 'j': 1,\n",
      " 'leg': 1,\n",
      " 'line': 2,\n",
      " 'link': 1,\n",
      " 'losure': 1,\n",
      " 'm': 1,\n",
      " 'me': 3,\n",
      " 'new': 5,\n",
      " 'null': 6,\n",
      " 'ob': 1,\n",
      " 'ok': 1,\n",
      " 'ol': 5,\n",
      " 'olecule': 1,\n",
      " 'om': 3,\n",
      " 'omain': 2,\n",
      " 'or': 3,\n",
      " 'ot': 2,\n",
      " 'posit': 1,\n",
      " 'pre': 1,\n",
      " 'private': 2,\n",
      " 'prop': 2,\n",
      " 'public': 7,\n",
      " 'ram': 1,\n",
      " 're': 1,\n",
      " 'reak': 1,\n",
      " 'return': 14,\n",
      " 's': 6,\n",
      " 'select': 1,\n",
      " 'self': 1,\n",
      " 'set': 2,\n",
      " 'size': 1,\n",
      " 'status': 1,\n",
      " 'sume': 1,\n",
      " 't': 2,\n",
      " 'tain': 1,\n",
      " 'tinue': 1,\n",
      " 'toArray': 1,\n",
      " 'true': 2,\n",
      " 'try': 8,\n",
      " 'type': 2,\n",
      " 'ublic': 1,\n",
      " 'update': 2,\n",
      " 'v': 1,\n",
      " 'values': 1,\n",
      " '{': 21,\n",
      " '}': 21,\n",
      " 'ĉ': 9,\n",
      " 'Ċ': 74,\n",
      " 'Ġ': 108,\n",
      " 'Ġ0': 2,\n",
      " 'Ġ<': 3,\n",
      " 'ĠAnnotation': 1,\n",
      " 'ĠArrayList': 2,\n",
      " 'ĠC': 1,\n",
      " 'ĠCache': 1,\n",
      " 'ĠCh': 1,\n",
      " 'ĠChar': 2,\n",
      " 'ĠCommerce': 1,\n",
      " 'ĠIAtomContainer': 1,\n",
      " 'ĠIn': 2,\n",
      " 'ĠIndex': 1,\n",
      " 'ĠJC': 1,\n",
      " 'ĠList': 4,\n",
      " 'ĠMetadata': 2,\n",
      " 'ĠResponse': 3,\n",
      " 'ĠString': 4,\n",
      " 'ĠT': 4,\n",
      " 'ĠToken': 2,\n",
      " 'ĠType': 5,\n",
      " 'Ġa': 2,\n",
      " 'Ġadd': 1,\n",
      " 'Ġb': 2,\n",
      " 'Ġbuilder': 1,\n",
      " 'Ġcache': 4,\n",
      " 'Ġcommerce': 2,\n",
      " 'Ġcon': 2,\n",
      " 'Ġd': 2,\n",
      " 'Ġdef': 4,\n",
      " 'Ġensure': 1,\n",
      " 'Ġfind': 2,\n",
      " 'Ġget': 1,\n",
      " 'ĠgetM': 1,\n",
      " 'ĠgetResource': 1,\n",
      " 'Ġid': 1,\n",
      " 'Ġident': 2,\n",
      " 'Ġindex': 1,\n",
      " 'Ġj': 1,\n",
      " 'Ġlinks': 1,\n",
      " 'Ġm': 4,\n",
      " 'Ġp': 1,\n",
      " 'Ġparse': 1,\n",
      " 'Ġpopulate': 1,\n",
      " 'Ġprop': 2,\n",
      " 'Ġput': 1,\n",
      " 'Ġresult': 3,\n",
      " 'Ġself': 1,\n",
      " 'Ġstat': 6,\n",
      " 'Ġt': 1,\n",
      " 'Ġthe': 3,\n",
      " 'Ġtmp': 3,\n",
      " 'Ġtoken': 2,\n",
      " 'Ġv': 5,\n",
      " 'Ġvalues': 2,\n",
      " 'Ġwh': 1,\n",
      " 'ĠĠĠ': 17,\n",
      " 'ĠĠĠĠĠ': 4,\n",
      " 'ĠĠĠĠĠĠĠ': 21,\n",
      " 'ĠĠĠĠĠĠĠĠĠĠĠ': 8,\n",
      " 'ĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠ': 6,\n",
      " 'ĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠ': 2}\n"
     ]
    }
   ],
   "source": [
    "pprint(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0.1_mgmnt.prep.ipynb.\n",
      "Converted 0.2_mgmnt.prep.files_mgmnt.ipynb.\n",
      "Converted 0.3_mgmnt.prep.bpe_tokenization.ipynb.\n",
      "Converted 0.4_mgmnt.prep.tokenization_counting.ipynb.\n",
      "Converted 0.5_mgmnt.prep.token_mgmnt.ipynb.\n",
      "Converted 1.1_exp.info.ipynb.\n",
      "Converted 1.2_exp.desc.metrics.java.ipynb.\n",
      "Converted 1.4_exp.metrics_python.ipynb.\n",
      "Converted 1.5_exp.metrics_java.ipynb.\n",
      "Converted 2.0_repr.codebert.ipynb.\n",
      "Converted 2.0_repr.i.ipynb.\n",
      "Converted 2.1_repr.codeberta.ipynb.\n",
      "Converted 2.1_repr.roberta.train.ipynb.\n",
      "Converted 2.2_repr.roberta.eval.ipynb.\n",
      "Converted 2.3_repr.word2vec.train.ipynb.\n",
      "Converted 2.6_repr.word2vec.eval.ipynb.\n",
      "Converted 2.7_repr.distmetrics.ipynb.\n",
      "Converted 2.8_repr.sentence_transformers.ipynb.\n",
      "Converted 3.1_traceability.unsupervised.eda.ipynb.\n",
      "Converted 3.2_traceability.unsupervised.approach.d2v.ipynb.\n",
      "Converted 3.2_traceability.unsupervised.approach.w2v.ipynb.\n",
      "Converted 4.0_infoxplainer.ir.ipynb.\n",
      "Converted 4.1_infoxplainer.ir.unsupervised.d2v.ipynb.\n",
      "Converted 4.2_infoxplainer.ir.unsupervised.w2v.ipynb.\n",
      "Converted 4.3_infoxplainer.ir.eval.x2v.ipynb.\n",
      "Converted 4.4_infoxplainer.causality.eval.traceability.ipynb.\n",
      "Converted 4.5_infoxplainer.description.eval.traceability.ipynb.\n",
      "Converted 4.6_infoxplainer.prediction.eval.traceability.ipynb.\n",
      "Converted 5.0_utils.clusterization.ipynb.\n",
      "Converted 5.1_utils.visualization.ipynb.\n",
      "Converted 5.2_utils.distances.ipynb.\n",
      "Converted 5.3_utils.plotting.ipynb.\n",
      "Converted 5.3_utils.statistics.ipynb.\n",
      "Converted 8.1_codexplainer.error_checker.ipynb.\n",
      "Converted 8.2_codexplainer.metrics.ipynb.\n",
      "Converted 8.4_codexplainer.metrics_example.ipynb.\n",
      "Converted 8.5_codexplainer.d2v_vectorization.ipynb.\n",
      "Converted 8.6_codexplainer.prototypes_criticisms.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
